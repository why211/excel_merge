import pandas as pd
import os
import glob
import re
from typing import List, Tuple, Dict, Optional
from difflib import SequenceMatcher
from difflib import SequenceMatcher

class ExcelProcessor:
    """Excelæ–‡ä»¶å¤„ç†å·¥å…·"""
    
    def __init__(self):
        self.selected_files = []
        self.all_fields = []
        self.selected_fields = []
        self.deduplicate = False
        self.dedup_fields = []
        self.output_filename = "result.xlsx"
        
        # å­—æ®µè¡¥å……åŠŸèƒ½ç›¸å…³å±æ€§
        self.enable_field_supplement = False
        self.field_mappings = {}  # å­—æ®µæ˜ å°„å­—å…¸ {field_name: {student_id: value}}
        self.default_values = {}  # é»˜è®¤å€¼å­—å…¸ {field_name: default_value}
        self.link_field = 'å­¦å·'  # å…³è”å­—æ®µï¼Œé»˜è®¤ä¸ºå­¦å·
        
        # æ–°å¢ï¼šæ™ºèƒ½åˆ—ååŒ¹é…ç›¸å…³å±æ€§
        self.column_mapping = {}  # åˆ—åæ˜ å°„å…³ç³»
        self.enable_smart_matching = True  # æ˜¯å¦å¯ç”¨æ™ºèƒ½åŒ¹é…
        self.similarity_threshold = 0.8  # ç›¸ä¼¼åº¦é˜ˆå€¼
        self.auto_clean_columns = True  # æ˜¯å¦è‡ªåŠ¨æ¸…ç†åˆ—å
        
        # å¸¸è§åˆ—åå˜ä½“æ˜ å°„
        self.common_column_variants = {
            'å­¦å·': ['å­¦å·', 'å­¦å·å·', 'å­¦å­¦å·', 'xuehao', 'student_id', 'å­¦ç”Ÿç¼–å·', 'å­¦ç”Ÿå­¦å·'],
            'å­¦ç”Ÿå§“å': ['å­¦ç”Ÿå§“å', 'å­¦ç”Ÿå§“åå', 'å­¦å­¦ç”Ÿå§“å', 'student_name', 'å§“å', 'å­¦ç”Ÿå', 'å­¦ç”Ÿå§“åï¼ˆä¸­æ–‡ï¼‰'],
            'ç­çº§': ['ç­çº§', 'ç­', 'class', 'ç­çº§åç§°'],
            'æˆç»©': ['æˆç»©', 'åˆ†æ•°', 'score', 'grade', 'è€ƒè¯•åˆ†æ•°'],
            'è¯¾ç¨‹': ['è¯¾ç¨‹', 'ç§‘ç›®', 'course', 'subject', 'è¯¾ç¨‹åç§°']
        }
        
        # æ–°å¢ï¼šæ™ºèƒ½åˆ—ååŒ¹é…ç›¸å…³å±æ€§
        self.column_mapping = {}  # åˆ—åæ˜ å°„å…³ç³»
        self.enable_smart_matching = True  # æ˜¯å¦å¯ç”¨æ™ºèƒ½åŒ¹é…
        self.similarity_threshold = 0.8  # ç›¸ä¼¼åº¦é˜ˆå€¼
        self.auto_clean_columns = True  # æ˜¯å¦è‡ªåŠ¨æ¸…ç†åˆ—å
        
        # å¸¸è§åˆ—åå˜ä½“æ˜ å°„
        self.common_column_variants = {
            'å­¦å·': ['å­¦å·', 'å­¦å·å·', 'å­¦å­¦å·', 'xuehao', 'student_id', 'å­¦ç”Ÿç¼–å·', 'å­¦ç”Ÿå­¦å·'],
            'å­¦ç”Ÿå§“å': ['å­¦ç”Ÿå§“å', 'å­¦ç”Ÿå§“åå', 'å­¦å­¦ç”Ÿå§“å', 'student_name', 'å§“å', 'å­¦ç”Ÿå', 'å­¦ç”Ÿå§“åï¼ˆä¸­æ–‡ï¼‰'],
            'ç­çº§': ['ç­çº§', 'ç­', 'class', 'ç­çº§åç§°'],
            'æˆç»©': ['æˆç»©', 'åˆ†æ•°', 'score', 'grade', 'è€ƒè¯•åˆ†æ•°'],
            'è¯¾ç¨‹': ['è¯¾ç¨‹', 'ç§‘ç›®', 'course', 'subject', 'è¯¾ç¨‹åç§°']
        }
    
    def clean_column_name(self, column_name: str) -> str:
        """
        æ¸…ç†åˆ—åï¼Œå»é™¤ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
        
        Args:
            column_name: åŸå§‹åˆ—å
            
        Returns:
            æ¸…ç†åçš„åˆ—å
        """
        if not self.auto_clean_columns:
            return column_name
        
        # å»é™¤é¦–å°¾ç©ºæ ¼
        cleaned = column_name.strip()
        
        # å»é™¤å¤šä½™çš„ç©ºæ ¼
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰
        cleaned = re.sub(r'[^\w\s\u4e00-\u9fff]', '', cleaned)
        
        # å†æ¬¡å»é™¤ç©ºæ ¼
        cleaned = cleaned.strip()
        
        return cleaned
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦
        
        Args:
            str1: å­—ç¬¦ä¸²1
            str2: å­—ç¬¦ä¸²2
            
        Returns:
            ç›¸ä¼¼åº¦ (0-1)
        """
        # ä½¿ç”¨SequenceMatcherè®¡ç®—ç›¸ä¼¼åº¦
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def find_similar_columns(self, target_column: str, available_columns: List[str]) -> List[Tuple[str, float]]:
        """
        æŸ¥æ‰¾ä¸ç›®æ ‡åˆ—åç›¸ä¼¼çš„åˆ—å
        
        Args:
            target_column: ç›®æ ‡åˆ—å
            available_columns: å¯ç”¨åˆ—ååˆ—è¡¨
            
        Returns:
            ç›¸ä¼¼åˆ—ååˆ—è¡¨ï¼ŒåŒ…å«ç›¸ä¼¼åº¦
        """
        similar_columns = []
        cleaned_target = self.clean_column_name(target_column)
        
        for column in available_columns:
            cleaned_column = self.clean_column_name(column)
            
            # ç²¾ç¡®åŒ¹é…
            if cleaned_target == cleaned_column:
                similar_columns.append((column, 1.0))
                continue
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = self.calculate_similarity(cleaned_target, cleaned_column)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§å˜ä½“
            for standard_name, variants in self.common_column_variants.items():
                if cleaned_target in variants and cleaned_column in variants:
                    similarity = max(similarity, 0.9)  # æé«˜å˜ä½“çš„ç›¸ä¼¼åº¦
                    break
            
            if similarity >= self.similarity_threshold:
                similar_columns.append((column, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similar_columns.sort(key=lambda x: x[1], reverse=True)
        return similar_columns
    
    def smart_column_mapping(self, required_columns: List[str], available_columns: List[str]) -> Dict[str, str]:
        """
        æ™ºèƒ½åˆ—åæ˜ å°„
        
        Args:
            required_columns: éœ€è¦çš„åˆ—å
            available_columns: å¯ç”¨çš„åˆ—å
            
        Returns:
            åˆ—åæ˜ å°„å­—å…¸
        """
        mapping = {}
        unmapped_required = []
        unmapped_available = available_columns.copy()
        
        print(f"\nğŸ” æ™ºèƒ½åˆ—åæ˜ å°„åˆ†æ...")
        print(f"ğŸ“‹ éœ€è¦çš„åˆ—å: {required_columns}")
        print(f"ğŸ“‹ å¯ç”¨çš„åˆ—å: {available_columns}")
        
        # ç¬¬ä¸€è½®ï¼šç²¾ç¡®åŒ¹é…å’Œå¸¸è§å˜ä½“åŒ¹é…
        for required in required_columns:
            matched = False
            
            # æ£€æŸ¥ç²¾ç¡®åŒ¹é…
            if required in available_columns:
                mapping[required] = required
                unmapped_available.remove(required)
                print(f"âœ… ç²¾ç¡®åŒ¹é…: {required} -> {required}")
                matched = True
                continue
            
            # æ£€æŸ¥å¸¸è§å˜ä½“
            if required in self.common_column_variants:
                variants = self.common_column_variants[required]
                for variant in variants:
                    if variant in available_columns:
                        mapping[required] = variant
                        unmapped_available.remove(variant)
                        print(f"âœ… å˜ä½“åŒ¹é…: {required} -> {variant}")
                        matched = True
                        break
            
            if not matched:
                unmapped_required.append(required)
        
        # ç¬¬äºŒè½®ï¼šæ¨¡ç³ŠåŒ¹é…
        if unmapped_required and unmapped_available:
            print(f"\nğŸ” è¿›è¡Œæ¨¡ç³ŠåŒ¹é…...")
            for required in unmapped_required:
                similar_columns = self.find_similar_columns(required, unmapped_available)
                
                if similar_columns:
                    best_match, similarity = similar_columns[0]
                    print(f"ğŸ” æ‰¾åˆ°ç›¸ä¼¼åˆ—å: {required} -> {best_match} (ç›¸ä¼¼åº¦: {similarity:.2f})")
                    
                    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç¡®è®¤æ˜ å°„
                    confirm = input(f"æ˜¯å¦å°† '{required}' æ˜ å°„åˆ° '{best_match}'ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
                    if confirm not in ['n', 'no', 'å¦']:
                        mapping[required] = best_match
                        unmapped_available.remove(best_match)
                        print(f"âœ… ç¡®è®¤æ˜ å°„: {required} -> {best_match}")
                    else:
                        print(f"âš ï¸  è·³è¿‡æ˜ å°„: {required}")
                else:
                    print(f"âŒ æœªæ‰¾åˆ°ä¸ '{required}' ç›¸ä¼¼çš„åˆ—å")
        
        # æ˜¾ç¤ºæ˜ å°„ç»“æœ
        if mapping:
            print(f"\nğŸ“‹ åˆ—åæ˜ å°„ç»“æœ:")
            for required, mapped in mapping.items():
                print(f"  {required} -> {mapped}")
        
        if unmapped_required:
            print(f"\nâš ï¸  æœªæ˜ å°„çš„åˆ—å: {unmapped_required}")
        
        return mapping
    
    def validate_required_columns(self, df: pd.DataFrame, required_columns: List[str]) -> Tuple[bool, List[str], Dict[str, str]]:
        """
        éªŒè¯å¿…éœ€çš„åˆ—åæ˜¯å¦å­˜åœ¨ï¼Œæ”¯æŒæ™ºèƒ½åŒ¹é…
        
        Args:
            df: æ•°æ®æ¡†
            required_columns: å¿…éœ€çš„åˆ—ååˆ—è¡¨
            
        Returns:
            (æ˜¯å¦éªŒè¯é€šè¿‡, ç¼ºå¤±çš„åˆ—ååˆ—è¡¨, åˆ—åæ˜ å°„å­—å…¸)
        """
        available_columns = list(df.columns)
        missing_columns = []
        column_mapping = {}
        
        if not self.enable_smart_matching:
            # ä¼ ç»Ÿä¸¥æ ¼åŒ¹é…
            for required in required_columns:
                if required not in available_columns:
                    missing_columns.append(required)
                else:
                    column_mapping[required] = required
        else:
            # æ™ºèƒ½åŒ¹é…
            column_mapping = self.smart_column_mapping(required_columns, available_columns)
            
            # æ£€æŸ¥å“ªäº›åˆ—åæ²¡æœ‰è¢«æ˜ å°„
            for required in required_columns:
                if required not in column_mapping:
                    missing_columns.append(required)
        
        return len(missing_columns) == 0, missing_columns, column_mapping
    
    def select_files(self, folder_path: str = ".") -> List[str]:
        """
        æ–‡ä»¶é€‰æ‹©åŠŸèƒ½
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•
            
        Returns:
            é€‰ä¸­çš„æ–‡ä»¶åˆ—è¡¨
        """
        print(f"\n=== æ­¥éª¤1: æ–‡ä»¶é€‰æ‹© ===")
        print(f"æ­£åœ¨æ‰«ææ–‡ä»¶å¤¹: {folder_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰Excelæ–‡ä»¶
        excel_patterns = ['*.xlsx', '*.xls']
        excel_files = []
        
        for pattern in excel_patterns:
            excel_files.extend(glob.glob(os.path.join(folder_path, pattern)))
        
        if not excel_files:
            print(f"âŒ åœ¨æ–‡ä»¶å¤¹ '{folder_path}' ä¸­æ²¡æœ‰æ‰¾åˆ°Excelæ–‡ä»¶")
            return []
        
        # æ˜¾ç¤ºæ‰¾åˆ°çš„æ–‡ä»¶
        print(f"\nâœ… æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶:")
        for i, file in enumerate(excel_files, 1):
            filename = os.path.basename(file)
            file_size = os.path.getsize(file) / 1024  # KB
            print(f"{i:2d}. {filename:<30} ({file_size:.1f} KB)")
        
        # ç”¨æˆ·é€‰æ‹©æ–‡ä»¶
        print(f"\nè¯·é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶:")
        print("ï¿½ï¿½ è¾“å…¥æ–‡ä»¶ç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2,3ï¼‰")
        print("ï¿½ï¿½ è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰æ–‡ä»¶")
        print("ğŸ“ è¾“å…¥ 'q' é€€å‡ºç¨‹åº")
        
        try:
            choice = input("\nè¯·é€‰æ‹©: ").strip().lower()
            
            if choice == 'q':
                print("ç¨‹åºé€€å‡º")
                return []
            elif choice == 'all':
                self.selected_files = excel_files
                print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(excel_files)} ä¸ªæ–‡ä»¶")
            else:
                # è§£æç”¨æˆ·é€‰æ‹©çš„æ–‡ä»¶ç¼–å·
                indices = [int(x.strip()) - 1 for x in choice.split(',')]
                self.selected_files = [excel_files[i] for i in indices if 0 <= i < len(excel_files)]
                
                if not self.selected_files:
                    print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆæ–‡ä»¶ï¼Œè¯·é‡æ–°é€‰æ‹©")
                    return self.select_files(folder_path)
                
                print(f"âœ… å·²é€‰æ‹© {len(self.selected_files)} ä¸ªæ–‡ä»¶:")
                for file in self.selected_files:
                    print(f"  ğŸ“„ {os.path.basename(file)}")
                
            return self.selected_files
            
        except (ValueError, IndexError) as e:
            print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {str(e)}ï¼Œè¯·é‡æ–°é€‰æ‹©")
            return self.select_files(folder_path)
    
    def get_field_list(self, files: List[str]) -> List[str]:
        """
        è·å–æ‰€æœ‰æ–‡ä»¶çš„å­—æ®µåˆ—è¡¨
        
        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            æ‰€æœ‰å­—æ®µçš„åˆ—è¡¨
        """
        print(f"\n=== æ­¥éª¤2: å­—æ®µåˆ†æ ===")
        all_fields = set()
        file_field_info = {}
        
        for file in files:
            try:
                df = pd.read_excel(file)
                file_fields = list(df.columns)
                
                # è¿‡æ»¤æ‰æ— æ•ˆå­—æ®µï¼ˆè¯´æ˜æ–‡å­—ã€Unnamedå­—æ®µç­‰ï¼‰
                valid_fields = []
                for field in file_fields:
                    # è·³è¿‡Unnamedå­—æ®µ
                    if field.startswith('Unnamed:'):
                        continue
                    # è·³è¿‡è¯´æ˜æ–‡å­—ï¼ˆé€šå¸¸åŒ…å«å¾ˆé•¿çš„æè¿°æ€§æ–‡å­—ï¼‰
                    if len(field) > 100:
                        continue
                    # è·³è¿‡ç©ºå­—æ®µ
                    if not field or field.strip() == '':
                        continue
                    # è·³è¿‡çº¯è¯´æ˜æ€§å­—æ®µ
                    if field in ['è¯´æ˜', 'è¯´æ˜æ–‡å­—', 'å¤‡æ³¨', 'æ³¨é‡Š']:
                        continue
                    # è·³è¿‡åŒ…å«è¯´æ˜å…³é”®è¯çš„å­—æ®µ
                    if any(keyword in field for keyword in ['è¯´æ˜', 'å¤‡æ³¨', 'æ³¨é‡Š', 'æ³¨æ„', 'æç¤º']):
                        continue
                    
                    # å¦‚æœå¯ç”¨è‡ªåŠ¨æ¸…ç†ï¼Œæ˜¾ç¤ºæ¸…ç†åçš„åˆ—å
                    if self.auto_clean_columns:
                        cleaned_field = self.clean_column_name(field)
                        if cleaned_field != field:
                            print(f"ğŸ“ åˆ—åæ¸…ç†: '{field}' -> '{cleaned_field}'")
                        valid_fields.append(cleaned_field)
                    else:
                        valid_fields.append(field)
                
                all_fields.update(valid_fields)
                file_field_info[os.path.basename(file)] = {
                    'field_count': len(valid_fields),
                    'fields': valid_fields
                }
                print(f"ğŸ“Š æ–‡ä»¶ '{os.path.basename(file)}' åŒ…å« {len(valid_fields)} ä¸ªæœ‰æ•ˆå­—æ®µ")
                
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
        
        # è®¡ç®—æ¯ä¸ªå­—æ®µçš„å‡ºç°æ¬¡æ•°å¹¶æ’åº
        field_occurrence = {}
        for field in all_fields:
            files_with_field = [f for f, info in file_field_info.items() if field in info['fields']]
            field_occurrence[field] = len(files_with_field)
        
        # æŒ‰å‡ºç°æ¬¡æ•°ä»é«˜åˆ°ä½æ’åº
        sorted_fields = sorted(field_occurrence.items(), key=lambda x: x[1], reverse=True)
        self.all_fields = [field for field, count in sorted_fields]
        
        print(f"\nâœ… æ€»å…±å‘ç° {len(self.all_fields)} ä¸ªä¸åŒæœ‰æ•ˆå­—æ®µ")
        
        return self.all_fields
    
    def analyze_field_supplement_situation(self, files: List[str], selected_fields: List[str]) -> Dict:
        """
        åˆ†æå­—æ®µè¡¥å……æƒ…å†µ
        
        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            selected_fields: ç”¨æˆ·é€‰æ‹©çš„å­—æ®µåˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        analysis_result = {
            'files_with_all_fields': [],  # åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µçš„æ–‡ä»¶
            'files_missing_fields': {},   # ç¼ºå°‘ç‰¹å®šå­—æ®µçš„æ–‡ä»¶ {field: [files]}
            'files_without_key_field': [], # ä¸åŒ…å«å…³é”®å­—æ®µï¼ˆå­¦å·ï¼‰çš„æ–‡ä»¶
            'total_files': len(files)
        }
        
        # åˆå§‹åŒ–ç¼ºå¤±å­—æ®µå­—å…¸
        for field in selected_fields:
            analysis_result['files_missing_fields'][field] = []
        
        print(f"\nğŸ” åˆ†æå­—æ®µè¡¥å……æƒ…å†µ...")
        
        for file in files:
            try:
                df = pd.read_excel(file)
                file_fields = self.get_file_fields(file)  # ä½¿ç”¨è¿‡æ»¤åçš„å­—æ®µ
                filename = os.path.basename(file)
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å­¦å·ï¼ˆä½œä¸ºå…³é”®å­—æ®µï¼‰
                has_student_id = any(id_field in file_fields for id_field in ['å­¦å·', '*å­¦å·'])
                
                if not has_student_id:
                    analysis_result['files_without_key_field'].append(file)
                    print(f"â„¹ï¸  {filename}: ä¸åŒ…å«å­¦å·")
                    continue
                
                # æ£€æŸ¥æ¯ä¸ªå¿…éœ€å­—æ®µ
                missing_fields = []
                for field in selected_fields:
                    # æ”¯æŒæ™ºèƒ½åŒ¹é…ï¼Œæ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
                    field_found = False
                    for col in df.columns:
                        if field in col or col in field:
                            field_found = True
                            break
                    
                    if not field_found:
                        missing_fields.append(field)
                        analysis_result['files_missing_fields'][field].append(file)
                
                if not missing_fields:
                    analysis_result['files_with_all_fields'].append(file)
                    print(f"âœ… {filename}: åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ")
                else:
                    missing_str = ', '.join(missing_fields)
                    print(f"âš ï¸  {filename}: ç¼ºå°‘å­—æ®µ {missing_str}")
                    
            except Exception as e:
                print(f"âŒ åˆ†ææ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
                analysis_result['files_without_key_field'].append(file)
        
        return analysis_result
    
    def build_field_mapping(self, files_with_all_fields: List[str], target_field: str, link_field: str = 'å­¦å·') -> Dict[str, str]:
        """
        æ„å»ºå…³è”å­—æ®µåˆ°ç›®æ ‡å­—æ®µçš„æ˜ å°„
        
        Args:
            files_with_all_fields: åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µçš„æ–‡ä»¶åˆ—è¡¨
            target_field: ç›®æ ‡å­—æ®µåç§°
            link_field: å…³è”å­—æ®µåç§°ï¼ˆé»˜è®¤å­¦å·ï¼‰
            
        Returns:
            å…³è”å­—æ®µåˆ°ç›®æ ‡å­—æ®µçš„æ˜ å°„å­—å…¸
        """
        if not files_with_all_fields:
            return {}
        
        print(f"\nğŸ”„ æ„å»º{link_field}åˆ°{target_field}çš„æ˜ å°„...")
        mapping = {}
        total_mappings = 0
        
        for file in files_with_all_fields:
            try:
                df = pd.read_excel(file)
                filename = os.path.basename(file)
                
                # ç¡®å®šå…³è”å­—æ®µåç§°
                link_field_name = None
                for col in df.columns:
                    if link_field in col or col in link_field:
                        link_field_name = col
                        break
                
                if not link_field_name:
                    print(f"âš ï¸  æ–‡ä»¶ '{filename}' ç¼ºå°‘{link_field}å­—æ®µï¼Œè·³è¿‡")
                    continue
                
                # ç¡®å®šç›®æ ‡å­—æ®µåç§°ï¼ˆæ”¯æŒæ™ºèƒ½åŒ¹é…ï¼‰
                target_field_name = None
                for col in df.columns:
                    if target_field in col or col in target_field:
                        target_field_name = col
                        break
                
                if not target_field_name:
                    print(f"âš ï¸  æ–‡ä»¶ '{filename}' ç¼ºå°‘{target_field}å­—æ®µï¼Œè·³è¿‡")
                    continue
                
                # æ„å»ºæ˜ å°„å…³ç³»
                file_mappings = 0
                for _, row in df.iterrows():
                    link_value = str(row[link_field_name]).strip()
                    target_value = str(row[target_field_name]).strip()
                    
                    # è·³è¿‡ç©ºå€¼
                    if pd.isna(link_value) or pd.isna(target_value) or link_value == '' or target_value == '':
                        continue
                    
                    # å¦‚æœå…³è”å€¼å·²å­˜åœ¨ï¼Œä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…
                    if link_value not in mapping:
                        mapping[link_value] = target_value
                        file_mappings += 1
                
                total_mappings += file_mappings
                print(f"ğŸ“Š {filename}: æ·»åŠ äº† {file_mappings} ä¸ªæ˜ å°„å…³ç³»")
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
                continue
        
        print(f"âœ… æ€»å…±æ„å»ºäº† {total_mappings} ä¸ª{link_field}-{target_field}æ˜ å°„å…³ç³»")
        return mapping
    
    def configure_field_supplement(self, analysis_result: Dict, selected_fields: List[str]) -> Tuple[bool, Dict[str, str], str]:
        """
        é…ç½®å­—æ®µè¡¥å……åŠŸèƒ½
        
        Args:
            analysis_result: åˆ†æç»“æœ
            selected_fields: ç”¨æˆ·é€‰æ‹©çš„å­—æ®µåˆ—è¡¨
            
        Returns:
            (æ˜¯å¦å¯ç”¨è¡¥å……åŠŸèƒ½, é»˜è®¤å€¼å­—å…¸)
        """
        files_with_all_fields = analysis_result['files_with_all_fields']
        files_missing_fields = analysis_result['files_missing_fields']
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å­—æ®µ
        missing_fields = [field for field, files in files_missing_fields.items() if files]
        
        if not missing_fields:
            print(f"\nâœ… æ‰€æœ‰æ–‡ä»¶éƒ½åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µï¼Œæ— éœ€è¡¥å……")
            return False, {}
        
        if not files_with_all_fields:
            print(f"\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µçš„æ–‡ä»¶ï¼Œæ— æ³•æ„å»ºæ˜ å°„å…³ç³»")
            print(f"ğŸ“ å»ºè®®ï¼šè‡³å°‘éœ€è¦ä¸€ä¸ªåŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µçš„æ–‡ä»¶æ¥æ„å»ºæ˜ å°„å…³ç³»")
            return False, ""
        
        print(f"\n=== å­—æ®µè¡¥å……é…ç½® ===")
        print(f"ğŸ“Š åˆ†æç»“æœ:")
        print(f"  â€¢ åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µçš„æ–‡ä»¶: {len(files_with_all_fields)} ä¸ª")
        print(f"  â€¢ ä¸åŒ…å«å­¦å·çš„æ–‡ä»¶: {len(analysis_result['files_without_key_field'])} ä¸ª")
        
        for field in missing_fields:
            missing_files = files_missing_fields[field]
            print(f"  â€¢ ç¼ºå°‘{field}å­—æ®µçš„æ–‡ä»¶: {len(missing_files)} ä¸ª")
        
        print(f"\nğŸ¤” æ£€æµ‹åˆ°éƒ¨åˆ†æ–‡ä»¶ç¼ºå°‘å­—æ®µï¼Œæ˜¯å¦å¯ç”¨å­—æ®µè¡¥å……åŠŸèƒ½ï¼Ÿ")
        print(f"ğŸ“ è¡¥å……åŠŸèƒ½å°†ä»å…¶ä»–æ–‡ä»¶ä¸­æ ¹æ®è¾“å…¥å­—æ®µåŒ¹é…è·å–ç¼ºå¤±å­—æ®µ")
        
        choice = input("è¯·é€‰æ‹© (y/nï¼Œé»˜è®¤y): ").strip().lower()
        enable_supplement = choice not in ['n', 'no', 'å¦']
        
        if not enable_supplement:
            print(f"âœ… å·²é€‰æ‹©ä¸å¯ç”¨è¡¥å……åŠŸèƒ½")
            return False, {}, 'å­¦å·'
        
        # é€‰æ‹©å…³è”å­—æ®µ
        print(f"\nğŸ”— è¯·é€‰æ‹©ç”¨äºåŒ¹é…çš„å…³è”å­—æ®µ:")
        print(f"ğŸ“‹ å¯ç”¨å­—æ®µ: {', '.join(selected_fields)}")
        print(f"ğŸ“ è¾“å…¥å­—æ®µåç§°ï¼ˆå¦‚ï¼šå­¦å·ã€å­¦ç”Ÿå§“åç­‰ï¼‰")
        print(f"ğŸ“ å»ºè®®é€‰æ‹©åœ¨æ‰€æœ‰æ–‡ä»¶ä¸­éƒ½å­˜åœ¨ä¸”å”¯ä¸€æ€§è¾ƒå¥½çš„å­—æ®µä½œä¸ºå…³è”å­—æ®µ")
        
        link_field = input("å…³è”å­—æ®µï¼ˆé»˜è®¤ï¼šå­¦å·ï¼‰: ").strip()
        if not link_field:
            link_field = 'å­¦å·'
        
        # éªŒè¯å…³è”å­—æ®µæ˜¯å¦åœ¨é€‰ä¸­å­—æ®µä¸­
        if link_field not in selected_fields:
            print(f"âš ï¸  å…³è”å­—æ®µ '{link_field}' ä¸åœ¨é€‰ä¸­å­—æ®µä¸­ï¼Œå°†ä½¿ç”¨é»˜è®¤å­—æ®µ 'å­¦å·'")
            link_field = 'å­¦å·'
        
        print(f"âœ… å·²è®¾ç½®å…³è”å­—æ®µ: {link_field}")
        
        # ä¸ºæ¯ä¸ªç¼ºå¤±å­—æ®µè®¾ç½®é»˜è®¤å€¼
        default_values = {}
        for field in missing_fields:
            print(f"\nğŸ“ è¯·è¾“å…¥{field}å­—æ®µæœªæ‰¾åˆ°åŒ¹é…æ—¶ä½¿ç”¨çš„é»˜è®¤å€¼")
            default_value = input(f"é»˜è®¤å€¼ï¼ˆé»˜è®¤ï¼šæœªçŸ¥{field}ï¼‰: ").strip()
            if not default_value:
                default_value = f"æœªçŸ¥{field}"
            default_values[field] = default_value
            print(f"âœ… å·²è®¾ç½®{field}é»˜è®¤å€¼: {default_value}")
        
        return True, default_values, link_field
    
    def supplement_fields(self, df: pd.DataFrame, field_mappings: Dict[str, Dict[str, str]], 
                         default_values: Dict[str, str], link_field: str = 'å­¦å·') -> pd.DataFrame:
        """
        ä¸ºæ•°æ®æ¡†è¡¥å……ç¼ºå¤±å­—æ®µ
        
        Args:
            df: æ•°æ®æ¡†
            field_mappings: å­—æ®µæ˜ å°„å­—å…¸ {field_name: {student_id: value}}
            default_values: é»˜è®¤å€¼å­—å…¸ {field_name: default_value}
            
        Returns:
            è¡¥å……åçš„æ•°æ®æ¡†
        """
        # ç¡®å®šå…³è”å­—æ®µåç§°
        link_field_name = None
        for col in df.columns:
            if link_field in col or col in link_field:
                link_field_name = col
                break
        
        if not link_field_name:
            print(f"âš ï¸  æ•°æ®æ¡†ä¸åŒ…å«å…³è”å­—æ®µ '{link_field}'ï¼Œæ— æ³•è¡¥å……å­—æ®µ")
            return df
        
        # ä¸ºæ¯ä¸ªç¼ºå¤±å­—æ®µè¿›è¡Œè¡¥å……
        for field_name, mapping in field_mappings.items():
            # ç¡®å®šç›®æ ‡å­—æ®µåç§°
            target_field_name = None
            for col in df.columns:
                if field_name in col or col in field_name:
                    target_field_name = col
                    break
            
            # å¦‚æœå­—æ®µä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
            if not target_field_name:
                target_field_name = field_name
                df[target_field_name] = default_values.get(field_name, f"æœªçŸ¥{field_name}")
                print(f"ğŸ“ åˆ›å»ºæ–°çš„{field_name}å­—æ®µ")
            else:
                # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºå€¼éœ€è¦è¡¥å……
                missing_values = df[target_field_name].isna() | (df[target_field_name].astype(str).str.strip() == '')
                if not missing_values.any():
                    print(f"âœ… {field_name}å­—æ®µå·²å®Œæ•´ï¼Œæ— éœ€è¡¥å……")
                    continue
                else:
                    missing_count = missing_values.sum()
                    print(f"ğŸ“Š å‘ç° {missing_count} ä¸ªç©ºçš„{field_name}ï¼Œå¼€å§‹è¡¥å……...")
            
            # è¡¥å……å­—æ®µå€¼
            supplemented_count = 0
            successful_matches = 0
            default_used = 0
            
            for idx, row in df.iterrows():
                link_value = str(row[link_field_name]).strip()
                
                # è·³è¿‡ç©ºå…³è”å€¼
                if pd.isna(link_value) or link_value == '':
                    continue
                
                # æ£€æŸ¥å½“å‰å­—æ®µå€¼æ˜¯å¦ä¸ºç©º
                current_value = str(row[target_field_name]).strip()
                if pd.isna(current_value) or current_value == '' or current_value == default_values.get(field_name, f"æœªçŸ¥{field_name}"):
                    # å°è¯•ä»æ˜ å°„ä¸­è·å–å€¼ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
                    if link_value in mapping:
                        df.at[idx, target_field_name] = mapping[link_value]
                        successful_matches += 1
                    else:
                        # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆæ”¯æŒä¸€ä½å­—ç¬¦çš„å·®å¼‚ï¼‰
                        matched_value = None
                        for map_key, map_value in mapping.items():
                            # å¦‚æœå…³è”å€¼é•¿åº¦ç›¸åŒï¼Œå°è¯•ä¸€ä½å­—ç¬¦çš„æ¨¡ç³ŠåŒ¹é…
                            if len(link_value) == len(map_key):
                                # è®¡ç®—ä¸åŒå­—ç¬¦çš„æ•°é‡
                                diff_count = sum(1 for a, b in zip(link_value, map_key) if a != b)
                                if diff_count <= 1:  # å…è®¸ä¸€ä½å­—ç¬¦çš„å·®å¼‚
                                    matched_value = map_value
                                    break
                        
                        if matched_value:
                            df.at[idx, target_field_name] = matched_value
                            successful_matches += 1
                        else:
                            df.at[idx, target_field_name] = default_values.get(field_name, f"æœªçŸ¥{field_name}")
                            default_used += 1
                    supplemented_count += 1
            
            if supplemented_count > 0:
                print(f"ğŸ“Š {field_name}è¡¥å……ç»Ÿè®¡: æˆåŠŸåŒ¹é… {successful_matches} ä¸ªï¼Œä½¿ç”¨é»˜è®¤å€¼ {default_used} ä¸ª")
        
        return df
    
    def get_file_fields(self, file_path: str) -> List[str]:
        """
        è·å–å•ä¸ªæ–‡ä»¶çš„å­—æ®µåˆ—è¡¨
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            å­—æ®µåˆ—è¡¨
        """
        try:
            df = pd.read_excel(file_path)
            file_fields = list(df.columns)
            
            # è¿‡æ»¤æ‰æ— æ•ˆå­—æ®µï¼ˆè¯´æ˜æ–‡å­—ã€Unnamedå­—æ®µç­‰ï¼‰
            valid_fields = []
            for field in file_fields:
                # è·³è¿‡Unnamedå­—æ®µ
                if field.startswith('Unnamed:'):
                    continue
                # è·³è¿‡è¯´æ˜æ–‡å­—ï¼ˆé€šå¸¸åŒ…å«å¾ˆé•¿çš„æè¿°æ€§æ–‡å­—ï¼‰
                if len(field) > 100:
                    continue
                # è·³è¿‡ç©ºå­—æ®µ
                if not field or field.strip() == '':
                    continue
                valid_fields.append(field)
            
            return valid_fields
        except Exception as e:
            return []
    
    def clean_column_name(self, column_name: str) -> str:
        """
        æ¸…ç†åˆ—åï¼Œå»é™¤ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
        
        Args:
            column_name: åŸå§‹åˆ—å
            
        Returns:
            æ¸…ç†åçš„åˆ—å
        """
        if not self.auto_clean_columns:
            return column_name
        
        # å»é™¤é¦–å°¾ç©ºæ ¼
        cleaned = column_name.strip()
        
        # å»é™¤å¤šä½™çš„ç©ºæ ¼
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰
        cleaned = re.sub(r'[^\w\s\u4e00-\u9fff]', '', cleaned)
        
        # å†æ¬¡å»é™¤ç©ºæ ¼
        cleaned = cleaned.strip()
        
        return cleaned
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦
        
        Args:
            str1: å­—ç¬¦ä¸²1
            str2: å­—ç¬¦ä¸²2
            
        Returns:
            ç›¸ä¼¼åº¦ (0-1)
        """
        # ä½¿ç”¨SequenceMatcherè®¡ç®—ç›¸ä¼¼åº¦
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def find_similar_columns(self, target_column: str, available_columns: List[str]) -> List[Tuple[str, float]]:
        """
        æŸ¥æ‰¾ä¸ç›®æ ‡åˆ—åç›¸ä¼¼çš„åˆ—å
        
        Args:
            target_column: ç›®æ ‡åˆ—å
            available_columns: å¯ç”¨åˆ—ååˆ—è¡¨
            
        Returns:
            ç›¸ä¼¼åˆ—ååˆ—è¡¨ï¼ŒåŒ…å«ç›¸ä¼¼åº¦
        """
        similar_columns = []
        cleaned_target = self.clean_column_name(target_column)
        
        for column in available_columns:
            cleaned_column = self.clean_column_name(column)
            
            # ç²¾ç¡®åŒ¹é…
            if cleaned_target == cleaned_column:
                similar_columns.append((column, 1.0))
                continue
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = self.calculate_similarity(cleaned_target, cleaned_column)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§å˜ä½“
            for standard_name, variants in self.common_column_variants.items():
                if cleaned_target in variants and cleaned_column in variants:
                    similarity = max(similarity, 0.9)  # æé«˜å˜ä½“çš„ç›¸ä¼¼åº¦
                    break
            
            if similarity >= self.similarity_threshold:
                similar_columns.append((column, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similar_columns.sort(key=lambda x: x[1], reverse=True)
        return similar_columns
    
    def smart_column_mapping(self, required_columns: List[str], available_columns: List[str]) -> Dict[str, str]:
        """
        æ™ºèƒ½åˆ—åæ˜ å°„
        
        Args:
            required_columns: éœ€è¦çš„åˆ—å
            available_columns: å¯ç”¨çš„åˆ—å
            
        Returns:
            åˆ—åæ˜ å°„å­—å…¸
        """
        mapping = {}
        unmapped_required = []
        unmapped_available = available_columns.copy()
        
        print(f"\nğŸ” æ™ºèƒ½åˆ—åæ˜ å°„åˆ†æ...")
        print(f"ğŸ“‹ éœ€è¦çš„åˆ—å: {required_columns}")
        print(f"ğŸ“‹ å¯ç”¨çš„åˆ—å: {available_columns}")
        
        # ç¬¬ä¸€è½®ï¼šç²¾ç¡®åŒ¹é…å’Œå¸¸è§å˜ä½“åŒ¹é…
        for required in required_columns:
            matched = False
            
            # æ£€æŸ¥ç²¾ç¡®åŒ¹é…
            if required in available_columns:
                mapping[required] = required
                unmapped_available.remove(required)
                print(f"âœ… ç²¾ç¡®åŒ¹é…: {required} -> {required}")
                matched = True
                continue
            
            # æ£€æŸ¥å¸¸è§å˜ä½“
            if required in self.common_column_variants:
                variants = self.common_column_variants[required]
                for variant in variants:
                    if variant in available_columns:
                        mapping[required] = variant
                        unmapped_available.remove(variant)
                        print(f"âœ… å˜ä½“åŒ¹é…: {required} -> {variant}")
                        matched = True
                        break
            
            if not matched:
                unmapped_required.append(required)
        
        # ç¬¬äºŒè½®ï¼šæ¨¡ç³ŠåŒ¹é…
        if unmapped_required and unmapped_available:
            print(f"\nğŸ” è¿›è¡Œæ¨¡ç³ŠåŒ¹é…...")
            for required in unmapped_required:
                similar_columns = self.find_similar_columns(required, unmapped_available)
                
                if similar_columns:
                    best_match, similarity = similar_columns[0]
                    print(f"ğŸ” æ‰¾åˆ°ç›¸ä¼¼åˆ—å: {required} -> {best_match} (ç›¸ä¼¼åº¦: {similarity:.2f})")
                    
                    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç¡®è®¤æ˜ å°„
                    confirm = input(f"æ˜¯å¦å°† '{required}' æ˜ å°„åˆ° '{best_match}'ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
                    if confirm not in ['n', 'no', 'å¦']:
                        mapping[required] = best_match
                        unmapped_available.remove(best_match)
                        print(f"âœ… ç¡®è®¤æ˜ å°„: {required} -> {best_match}")
                    else:
                        print(f"âš ï¸  è·³è¿‡æ˜ å°„: {required}")
                else:
                    print(f"âŒ æœªæ‰¾åˆ°ä¸ '{required}' ç›¸ä¼¼çš„åˆ—å")
        
        # æ˜¾ç¤ºæ˜ å°„ç»“æœ
        if mapping:
            print(f"\nğŸ“‹ åˆ—åæ˜ å°„ç»“æœ:")
            for required, mapped in mapping.items():
                print(f"  {required} -> {mapped}")
        
        if unmapped_required:
            print(f"\nâš ï¸  æœªæ˜ å°„çš„åˆ—å: {unmapped_required}")
        
        return mapping
    
    def validate_required_columns(self, df: pd.DataFrame, required_columns: List[str]) -> Tuple[bool, List[str], Dict[str, str]]:
        """
        éªŒè¯å¿…éœ€çš„åˆ—åæ˜¯å¦å­˜åœ¨ï¼Œæ”¯æŒæ™ºèƒ½åŒ¹é…
        
        Args:
            df: æ•°æ®æ¡†
            required_columns: å¿…éœ€çš„åˆ—ååˆ—è¡¨
            
        Returns:
            (æ˜¯å¦éªŒè¯é€šè¿‡, ç¼ºå¤±çš„åˆ—ååˆ—è¡¨, åˆ—åæ˜ å°„å­—å…¸)
        """
        available_columns = list(df.columns)
        missing_columns = []
        column_mapping = {}
        
        if not self.enable_smart_matching:
            # ä¼ ç»Ÿä¸¥æ ¼åŒ¹é…
            for required in required_columns:
                if required not in available_columns:
                    missing_columns.append(required)
                else:
                    column_mapping[required] = required
        else:
            # æ™ºèƒ½åŒ¹é…
            column_mapping = self.smart_column_mapping(required_columns, available_columns)
            
            # æ£€æŸ¥å“ªäº›åˆ—åæ²¡æœ‰è¢«æ˜ å°„
            for required in required_columns:
                if required not in column_mapping:
                    missing_columns.append(required)
        
        return len(missing_columns) == 0, missing_columns, column_mapping
    
    def wildcard_match(self, pattern: str, text: str) -> bool:
        """
        é€šé…ç¬¦åŒ¹é…å‡½æ•°ï¼Œæ”¯æŒ * ä»£è¡¨ä»»æ„ä¸€ä¸ªå­—ç¬¦
        
        Args:
            pattern: åŒ…å« * çš„æ¨¡å¼å­—ç¬¦ä¸²
            text: è¦åŒ¹é…çš„æ–‡æœ¬
            
        Returns:
            æ˜¯å¦åŒ¹é…
        """
        if '*' not in pattern:
            return pattern == text
        
        # å°† * è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼çš„ . å­—ç¬¦
        regex_pattern = pattern.replace('*', '.')
        import re
        return bool(re.match(regex_pattern, text))
    
    def flexible_wildcard_match(self, pattern: str, text: str) -> bool:
        """
        çµæ´»çš„é€šé…ç¬¦åŒ¹é…å‡½æ•°ï¼Œæ”¯æŒ * ä»£è¡¨ä»»æ„å­—ç¬¦åºåˆ—
        
        Args:
            pattern: åŒ…å« * çš„æ¨¡å¼å­—ç¬¦ä¸²
            text: è¦åŒ¹é…çš„æ–‡æœ¬
            
        Returns:
            æ˜¯å¦åŒ¹é…
        """
        if '*' not in pattern:
            return pattern == text
        
        # å°† * è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼çš„ .* å­—ç¬¦ï¼ˆåŒ¹é…ä»»æ„å­—ç¬¦åºåˆ—ï¼‰
        regex_pattern = pattern.replace('*', '.*')
        import re
        return bool(re.match(regex_pattern, text))
    
    def enhanced_field_matching(self, pattern: str, all_fields: List[str]) -> Tuple[List[str], str]:
        """
        å¢å¼ºçš„å­—æ®µåŒ¹é…å‡½æ•°ï¼Œæ”¯æŒå¤šç§åŒ¹é…æ–¹å¼
        
        Args:
            pattern: åŒ¹é…æ¨¡å¼
            all_fields: æ‰€æœ‰å¯ç”¨å­—æ®µåˆ—è¡¨
            
        Returns:
            (åŒ¹é…çš„å­—æ®µåˆ—è¡¨, åŒ¹é…ç±»å‹æè¿°)
        """
        # 1. ç²¾ç¡®åŒ¹é…
        if pattern in all_fields:
            return [pattern], "ç²¾ç¡®åŒ¹é…"
        
        # 2. é€šé…ç¬¦åŒ¹é…
        if '*' in pattern:
            matched_fields = self.find_matching_fields(pattern, all_fields)
            if matched_fields:
                return matched_fields, "é€šé…ç¬¦åŒ¹é…"
        
        # 3. åŒ…å«åŒ¹é…ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰
        matched_fields = [field for field in all_fields if pattern.lower() in field.lower()]
        if matched_fields:
            return matched_fields, "åŒ…å«åŒ¹é…"
        
        # 4. æ— åŒ¹é…
        return [], "æ— åŒ¹é…"
    
    def find_matching_fields(self, pattern: str, all_fields: List[str]) -> List[str]:
        """
        æ ¹æ®é€šé…ç¬¦æ¨¡å¼æŸ¥æ‰¾åŒ¹é…çš„å­—æ®µ
        
        Args:
            pattern: åŒ…å« * çš„æ¨¡å¼å­—ç¬¦ä¸²
            all_fields: æ‰€æœ‰å¯ç”¨å­—æ®µåˆ—è¡¨
            
        Returns:
            åŒ¹é…çš„å­—æ®µåˆ—è¡¨
        """
        if '*' not in pattern:
            # ç²¾ç¡®åŒ¹é…
            return [field for field in all_fields if field == pattern]
        
        # é€šé…ç¬¦åŒ¹é…
        matched_fields = []
        for field in all_fields:
            if self.flexible_wildcard_match(pattern, field):
                matched_fields.append(field)
        
        return matched_fields
    
    def select_fields(self, all_fields: List[str]) -> List[str]:
        """
        å­—æ®µé€‰æ‹©åŠŸèƒ½
        
        Args:
            all_fields: æ‰€æœ‰å¯ç”¨å­—æ®µåˆ—è¡¨
            
        Returns:
            é€‰ä¸­çš„å­—æ®µåˆ—è¡¨
        """
        print(f"\n=== æ­¥éª¤3: å­—æ®µé€‰æ‹© ===")
        
        # è¯¢é—®æ˜¯å¦æ˜¾ç¤ºå­—æ®µå‡ºç°æ¬¡æ•°
        print("ğŸ¤” æ˜¯å¦æ˜¾ç¤ºå­—æ®µå‡ºç°æ¬¡æ•°ï¼Ÿ")
        show_occurrence = input("è¯·é€‰æ‹© (y/nï¼Œé»˜è®¤y): ").strip().lower()
        show_occurrence = show_occurrence not in ['n', 'no', 'å¦']
        
        if show_occurrence:
            print("ğŸ“‹ å¯ç”¨å­—æ®µåˆ—è¡¨ï¼ˆæŒ‰å‡ºç°æ¬¡æ•°æ’åºï¼‰:")
        else:
            print("ğŸ“‹ å¯ç”¨å­—æ®µåˆ—è¡¨:")
        
        # åˆ†é¡µæ˜¾ç¤ºå­—æ®µ
        page_size = 10
        total_pages = (len(all_fields) + page_size - 1) // page_size
        
        for page in range(total_pages):
            start_idx = page * page_size
            end_idx = min(start_idx + page_size, len(all_fields))
            
            print(f"\n--- ç¬¬ {page + 1}/{total_pages} é¡µ ---")
            for i in range(start_idx, end_idx):
                field = all_fields[i]
                if show_occurrence:
                    # è®¡ç®—è¯¥å­—æ®µçš„å‡ºç°æ¬¡æ•°
                    occurrence_count = sum(1 for f in self.selected_files if field in self.get_file_fields(f))
                    print(f"{i + 1:2d}. {field:<25} (å‡ºç°åœ¨ {occurrence_count} ä¸ªæ–‡ä»¶ä¸­)")
                else:
                    print(f"{i + 1:2d}. {field}")
        
        print(f"\nè¯·é€‰æ‹©è¦å¯¼å…¥çš„å­—æ®µ:")
        print("ğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2,3ï¼‰")
        print("ğŸ“ è¾“å…¥å­—æ®µåç§°ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼šå­¦å·,å­¦ç”Ÿå§“åï¼‰")
        print("ğŸ“ æ”¯æŒé€šé…ç¬¦åŒ¹é…ï¼ˆ*ä»£è¡¨ä»»æ„ä¸€ä¸ªå­—ç¬¦ï¼Œå¦‚ï¼š*å­¦å·,å­¦*å·ï¼‰")
        print("ğŸ“ æ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚ï¼šå­¦å· å¯åŒ¹é… å­¦ç”Ÿå­¦å·ã€å­¦å·ä¿¡æ¯ç­‰ï¼‰")
        print("ğŸ“ è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰å­—æ®µ")
        print("ğŸ“ è¾“å…¥ 'page 1' æŸ¥çœ‹ç¬¬1é¡µï¼ˆå¯æ›¿æ¢é¡µç ï¼‰")
        
        try:
            choice = input("\nè¯·é€‰æ‹©: ").strip()
            
            if choice.startswith('page '):
                try:
                    page_num = int(choice.split()[1]) - 1
                    if 0 <= page_num < total_pages:
                        print(f"\n--- ç¬¬ {page_num + 1}/{total_pages} é¡µ ---")
                        start_idx = page_num * page_size
                        end_idx = min(start_idx + page_size, len(all_fields))
                        for i in range(start_idx, end_idx):
                            field = all_fields[i]
                            print(f"{i + 1:2d}. {field}")
                        return self.select_fields(all_fields)
                    else:
                        print("âŒ é¡µç è¶…å‡ºèŒƒå›´")
                        return self.select_fields(all_fields)
                except:
                    print("âŒ é¡µç æ ¼å¼é”™è¯¯")
                    return self.select_fields(all_fields)
            
            elif choice.lower() == 'all':
                self.selected_fields = all_fields
                print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(all_fields)} ä¸ªå­—æ®µ")
            else:
                # è§£æç”¨æˆ·é€‰æ‹©
                selected_items = [item.strip() for item in choice.split(',')]
                self.selected_fields = []
                
                for item in selected_items:
                    # å°è¯•ä½œä¸ºæ•°å­—å¤„ç†
                    try:
                        index = int(item) - 1
                        if 0 <= index < len(all_fields):
                            self.selected_fields.append(all_fields[index])
                        else:
                            print(f"âš ï¸  å­—æ®µç¼–å· {item} è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡")
                    except ValueError:
                        # ä½¿ç”¨å¢å¼ºçš„å­—æ®µåŒ¹é…å‡½æ•°
                        matched_fields, match_type = self.enhanced_field_matching(item, all_fields)
                        
                        if len(matched_fields) == 1:
                            # å•ä¸ªåŒ¹é…ï¼Œç›´æ¥æ·»åŠ 
                            self.selected_fields.append(matched_fields[0])
                            if match_type != "ç²¾ç¡®åŒ¹é…":
                                print(f"ğŸ“ {match_type}å­—æ®µ: {item} -> {matched_fields[0]}")
                        elif len(matched_fields) > 1:
                            # å¤šä¸ªåŒ¹é…ï¼Œè¯¢é—®ç”¨æˆ·
                            print(f"\nğŸ” {match_type} '{item}' åŒ¹é…åˆ° {len(matched_fields)} ä¸ªå­—æ®µ:")
                            for i, field in enumerate(matched_fields, 1):
                                print(f"  {i}. {field}")
                            
                            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä½¿ç”¨è¿™äº›åŒ¹é…çš„å­—æ®µ
                            print(f"\nğŸ¤” æ˜¯å¦ä½¿ç”¨è¿™äº›åŒ¹é…çš„å­—æ®µï¼Ÿ")
                            print(f"ğŸ“ è¾“å…¥ 'y' ä½¿ç”¨æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            print(f"ğŸ“ è¾“å…¥ 'n' è·³è¿‡æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            print(f"ğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼ˆå¦‚ï¼š1,3ï¼‰é€‰æ‹©ç‰¹å®šå­—æ®µ")
                            use_choice = input(f"\nè¯·é€‰æ‹©: ").strip().lower()
                            
                            if use_choice in ['y', 'yes', 'æ˜¯']:
                                self.selected_fields.extend(matched_fields)
                                print(f"âœ… å·²æ·»åŠ  {len(matched_fields)} ä¸ªåŒ¹é…å­—æ®µ")
                            elif use_choice in ['n', 'no', 'å¦']:
                                print(f"âš ï¸  è·³è¿‡ '{item}' çš„æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            else:
                                # ç”¨æˆ·é€‰æ‹©äº†ç‰¹å®šå­—æ®µç¼–å·
                                try:
                                    selected_indices = [int(x.strip()) - 1 for x in use_choice.split(',')]
                                    selected_fields = [matched_fields[i] for i in selected_indices if 0 <= i < len(matched_fields)]
                                    if selected_fields:
                                        self.selected_fields.extend(selected_fields)
                                        print(f"âœ… å·²æ·»åŠ  {len(selected_fields)} ä¸ªé€‰å®šå­—æ®µ")
                                    else:
                                        print(f"âš ï¸  æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè·³è¿‡")
                                except (ValueError, IndexError):
                                    print(f"âš ï¸  è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡æ‰€æœ‰åŒ¹é…å­—æ®µ")
                        else:
                            # æ— åŒ¹é…
                            print(f"âš ï¸  æœªæ‰¾åˆ°åŒ¹é…å­—æ®µ '{item}'ï¼Œè·³è¿‡")
                
                if not self.selected_fields:
                    print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè¯·é‡æ–°é€‰æ‹©")
                    return self.select_fields(all_fields)
                
                # å»é‡å¹¶ä¿æŒé¡ºåº
                seen = set()
                unique_fields = []
                for field in self.selected_fields:
                    if field not in seen:
                        seen.add(field)
                        unique_fields.append(field)
                self.selected_fields = unique_fields
                
                print(f"âœ… å·²é€‰æ‹© {len(self.selected_fields)} ä¸ªå­—æ®µ:")
                for field in self.selected_fields:
                    print(f"  ğŸ“‹ {field}")
                
            return self.selected_fields
            
        except Exception as e:
            print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {str(e)}ï¼Œè¯·é‡æ–°é€‰æ‹©")
            return self.select_fields(all_fields)
    
    def configure_deduplication(self) -> Tuple[bool, List[str]]:
        """
        å»é‡é…ç½®ï¼šè¿”å›(æ˜¯å¦å»é‡, å»é‡å­—æ®µåˆ—è¡¨)
        
        Returns:
            (æ˜¯å¦å»é‡, å»é‡å­—æ®µåˆ—è¡¨)
        """
        print(f"\n=== æ­¥éª¤4: å»é‡é…ç½® ===")
        
        # è¯¢é—®æ˜¯å¦éœ€è¦å»é‡
        print("ğŸ¤” æ˜¯å¦éœ€è¦å»é‡ï¼Ÿ")
        print("ğŸ“ å»é‡å°†åˆ é™¤é‡å¤çš„è®°å½•ï¼Œä¿ç•™ç¬¬ä¸€æ¡")
        dedup_choice = input("è¯·é€‰æ‹© (y/nï¼Œé»˜è®¤n): ").strip().lower()
        self.deduplicate = dedup_choice in ['y', 'yes', 'æ˜¯']
        
        if not self.deduplicate:
            print("âœ… å·²é€‰æ‹©ä¸å»é‡ï¼Œå°†ä¿ç•™æ‰€æœ‰è®°å½•")
            return False, []
        
        # å¦‚æœå»é‡ï¼Œé€‰æ‹©å»é‡å­—æ®µ
        print(f"\nğŸ“‹ è¯·é€‰æ‹©å»é‡å­—æ®µï¼ˆåŸºäºè¿™äº›å­—æ®µçš„ç»„åˆæ¥åˆ¤æ–­é‡å¤ï¼‰:")
        print("å¯ç”¨å­—æ®µåˆ—è¡¨:")
        for i, field in enumerate(self.selected_fields, 1):
            print(f"{i:2d}. {field}")
        
        print(f"\nğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2ï¼‰")
        print(f"ğŸ“ è¾“å…¥å­—æ®µåç§°ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼šå­¦å·,å­¦ç”Ÿå§“åï¼‰")
        print(f"ğŸ“ æ”¯æŒé€šé…ç¬¦åŒ¹é…ï¼ˆ*ä»£è¡¨ä»»æ„ä¸€ä¸ªå­—ç¬¦ï¼Œå¦‚ï¼š*å­¦å·,å­¦*å·ï¼‰")
        print(f"ğŸ“ æ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚ï¼šå­¦å· å¯åŒ¹é… å­¦ç”Ÿå­¦å·ã€å­¦å·ä¿¡æ¯ç­‰ï¼‰")
        print(f"ğŸ“ è¾“å…¥ 'all' ä½¿ç”¨æ‰€æœ‰é€‰ä¸­å­—æ®µè¿›è¡Œå»é‡")
        print(f"ğŸ“ è¾“å…¥ 'single 1' åªä½¿ç”¨ç¬¬1ä¸ªå­—æ®µå»é‡")
        
        try:
            choice = input("\nè¯·é€‰æ‹©å»é‡å­—æ®µ: ").strip().lower()
            
            if choice.lower() == 'all':
                self.dedup_fields = self.selected_fields.copy()
                print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(self.dedup_fields)} ä¸ªå­—æ®µè¿›è¡Œå»é‡")
            elif choice.startswith('single '):
                try:
                    field_idx = int(choice.split()[1]) - 1
                    if 0 <= field_idx < len(self.selected_fields):
                        self.dedup_fields = [self.selected_fields[field_idx]]
                        print(f"âœ… å·²é€‰æ‹©å•ä¸ªå­—æ®µè¿›è¡Œå»é‡: {self.dedup_fields[0]}")
                    else:
                        print("âŒ å­—æ®µç¼–å·è¶…å‡ºèŒƒå›´")
                        return self.configure_deduplication()
                except:
                    print("âŒ å­—æ®µç¼–å·æ ¼å¼é”™è¯¯")
                    return self.configure_deduplication()
            else:
                # è§£æç”¨æˆ·é€‰æ‹©
                selected_items = [item.strip() for item in choice.split(',')]
                self.dedup_fields = []
                
                for item in selected_items:
                    # å°è¯•ä½œä¸ºæ•°å­—å¤„ç†
                    try:
                        index = int(item) - 1
                        if 0 <= index < len(self.selected_fields):
                            self.dedup_fields.append(self.selected_fields[index])
                        else:
                            print(f"âš ï¸  å­—æ®µç¼–å· {item} è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡")
                    except ValueError:
                        # ä½¿ç”¨å¢å¼ºçš„å­—æ®µåŒ¹é…å‡½æ•°
                        matched_fields, match_type = self.enhanced_field_matching(item, self.selected_fields)
                        
                        if len(matched_fields) == 1:
                            # å•ä¸ªåŒ¹é…ï¼Œç›´æ¥æ·»åŠ 
                            self.dedup_fields.append(matched_fields[0])
                            if match_type != "ç²¾ç¡®åŒ¹é…":
                                print(f"ğŸ“ {match_type}å­—æ®µ: {item} -> {matched_fields[0]}")
                        elif len(matched_fields) > 1:
                            # å¤šä¸ªåŒ¹é…ï¼Œè¯¢é—®ç”¨æˆ·
                            print(f"\nğŸ” {match_type} '{item}' åŒ¹é…åˆ° {len(matched_fields)} ä¸ªå­—æ®µ:")
                            for i, field in enumerate(matched_fields, 1):
                                print(f"  {i}. {field}")
                            
                            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä½¿ç”¨è¿™äº›åŒ¹é…çš„å­—æ®µ
                            print(f"\nğŸ¤” æ˜¯å¦ä½¿ç”¨è¿™äº›åŒ¹é…çš„å­—æ®µè¿›è¡Œå»é‡ï¼Ÿ")
                            print(f"ğŸ“ è¾“å…¥ 'y' ä½¿ç”¨æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            print(f"ğŸ“ è¾“å…¥ 'n' è·³è¿‡æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            print(f"ğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼ˆå¦‚ï¼š1,3ï¼‰é€‰æ‹©ç‰¹å®šå­—æ®µ")
                            use_choice = input(f"\nè¯·é€‰æ‹©: ").strip().lower()
                            
                            if use_choice in ['y', 'yes', 'æ˜¯']:
                                self.dedup_fields.extend(matched_fields)
                                print(f"âœ… å·²æ·»åŠ  {len(matched_fields)} ä¸ªåŒ¹é…å­—æ®µ")
                            elif use_choice in ['n', 'no', 'å¦']:
                                print(f"âš ï¸  è·³è¿‡ '{item}' çš„æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            else:
                                # ç”¨æˆ·é€‰æ‹©äº†ç‰¹å®šå­—æ®µç¼–å·
                                try:
                                    selected_indices = [int(x.strip()) - 1 for x in use_choice.split(',')]
                                    selected_fields = [matched_fields[i] for i in selected_indices if 0 <= i < len(matched_fields)]
                                    if selected_fields:
                                        self.dedup_fields.extend(selected_fields)
                                        print(f"âœ… å·²æ·»åŠ  {len(selected_fields)} ä¸ªé€‰å®šå­—æ®µ")
                                    else:
                                        print(f"âš ï¸  æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè·³è¿‡")
                                except (ValueError, IndexError):
                                    print(f"âš ï¸  è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡æ‰€æœ‰åŒ¹é…å­—æ®µ")
                        else:
                            # æ— åŒ¹é…
                            print(f"âš ï¸  æœªæ‰¾åˆ°åŒ¹é…å­—æ®µ '{item}'ï¼Œè·³è¿‡")
                
                if not self.dedup_fields:
                    print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè¯·é‡æ–°é€‰æ‹©")
                    return self.configure_deduplication()
                
                # å»é‡å¹¶ä¿æŒé¡ºåº
                seen = set()
                unique_fields = []
                for field in self.dedup_fields:
                    if field not in seen:
                        seen.add(field)
                        unique_fields.append(field)
                self.dedup_fields = unique_fields
                
                print(f"âœ… å·²é€‰æ‹© {len(self.dedup_fields)} ä¸ªå­—æ®µè¿›è¡Œå»é‡:")
                for field in self.dedup_fields:
                    print(f"  ğŸ” {field}")
                
            return True, self.dedup_fields
            
        except Exception as e:
            print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {str(e)}ï¼Œè¯·é‡æ–°é€‰æ‹©")
            return self.configure_deduplication()
    
    def process_data(self, files: List[str], selected_fields: List[str], 
                    deduplicate: bool, dedup_fields: List[str]) -> pd.DataFrame:
        """
        æ•°æ®å¤„ç†ä¸»å‡½æ•°
        
        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            selected_fields: é€‰ä¸­çš„å­—æ®µ
            deduplicate: æ˜¯å¦å»é‡
            dedup_fields: å»é‡å­—æ®µåˆ—è¡¨
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ¡†
        """
        print(f"\n=== æ­¥éª¤5: æ•°æ®å¤„ç† ===")
        all_data = []
        total_rows = 0
        
        print("ğŸ”„ å¼€å§‹å¤„ç†æ–‡ä»¶...")
        
        for i, file in enumerate(files, 1):
            try:
                print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(files)}: {os.path.basename(file)}")
                df = pd.read_excel(file)
                
                # ä½¿ç”¨æ™ºèƒ½åˆ—ååŒ¹é…éªŒè¯å¿…éœ€å­—æ®µ
                is_valid, missing_fields, column_mapping = self.validate_required_columns(df, selected_fields)
                
                if not is_valid:
                    print(f"âš ï¸  è­¦å‘Šï¼šæ–‡ä»¶ç¼ºå°‘å­—æ®µ {missing_fields}ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
                    continue
                
                # ä½¿ç”¨æ˜ å°„åçš„åˆ—å
                mapped_fields = [column_mapping.get(field, field) for field in selected_fields]
                print(f"ğŸ“‹ ä½¿ç”¨æ˜ å°„åçš„åˆ—å: {mapped_fields}")
                
                # ä½¿ç”¨æ˜ å°„åçš„åˆ—åæå–æ•°æ®
                selected_data = df[mapped_fields].copy()
                
                # å°†åˆ—åé‡å‘½åä¸ºæ ‡å‡†åç§°ï¼Œå¹¶æŒ‰ç…§ç”¨æˆ·é€‰æ‹©çš„é¡ºåºé‡æ–°æ’åˆ—
                rename_mapping = {}
                for i, field in enumerate(selected_fields):
                    if mapped_fields[i] != field:
                        rename_mapping[mapped_fields[i]] = field
                
                if rename_mapping:
                    selected_data = selected_data.rename(columns=rename_mapping)
                    print(f"ğŸ“ åˆ—åé‡å‘½å: {rename_mapping}")
                
                # æŒ‰ç…§ç”¨æˆ·é€‰æ‹©çš„å­—æ®µé¡ºåºé‡æ–°æ’åˆ—åˆ—
                selected_data = selected_data[selected_fields]
                print(f"ğŸ“‹ æŒ‰ç”¨æˆ·é€‰æ‹©é¡ºåºæ’åˆ—å­—æ®µ: {selected_fields}")
                
                all_data.append(selected_data)
                file_rows = len(selected_data)
                total_rows += file_rows
                print(f"âœ… æˆåŠŸè¯»å– {file_rows} è¡Œæ•°æ®")
                
            except Exception as e:
                print(f"âŒ é”™è¯¯ï¼šå¤„ç†æ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
                continue
        
        if not all_data:
            print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ•°æ®")
            return pd.DataFrame()
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        print(f"\nğŸ”„ æ­£åœ¨åˆå¹¶æ•°æ®...")
        combined_df = pd.concat(all_data, ignore_index=True)
        print(f"âœ… åˆå¹¶å®Œæˆï¼Œæ€»è¡Œæ•°: {len(combined_df)}")
        
        # å­—æ®µè¡¥å……å¤„ç†
        if self.enable_field_supplement and self.field_mappings:
            print(f"\nğŸ”„ æ­£åœ¨è¡¥å……ç¼ºå¤±å­—æ®µ...")
            combined_df = self.supplement_fields(
                combined_df, 
                self.field_mappings, 
                self.default_values,
                self.link_field
            )
        
        # å»é‡å¤„ç†
        if deduplicate and dedup_fields:
            print(f"\nğŸ”„ æ­£åœ¨æŒ‰å­—æ®µ {dedup_fields} å»é‡...")
            before_count = len(combined_df)
            combined_df = combined_df.drop_duplicates(subset=dedup_fields, keep='first')
            after_count = len(combined_df)
            removed_count = before_count - after_count
            
            print(f"âœ… å»é‡å®Œæˆ:")
            print(f"  ğŸ“Š å»é‡å‰è¡Œæ•°: {before_count}")
            print(f"  ğŸ“Š å»é‡åè¡Œæ•°: {after_count}")
            print(f"  ï¿½ï¿½ï¸  åˆ é™¤é‡å¤è®°å½•: {removed_count}")
            
            if removed_count > 0:
                print(f"  ğŸ“ˆ å»é‡ç‡: {removed_count/before_count*100:.1f}%")
        
        return combined_df
    
    def export_to_excel(self, df: pd.DataFrame, output_filename: str = None):
        """
        å¯¼å‡ºåˆ°Excel
        
        Args:
            df: æ•°æ®æ¡†
            output_filename: è¾“å‡ºæ–‡ä»¶å
        """
        if output_filename is None:
            output_filename = self.output_filename
        
        print(f"\n=== æ­¥éª¤6: å¯¼å‡ºç»“æœ ===")
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        output_path = output_filename
        if not os.path.dirname(output_path):
            output_path = os.path.join(".", output_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(output_path):
            print(f"âš ï¸  æ–‡ä»¶ '{output_filename}' å·²å­˜åœ¨")
            overwrite = input("æ˜¯å¦è¦†ç›–ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            if overwrite not in ['y', 'yes', 'æ˜¯']:
                # ç”Ÿæˆæ–°æ–‡ä»¶å
                base_name = os.path.splitext(output_filename)[0]
                extension = os.path.splitext(output_filename)[1]
                counter = 1
                while True:
                    new_filename = f"{base_name}_{counter}{extension}"
                    new_output_path = os.path.join(".", new_filename)
                    if not os.path.exists(new_output_path):
                        output_path = new_output_path
                        output_filename = new_filename
                        print(f"ğŸ“ ä½¿ç”¨æ–°æ–‡ä»¶å: {new_filename}")
                        break
                    counter += 1
            else:
                # å°è¯•åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶
                try:
                    os.remove(output_path)
                    print(f"âœ… å·²åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶: {output_filename}")
                except PermissionError:
                    print(f"âŒ æ— æ³•åˆ é™¤æ–‡ä»¶ '{output_filename}'ï¼Œæ–‡ä»¶å¯èƒ½è¢«å…¶ä»–ç¨‹åºå ç”¨")
                    print("è¯·å…³é—­Excelæˆ–å…¶ä»–å¯èƒ½æ‰“å¼€è¯¥æ–‡ä»¶çš„ç¨‹åºï¼Œç„¶åé‡è¯•")
                    return None
                except Exception as e:
                    print(f"âŒ åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                    return None
        
        try:
            # åˆ›å»ºExcelå†™å…¥å™¨ï¼Œæ”¯æŒå¤šä¸ªå·¥ä½œè¡¨
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # ä¸»æ•°æ®è¡¨
                df.to_excel(writer, sheet_name='åˆå¹¶æ•°æ®', index=False)
                
                # ç»Ÿè®¡ä¿¡æ¯è¡¨
                stats_items = [
                    'æ€»è®°å½•æ•°',
                    'å¤„ç†æ–‡ä»¶æ•°',
                    'é€‰æ‹©å­—æ®µæ•°',
                    'æ˜¯å¦å»é‡',
                    'å»é‡å­—æ®µæ•°',
                    'åˆ é™¤é‡å¤è®°å½•æ•°'
                ]
                stats_values = [
                    len(df),
                    len(self.selected_files),
                    len(self.selected_fields),
                    'æ˜¯' if self.deduplicate else 'å¦',
                    len(self.dedup_fields) if self.deduplicate else 0,
                    len(df) - len(df.drop_duplicates(subset=self.dedup_fields)) if self.deduplicate and self.dedup_fields else 0
                ]
                
                # æ·»åŠ å­—æ®µè¡¥å……ç»Ÿè®¡
                if self.enable_field_supplement:
                    stats_items.extend([
                        'æ˜¯å¦å¯ç”¨å­—æ®µè¡¥å……',
                        'å…³è”å­—æ®µ',
                        'è¡¥å……å­—æ®µæ•°',
                        'å­—æ®µè¡¥å……æˆåŠŸç‡'
                    ])
                    # è®¡ç®—è¡¥å……æˆåŠŸç‡ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ç»Ÿè®¡å…·ä½“çš„è¡¥å……æƒ…å†µï¼‰
                    stats_values.extend([
                        'æ˜¯',
                        self.link_field,
                        len(self.field_mappings),
                        '100.0%'  # ç®€åŒ–æ˜¾ç¤º
                    ])
                else:
                    stats_items.append('æ˜¯å¦å¯ç”¨å­—æ®µè¡¥å……')
                    stats_values.append('å¦')
                
                stats_items.append('å¤„ç†æ—¶é—´')
                stats_values.append(pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'))
                
                stats_data = {
                    'ç»Ÿè®¡é¡¹ç›®': stats_items,
                    'æ•°å€¼': stats_values
                }
                stats_df = pd.DataFrame(stats_data)
                stats_df.to_excel(writer, sheet_name='å¤„ç†ç»Ÿè®¡', index=False)
                
                # å­—æ®µä¿¡æ¯è¡¨
                field_info = {
                    'å­—æ®µåç§°': self.selected_fields,
                    'å­—æ®µç±»å‹': [str(df[field].dtype) for field in self.selected_fields],
                    'éç©ºå€¼æ•°é‡': [df[field].notna().sum() for field in self.selected_fields],
                    'ç©ºå€¼æ•°é‡': [df[field].isna().sum() for field in self.selected_fields]
                }
                field_df = pd.DataFrame(field_info)
                field_df.to_excel(writer, sheet_name='å­—æ®µä¿¡æ¯', index=False)
            
            print(f"âœ… æ•°æ®å·²æˆåŠŸå¯¼å‡ºåˆ°: {output_path}")
            print(f"ï¿½ï¿½ æ€»å…±å¯¼å‡º {len(df)} æ¡è®°å½•")
            print(f"ğŸ“‹ åŒ…å«å·¥ä½œè¡¨: åˆå¹¶æ•°æ®ã€å¤„ç†ç»Ÿè®¡ã€å­—æ®µä¿¡æ¯")
            
            return output_path
            
        except PermissionError:
            print(f"âŒ æƒé™é”™è¯¯ï¼šæ— æ³•ä¿å­˜åˆ° {output_path}")
            print("è¯·ç¡®ä¿æ–‡ä»¶æ²¡æœ‰è¢«å…¶ä»–ç¨‹åºï¼ˆå¦‚Excelï¼‰æ‰“å¼€")
            print("å»ºè®®ï¼š")
            print("1. å…³é—­å¯èƒ½æ‰“å¼€è¯¥æ–‡ä»¶çš„Excelç¨‹åº")
            print("2. ä½¿ç”¨ä¸åŒçš„æ–‡ä»¶å")
            print("3. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«è®¾ç½®ä¸ºåªè¯»")
            return None
        except Exception as e:
            print(f"âŒ å¯¼å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return None
    
    def set_output_filename(self):
        """è®¾ç½®è¾“å‡ºæ–‡ä»¶å"""
        print(f"\n=== æ­¥éª¤4.5: è¾“å‡ºè®¾ç½® ===")
        print(f"ğŸ“ å½“å‰è¾“å‡ºæ–‡ä»¶å: {self.output_filename}")
        filename = input("è¯·è¾“å…¥æ–°çš„è¾“å‡ºæ–‡ä»¶ååˆ—å¦‚G:\\wang\\excelï¼ˆé»˜è®¤æ ¼å¼ä¸ºxlsxï¼‰: ").strip()
        if filename:
            # ç¡®ä¿æ–‡ä»¶æ‰©å±•åæ­£ç¡®
            if not filename.endswith(('.xlsx', '.xls')):
                filename += '.xlsx'
            self.output_filename = filename
        print(f"âœ… è¾“å‡ºæ–‡ä»¶å: {self.output_filename}")
    

    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        print("=" * 60)
        print("ğŸ¯ Excelæ–‡ä»¶å¤„ç†å·¥å…· v2.4")
        print("=" * 60)
        
        # é…ç½®æ™ºèƒ½åŒ¹é…é€‰é¡¹
        print(f"\n=== æ™ºèƒ½åŒ¹é…é…ç½® ===")
        print(f"ğŸ¤– å½“å‰æ™ºèƒ½åŒ¹é…è®¾ç½®:")
        print(f"  â€¢ æ™ºèƒ½åŒ¹é…: {'å¯ç”¨' if self.enable_smart_matching else 'ç¦ç”¨'}")
        print(f"  â€¢ è‡ªåŠ¨æ¸…ç†åˆ—å: {'å¯ç”¨' if self.auto_clean_columns else 'ç¦ç”¨'}")
        print(f"  â€¢ ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold}")
        
        change_settings = input("æ˜¯å¦ä¿®æ”¹æ™ºèƒ½åŒ¹é…è®¾ç½®ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
        if change_settings in ['y', 'yes', 'æ˜¯']:
            # é…ç½®æ™ºèƒ½åŒ¹é…
            smart_choice = input("æ˜¯å¦å¯ç”¨æ™ºèƒ½åˆ—ååŒ¹é…ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
            self.enable_smart_matching = smart_choice not in ['n', 'no', 'å¦']
            
            # é…ç½®è‡ªåŠ¨æ¸…ç†
            clean_choice = input("æ˜¯å¦è‡ªåŠ¨æ¸…ç†åˆ—åï¼ˆå»é™¤ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ï¼‰ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
            self.auto_clean_columns = clean_choice not in ['n', 'no', 'å¦']
            
            # é…ç½®ç›¸ä¼¼åº¦é˜ˆå€¼
            try:
                threshold_input = input(f"è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼ (0.0-1.0ï¼Œé»˜è®¤{self.similarity_threshold}): ").strip()
                if threshold_input:
                    threshold = float(threshold_input)
                    if 0.0 <= threshold <= 1.0:
                        self.similarity_threshold = threshold
                    else:
                        print(f"âš ï¸  é˜ˆå€¼è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤å€¼ {self.similarity_threshold}")
            except ValueError:
                print(f"âš ï¸  è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å€¼ {self.similarity_threshold}")
            
            print(f"âœ… æ™ºèƒ½åŒ¹é…è®¾ç½®å·²æ›´æ–°")
        
        try:
            # 1. æ–‡ä»¶é€‰æ‹©
            folder_path = input("è¯·è¾“å…¥åŒ…å«Excelæ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆæˆ–æŒ‰å›è½¦ä½¿ç”¨å½“å‰ç›®å½•ï¼‰: ").strip()
            if not folder_path:
                folder_path = "."
            
            files = self.select_files(folder_path)
            if not files:
                print("âŒ æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶ï¼Œç¨‹åºé€€å‡º")
                return
            
            # 2. å­—æ®µåˆ†æ
            all_fields = self.get_field_list(files)
            if not all_fields:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•å­—æ®µï¼Œç¨‹åºé€€å‡º")
                return
            
            # 3. å­—æ®µé€‰æ‹©
            selected_fields = self.select_fields(all_fields)
            if not selected_fields:
                print("âŒ æœªé€‰æ‹©ä»»ä½•å­—æ®µï¼Œç¨‹åºé€€å‡º")
                return
            
            # 3.5. å­—æ®µè¡¥å……é…ç½®
            analysis_result = self.analyze_field_supplement_situation(files, selected_fields)
            self.enable_field_supplement, self.default_values, self.link_field = self.configure_field_supplement(analysis_result, selected_fields)
            
            if self.enable_field_supplement:
                # æ„å»ºå­—æ®µæ˜ å°„
                self.field_mappings = {}
                missing_fields = [field for field, files in analysis_result['files_missing_fields'].items() if files]
                
                for field in missing_fields:
                    mapping = self.build_field_mapping(analysis_result['files_with_all_fields'], field, self.link_field)
                    if mapping:
                        self.field_mappings[field] = mapping
                
                # ç¡®ä¿ç¼ºå¤±å­—æ®µè¢«é€‰ä¸­
                for field in missing_fields:
                    if field not in selected_fields:
                        selected_fields.append(field)
                        print(f"ğŸ“ è‡ªåŠ¨æ·»åŠ {field}å­—æ®µåˆ°é€‰æ‹©åˆ—è¡¨")
            
            # 4. å»é‡é…ç½®
            deduplicate, dedup_fields = self.configure_deduplication()
            
            # 4.5. è¾“å‡ºè®¾ç½®
            self.set_output_filename()
            
            # 5. æ•°æ®å¤„ç†
            result_df = self.process_data(files, selected_fields, deduplicate, dedup_fields)
            if result_df.empty:
                print("âŒ æ²¡æœ‰æ•°æ®å¯å¤„ç†ï¼Œç¨‹åºé€€å‡º")
                return
            
            # 6. å¯¼å‡ºç»“æœ
            output_path = self.export_to_excel(result_df)
            
            if output_path:
                print(f"\n" + "=" * 60)
                print("ğŸ‰ å¤„ç†å®Œæˆï¼")
                print("=" * 60)
                print(f"ğŸ“„ ç»“æœæ–‡ä»¶: {output_path}")
                print(f"ğŸ“Š å¤„ç†è®°å½•æ•°: {len(result_df)}")
                print(f"ğŸ“ å¤„ç†æ–‡ä»¶æ•°: {len(files)}")
                print(f"ğŸ“‹ é€‰æ‹©å­—æ®µæ•°: {len(selected_fields)}")
                if deduplicate and dedup_fields:
                    print(f"ğŸ” å»é‡å­—æ®µ: {', '.join(dedup_fields)}")
                if self.enable_field_supplement:
                    print(f"ğŸ”§ å­—æ®µè¡¥å……: å·²å¯ç”¨ï¼Œè¡¥å……å­—æ®µæ•° {len(self.field_mappings)}")
                

            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    processor = ExcelProcessor()
    processor.run()

if __name__ == "__main__":
    main()