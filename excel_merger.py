import pandas as pd
import os
import glob
import re
from typing import List, Tuple, Dict, Optional
from difflib import SequenceMatcher

class ExcelProcessor:
    """Excelæ–‡ä»¶å¤„ç†å·¥å…·"""
    
    def __init__(self):
        self.selected_files = []
        self.all_fields = []
        self.selected_fields = []
        self.deduplicate = False
        self.dedup_fields = []
        self.output_filename = "result.xlsx"
        
        # é‡å¤è®°å½•ç›¸å…³å±æ€§
        self.duplicate_records = pd.DataFrame()  # å­˜å‚¨å‘ç°çš„é‡å¤è®°å½•
        self.duplicate_count = 0  # é‡å¤è®°å½•æ•°é‡
        self.enable_interactive_dedup = True  # æ˜¯å¦å¯ç”¨äº¤äº’å¼å»é‡
        self.conflict_resolution_choices = {}  # å­˜å‚¨ç”¨æˆ·çš„å†²çªè§£å†³é€‰æ‹©

        
        # æ–°å¢ï¼šæ™ºèƒ½åˆ—ååŒ¹é…ç›¸å…³å±æ€§
        self.column_mapping = {}  # åˆ—åæ˜ å°„å…³ç³»
        self.enable_smart_matching = True  # æ˜¯å¦å¯ç”¨æ™ºèƒ½åŒ¹é…
        self.similarity_threshold = 0.8  # ç›¸ä¼¼åº¦é˜ˆå€¼
        self.auto_clean_columns = True  # æ˜¯å¦è‡ªåŠ¨æ¸…ç†åˆ—å
        
        # å¸¸è§åˆ—åå˜ä½“æ˜ å°„ï¼ˆå»é‡ï¼‰
        self.common_column_variants = {
            'å­¦å·': ['å­¦å·', 'å­¦å·å·', 'å­¦å­¦å·', 'xuehao', 'student_id', 'å­¦ç”Ÿç¼–å·', 'å­¦ç”Ÿå­¦å·'],
            'å­¦ç”Ÿå§“å': ['å­¦ç”Ÿå§“å', 'å­¦ç”Ÿå§“åå', 'å­¦å­¦ç”Ÿå§“å', 'student_name', 'å§“å', 'å­¦ç”Ÿå', 'å­¦ç”Ÿå§“åï¼ˆä¸­æ–‡ï¼‰'],
            'ç­çº§': ['ç­çº§', 'ç­', 'class', 'ç­çº§åç§°', 'class_name'],
            'æˆç»©': ['æˆç»©', 'åˆ†æ•°', 'score', 'grade', 'è€ƒè¯•åˆ†æ•°'],
            'è¯¾ç¨‹': ['è¯¾ç¨‹', 'ç§‘ç›®', 'course', 'subject', 'è¯¾ç¨‹åç§°']
        }
    
    def clean_column_name(self, column_name: str) -> str:
        """
        æ¸…ç†åˆ—åï¼Œå»é™¤ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
        
        Args:
            column_name: åŸå§‹åˆ—å
            
        Returns:
            æ¸…ç†åçš„åˆ—å
        """
        if not self.auto_clean_columns:
            return column_name
        
        # å»é™¤é¦–å°¾ç©ºæ ¼
        cleaned = column_name.strip()
        
        # å»é™¤å¤šä½™çš„ç©ºæ ¼
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰
        cleaned = re.sub(r'[^\w\s\u4e00-\u9fff]', '', cleaned)
        
        # å†æ¬¡å»é™¤ç©ºæ ¼
        cleaned = cleaned.strip()
        
        return cleaned
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦
        
        Args:
            str1: å­—ç¬¦ä¸²1
            str2: å­—ç¬¦ä¸²2
            
        Returns:
            ç›¸ä¼¼åº¦ (0-1)
        """
        # ä½¿ç”¨SequenceMatcherè®¡ç®—ç›¸ä¼¼åº¦
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def find_similar_columns(self, target_column: str, available_columns: List[str]) -> List[Tuple[str, float]]:
        """
        æŸ¥æ‰¾ä¸ç›®æ ‡åˆ—åç›¸ä¼¼çš„åˆ—å
        
        Args:
            target_column: ç›®æ ‡åˆ—å
            available_columns: å¯ç”¨åˆ—ååˆ—è¡¨
            
        Returns:
            ç›¸ä¼¼åˆ—ååˆ—è¡¨ï¼ŒåŒ…å«ç›¸ä¼¼åº¦
        """
        similar_columns = []
        cleaned_target = self.clean_column_name(target_column)
        
        for column in available_columns:
            cleaned_column = self.clean_column_name(column)
            
            # ç²¾ç¡®åŒ¹é…
            if cleaned_target == cleaned_column:
                similar_columns.append((column, 1.0))
                continue
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = self.calculate_similarity(cleaned_target, cleaned_column)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§å˜ä½“
            for standard_name, variants in self.common_column_variants.items():
                if cleaned_target in variants and cleaned_column in variants:
                    similarity = max(similarity, 0.9)  # æé«˜å˜ä½“çš„ç›¸ä¼¼åº¦
                    break
            
            if similarity >= self.similarity_threshold:
                similar_columns.append((column, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similar_columns.sort(key=lambda x: x[1], reverse=True)
        return similar_columns
    
    def smart_column_mapping(self, required_columns: List[str], available_columns: List[str]) -> Dict[str, str]:
        """
        æ™ºèƒ½åˆ—åæ˜ å°„
        
        Args:
            required_columns: éœ€è¦çš„åˆ—å
            available_columns: å¯ç”¨çš„åˆ—å
            
        Returns:
            åˆ—åæ˜ å°„å­—å…¸
        """
        mapping = {}
        unmapped_required = []
        unmapped_available = available_columns.copy()
        

        
        # ç¬¬ä¸€è½®ï¼šç²¾ç¡®åŒ¹é…å’Œå¸¸è§å˜ä½“åŒ¹é…
        for required in required_columns:
            matched = False
            
            # æ£€æŸ¥ç²¾ç¡®åŒ¹é…
            if required in available_columns:
                mapping[required] = required
                unmapped_available.remove(required)

                matched = True
                continue
            
            # æ£€æŸ¥å¸¸è§å˜ä½“
            if required in self.common_column_variants:
                variants = self.common_column_variants[required]
                for variant in variants:
                    if variant in available_columns:
                        mapping[required] = variant
                        unmapped_available.remove(variant)
                        print(f"âœ… å˜ä½“åŒ¹é…: {variant} -> {required}")
                        matched = True
                        break
            
            if not matched:
                unmapped_required.append(required)
        
        # ç¬¬äºŒè½®ï¼šæ¨¡ç³ŠåŒ¹é…
        if unmapped_required and unmapped_available:
            print(f"\nğŸ” è¿›è¡Œæ¨¡ç³ŠåŒ¹é…...")
            for required in unmapped_required:
                similar_columns = self.find_similar_columns(required, unmapped_available)
                
                if similar_columns:
                    best_match, similarity = similar_columns[0]
                    print(f"ğŸ” æ‰¾åˆ°ç›¸ä¼¼åˆ—å: {best_match} -> {required} (ç›¸ä¼¼åº¦: {similarity:.2f})")
                    
                    # å¦‚æœç›¸ä¼¼åº¦ä¸º1.00ï¼Œè‡ªåŠ¨ç¡®è®¤æ˜ å°„
                    if similarity >= 1.0:
                        mapping[required] = best_match
                        unmapped_available.remove(best_match)
                        print(f"âœ… è‡ªåŠ¨æ˜ å°„ (å®Œå…¨åŒ¹é…): {best_match} -> {required}")
                    else:
                        # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç¡®è®¤æ˜ å°„
                        confirm = input(f"æ˜¯å¦å°†æ–‡ä»¶åˆ—å '{best_match}' æ˜ å°„åˆ°æ ‡å‡†å­—æ®µ '{required}'ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
                        if confirm not in ['n', 'no', 'å¦']:
                            mapping[required] = best_match
                            unmapped_available.remove(best_match)
                            print(f"âœ… ç¡®è®¤æ˜ å°„: {best_match} -> {required}")
                        else:
                            print(f"âš ï¸  è·³è¿‡æ˜ å°„: {required}")
                else:
                    print(f"âŒ æœªæ‰¾åˆ°ä¸ '{required}' ç›¸ä¼¼çš„åˆ—å")
                    print(f"ğŸ¤” è¯·é€‰æ‹©:")
                    print(f"  1. æ‰‹åŠ¨é€‰æ‹©åˆ—å (è¾“å…¥ 'm')")
                    print(f"  2. è·³è¿‡æ­¤å­—æ®µ (è¾“å…¥ 's')")
                    
                    while True:
                        choice = input(f"å¯¹äºå­—æ®µ '{required}' è¯·é€‰æ‹©: ").strip().lower()
                        if choice == 's':
                            print(f"âš ï¸  è·³è¿‡æ˜ å°„: {required}")
                            break
                        elif choice == 'm':
                            selected_column = self._manual_select_column(required, unmapped_available)
                            if selected_column:
                                mapping[required] = selected_column
                                unmapped_available.remove(selected_column)
                                unmapped_required.remove(required)
                                print(f"âœ… æ‰‹åŠ¨æ˜ å°„: {selected_column} -> {required}")
                            break
                        else:
                            print("âŒ è¯·è¾“å…¥ 'm' æˆ– 's'")
        
        # æ˜¾ç¤ºæ˜ å°„ç»“æœ
        if mapping:
            print(f"\nğŸ“‹ åˆ—åæ˜ å°„ç»“æœ:")
            for required, mapped in mapping.items():
                print(f"  {mapped} -> {required}")
        
        if unmapped_required:
            print(f"\nâš ï¸  æœªæ˜ å°„çš„åˆ—å: {unmapped_required}")
        
        return mapping
    
    def validate_required_columns(self, df: pd.DataFrame, required_columns: List[str]) -> Tuple[bool, List[str], Dict[str, str]]:
        """
        éªŒè¯å¿…éœ€çš„åˆ—åæ˜¯å¦å­˜åœ¨ï¼Œæ”¯æŒæ™ºèƒ½åŒ¹é…
        
        Args:
            df: æ•°æ®æ¡†
            required_columns: å¿…éœ€çš„åˆ—ååˆ—è¡¨
            
        Returns:
            (æ˜¯å¦éªŒè¯é€šè¿‡, ç¼ºå¤±çš„åˆ—ååˆ—è¡¨, åˆ—åæ˜ å°„å­—å…¸)
        """
        available_columns = list(df.columns)
        missing_columns = []
        column_mapping = {}
        
        if not self.enable_smart_matching:
            # ä¼ ç»Ÿä¸¥æ ¼åŒ¹é…
            for required in required_columns:
                if required not in available_columns:
                    missing_columns.append(required)
                else:
                    column_mapping[required] = required
        else:
            # æ™ºèƒ½åŒ¹é…
            column_mapping = self.smart_column_mapping(required_columns, available_columns)
            
            # æ£€æŸ¥å“ªäº›åˆ—åæ²¡æœ‰è¢«æ˜ å°„
            for required in required_columns:
                if required not in column_mapping:
                    missing_columns.append(required)
        
        return len(missing_columns) == 0, missing_columns, column_mapping
    
    def select_files(self, folder_path: str = ".") -> List[str]:
        """
        æ–‡ä»¶é€‰æ‹©åŠŸèƒ½
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•
            
        Returns:
            é€‰ä¸­çš„æ–‡ä»¶åˆ—è¡¨
        """
        print(f"\n=== æ­¥éª¤1: æ–‡ä»¶é€‰æ‹© ===")
        print(f"æ­£åœ¨æ‰«ææ–‡ä»¶å¤¹: {folder_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰Excelæ–‡ä»¶
        excel_patterns = ['*.xlsx', '*.xls']
        excel_files = []
        
        for pattern in excel_patterns:
            excel_files.extend(glob.glob(os.path.join(folder_path, pattern)))
        
        if not excel_files:
            print(f"âŒ åœ¨æ–‡ä»¶å¤¹ '{folder_path}' ä¸­æ²¡æœ‰æ‰¾åˆ°Excelæ–‡ä»¶")
            return []
        
        # æ˜¾ç¤ºæ‰¾åˆ°çš„æ–‡ä»¶
        print(f"\nâœ… æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶:")
        for i, file in enumerate(excel_files, 1):
            filename = os.path.basename(file)
            file_size = os.path.getsize(file) / 1024  # KB
            print(f"{i:2d}. {filename:<30} ({file_size:.1f} KB)")
        
        # ç”¨æˆ·é€‰æ‹©æ–‡ä»¶
        print(f"\nè¯·é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶:")
        print("- è¾“å…¥æ–‡ä»¶ç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2,3ï¼‰")
        print("- è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰æ–‡ä»¶")
        print("ğŸ“ è¾“å…¥ 'q' é€€å‡ºç¨‹åº")
        
        try:
            choice = input("\nè¯·é€‰æ‹©: ").strip().lower()
            
            if choice == 'q':
                print("ç¨‹åºé€€å‡º")
                return []
            elif choice == 'all':
                self.selected_files = excel_files
                print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(excel_files)} ä¸ªæ–‡ä»¶")
            else:
                # è§£æç”¨æˆ·é€‰æ‹©çš„æ–‡ä»¶ç¼–å·
                indices = [int(x.strip()) - 1 for x in choice.split(',')]
                self.selected_files = [excel_files[i] for i in indices if 0 <= i < len(excel_files)]
                
                if not self.selected_files:
                    print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆæ–‡ä»¶ï¼Œè¯·é‡æ–°é€‰æ‹©")
                    return self.select_files(folder_path)
                
                print(f"âœ… å·²é€‰æ‹© {len(self.selected_files)} ä¸ªæ–‡ä»¶:")
                for file in self.selected_files:
                    print(f"  ğŸ“„ {os.path.basename(file)}")
                
            return self.selected_files
            
        except (ValueError, IndexError) as e:
            print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {str(e)}ï¼Œè¯·é‡æ–°é€‰æ‹©")
            return self.select_files(folder_path)
    
    def get_field_list(self, files: List[str]) -> List[str]:
        """
        è·å–æ‰€æœ‰æ–‡ä»¶çš„å­—æ®µåˆ—è¡¨
        
        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            æ‰€æœ‰å­—æ®µçš„åˆ—è¡¨
        """
        print(f"\n=== æ­¥éª¤2: å­—æ®µåˆ†æ ===")
        all_fields = set()
        file_field_info = {}
        
        for file in files:
            try:
                df = pd.read_excel(file)
                file_fields = list(df.columns)
                
                # è¿‡æ»¤æ‰æ— æ•ˆå­—æ®µï¼ˆè¯´æ˜æ–‡å­—ã€Unnamedå­—æ®µç­‰ï¼‰
                valid_fields = []
                for field in file_fields:
                    # è·³è¿‡Unnamedå­—æ®µ
                    if field.startswith('Unnamed:'):
                        continue
                    # è·³è¿‡è¯´æ˜æ–‡å­—ï¼ˆé€šå¸¸åŒ…å«å¾ˆé•¿çš„æè¿°æ€§æ–‡å­—ï¼‰
                    if len(field) > 100:
                        continue
                    # è·³è¿‡ç©ºå­—æ®µ
                    if not field or field.strip() == '':
                        continue
                    # è·³è¿‡çº¯è¯´æ˜æ€§å­—æ®µ
                    if field in ['è¯´æ˜', 'è¯´æ˜æ–‡å­—', 'å¤‡æ³¨', 'æ³¨é‡Š']:
                        continue
                    # è·³è¿‡åŒ…å«è¯´æ˜å…³é”®è¯çš„å­—æ®µ
                    if any(keyword in field for keyword in ['è¯´æ˜', 'å¤‡æ³¨', 'æ³¨é‡Š', 'æ³¨æ„', 'æç¤º']):
                        continue
                    
                    # å¦‚æœå¯ç”¨è‡ªåŠ¨æ¸…ç†ï¼Œæ˜¾ç¤ºæ¸…ç†åçš„åˆ—å
                    if self.auto_clean_columns:
                        cleaned_field = self.clean_column_name(field)
                        if cleaned_field != field:
                            print(f"ğŸ“ åˆ—åæ¸…ç†: '{field}' -> '{cleaned_field}'")
                        valid_fields.append(cleaned_field)
                    else:
                        valid_fields.append(field)
                
                all_fields.update(valid_fields)
                file_field_info[os.path.basename(file)] = {
                    'field_count': len(valid_fields),
                    'fields': valid_fields
                }
                print(f"ğŸ“Š æ–‡ä»¶ '{os.path.basename(file)}' åŒ…å« {len(valid_fields)} ä¸ªæœ‰æ•ˆå­—æ®µ")
                
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
        
        # è®¡ç®—æ¯ä¸ªå­—æ®µçš„å‡ºç°æ¬¡æ•°å¹¶æ’åº
        field_occurrence = {}
        for field in all_fields:
            files_with_field = [f for f, info in file_field_info.items() if field in info['fields']]
            field_occurrence[field] = len(files_with_field)
        
        # æŒ‰å‡ºç°æ¬¡æ•°ä»é«˜åˆ°ä½æ’åº
        sorted_fields = sorted(field_occurrence.items(), key=lambda x: x[1], reverse=True)
        self.all_fields = [field for field, count in sorted_fields]
        
        print(f"\nâœ… æ€»å…±å‘ç° {len(self.all_fields)} ä¸ªä¸åŒæœ‰æ•ˆå­—æ®µ")
        
        return self.all_fields
    

    

    

    

    
    def get_file_fields(self, file_path: str) -> List[str]:
        """
        è·å–å•ä¸ªæ–‡ä»¶çš„å­—æ®µåˆ—è¡¨
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            å­—æ®µåˆ—è¡¨
        """
        try:
            df = pd.read_excel(file_path)
            file_fields = list(df.columns)
            
            # è¿‡æ»¤æ‰æ— æ•ˆå­—æ®µï¼ˆè¯´æ˜æ–‡å­—ã€Unnamedå­—æ®µç­‰ï¼‰
            valid_fields = []
            for field in file_fields:
                # è·³è¿‡Unnamedå­—æ®µ
                if field.startswith('Unnamed:'):
                    continue
                # è·³è¿‡è¯´æ˜æ–‡å­—ï¼ˆé€šå¸¸åŒ…å«å¾ˆé•¿çš„æè¿°æ€§æ–‡å­—ï¼‰
                if len(field) > 100:
                    continue
                # è·³è¿‡ç©ºå­—æ®µ
                if not field or field.strip() == '':
                    continue
                valid_fields.append(field)
            
            return valid_fields
        except Exception as e:
            return []
    
    def clean_column_name(self, column_name: str) -> str:
        """
        æ¸…ç†åˆ—åï¼Œå»é™¤ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
        
        Args:
            column_name: åŸå§‹åˆ—å
            
        Returns:
            æ¸…ç†åçš„åˆ—å
        """
        if not self.auto_clean_columns:
            return column_name
        
        # å»é™¤é¦–å°¾ç©ºæ ¼
        cleaned = column_name.strip()
        
        # å»é™¤å¤šä½™çš„ç©ºæ ¼
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰
        cleaned = re.sub(r'[^\w\s\u4e00-\u9fff]', '', cleaned)
        
        # å†æ¬¡å»é™¤ç©ºæ ¼
        cleaned = cleaned.strip()
        
        return cleaned
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦
        
        Args:
            str1: å­—ç¬¦ä¸²1
            str2: å­—ç¬¦ä¸²2
            
        Returns:
            ç›¸ä¼¼åº¦ (0-1)
        """
        # ä½¿ç”¨SequenceMatcherè®¡ç®—ç›¸ä¼¼åº¦
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def find_similar_columns(self, target_column: str, available_columns: List[str]) -> List[Tuple[str, float]]:
        """
        æŸ¥æ‰¾ä¸ç›®æ ‡åˆ—åç›¸ä¼¼çš„åˆ—å
        
        Args:
            target_column: ç›®æ ‡åˆ—å
            available_columns: å¯ç”¨åˆ—ååˆ—è¡¨
            
        Returns:
            ç›¸ä¼¼åˆ—ååˆ—è¡¨ï¼ŒåŒ…å«ç›¸ä¼¼åº¦
        """
        similar_columns = []
        cleaned_target = self.clean_column_name(target_column)
        
        for column in available_columns:
            cleaned_column = self.clean_column_name(column)
            
            # ç²¾ç¡®åŒ¹é…
            if cleaned_target == cleaned_column:
                similar_columns.append((column, 1.0))
                continue
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = self.calculate_similarity(cleaned_target, cleaned_column)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§å˜ä½“
            for standard_name, variants in self.common_column_variants.items():
                if cleaned_target in variants and cleaned_column in variants:
                    similarity = max(similarity, 0.9)  # æé«˜å˜ä½“çš„ç›¸ä¼¼åº¦
                    break
            
            if similarity >= self.similarity_threshold:
                similar_columns.append((column, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similar_columns.sort(key=lambda x: x[1], reverse=True)
        return similar_columns
    
    def smart_column_mapping(self, required_columns: List[str], available_columns: List[str]) -> Dict[str, str]:
        """
        æ™ºèƒ½åˆ—åæ˜ å°„
        
        Args:
            required_columns: éœ€è¦çš„åˆ—å
            available_columns: å¯ç”¨çš„åˆ—å
            
        Returns:
            åˆ—åæ˜ å°„å­—å…¸
        """
        mapping = {}
        unmapped_required = []
        unmapped_available = available_columns.copy()
        
        print(f"\nğŸ” æ™ºèƒ½åˆ—åæ˜ å°„åˆ†æ...")
        print(f"ğŸ“‹ éœ€è¦çš„åˆ—å: {required_columns}")
        print(f"ğŸ“‹ å¯ç”¨çš„åˆ—å: {available_columns}")
        
        # ç¬¬ä¸€è½®ï¼šç²¾ç¡®åŒ¹é…å’Œå¸¸è§å˜ä½“åŒ¹é…
        for required in required_columns:
            matched = False
            
            # æ£€æŸ¥ç²¾ç¡®åŒ¹é…
            if required in available_columns:
                mapping[required] = required
                unmapped_available.remove(required)
                print(f"âœ… ç²¾ç¡®åŒ¹é…: {required} -> {required}")
                matched = True
                continue
            
            # æ£€æŸ¥å¸¸è§å˜ä½“
            if required in self.common_column_variants:
                variants = self.common_column_variants[required]
                for variant in variants:
                    if variant in available_columns:
                        mapping[required] = variant
                        unmapped_available.remove(variant)
                        print(f"âœ… å˜ä½“åŒ¹é…: {variant} -> {required}")
                        matched = True
                        break
            
            if not matched:
                unmapped_required.append(required)
        
        # ç¬¬äºŒè½®ï¼šæ¨¡ç³ŠåŒ¹é…
        if unmapped_required and unmapped_available:
            print(f"\nğŸ” è¿›è¡Œæ¨¡ç³ŠåŒ¹é…...")
            for required in unmapped_required:
                similar_columns = self.find_similar_columns(required, unmapped_available)
                
                if similar_columns:
                    best_match, similarity = similar_columns[0]
                    print(f"ğŸ” æ‰¾åˆ°ç›¸ä¼¼åˆ—å: {best_match} -> {required} (ç›¸ä¼¼åº¦: {similarity:.2f})")
                    
                    # å¦‚æœç›¸ä¼¼åº¦ä¸º1.00ï¼Œè‡ªåŠ¨ç¡®è®¤æ˜ å°„
                    if similarity >= 1.0:
                        mapping[required] = best_match
                        unmapped_available.remove(best_match)
                        print(f"âœ… è‡ªåŠ¨æ˜ å°„ (å®Œå…¨åŒ¹é…): {best_match} -> {required}")
                    else:
                        # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç¡®è®¤æ˜ å°„
                        confirm = input(f"æ˜¯å¦å°†æ–‡ä»¶åˆ—å '{best_match}' æ˜ å°„åˆ°æ ‡å‡†å­—æ®µ '{required}'ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
                        if confirm not in ['n', 'no', 'å¦']:
                            mapping[required] = best_match
                            unmapped_available.remove(best_match)
                            print(f"âœ… ç¡®è®¤æ˜ å°„: {best_match} -> {required}")
                        else:
                            print(f"âš ï¸  è·³è¿‡æ˜ å°„: {required}")
                else:
                    print(f"âŒ æœªæ‰¾åˆ°ä¸ '{required}' ç›¸ä¼¼çš„åˆ—å")
                    print(f"ğŸ¤” è¯·é€‰æ‹©:")
                    print(f"  1. æ‰‹åŠ¨é€‰æ‹©åˆ—å (è¾“å…¥ 'm')")
                    print(f"  2. è·³è¿‡æ­¤å­—æ®µ (è¾“å…¥ 's')")
                    
                    while True:
                        choice = input(f"å¯¹äºå­—æ®µ '{required}' è¯·é€‰æ‹©: ").strip().lower()
                        if choice == 's':
                            print(f"âš ï¸  è·³è¿‡æ˜ å°„: {required}")
                            break
                        elif choice == 'm':
                            selected_column = self._manual_select_column(required, unmapped_available)
                            if selected_column:
                                mapping[required] = selected_column
                                unmapped_available.remove(selected_column)
                                unmapped_required.remove(required)
                                print(f"âœ… æ‰‹åŠ¨æ˜ å°„: {selected_column} -> {required}")
                            break
                        else:
                            print("âŒ è¯·è¾“å…¥ 'm' æˆ– 's'")
        
        # æ˜¾ç¤ºæ˜ å°„ç»“æœ
        if mapping:
            print(f"\nğŸ“‹ åˆ—åæ˜ å°„ç»“æœ:")
            for required, mapped in mapping.items():
                print(f"  {mapped} -> {required}")
        
        if unmapped_required:
            print(f"\nâš ï¸  æœªæ˜ å°„çš„åˆ—å: {unmapped_required}")
        
        return mapping
    
    def validate_required_columns(self, df: pd.DataFrame, required_columns: List[str]) -> Tuple[bool, List[str], Dict[str, str]]:
        """
        éªŒè¯å¿…éœ€çš„åˆ—åæ˜¯å¦å­˜åœ¨ï¼Œæ”¯æŒæ™ºèƒ½åŒ¹é…
        
        Args:
            df: æ•°æ®æ¡†
            required_columns: å¿…éœ€çš„åˆ—ååˆ—è¡¨
            
        Returns:
            (æ˜¯å¦éªŒè¯é€šè¿‡, ç¼ºå¤±çš„åˆ—ååˆ—è¡¨, åˆ—åæ˜ å°„å­—å…¸)
        """
        available_columns = list(df.columns)
        missing_columns = []
        column_mapping = {}
        
        if not self.enable_smart_matching:
            # ä¼ ç»Ÿä¸¥æ ¼åŒ¹é…
            for required in required_columns:
                if required not in available_columns:
                    missing_columns.append(required)
                else:
                    column_mapping[required] = required
        else:
            # æ™ºèƒ½åŒ¹é…
            column_mapping = self.smart_column_mapping(required_columns, available_columns)
            
            # æ£€æŸ¥å“ªäº›åˆ—åæ²¡æœ‰è¢«æ˜ å°„
            for required in required_columns:
                if required not in column_mapping:
                    missing_columns.append(required)
        
        return len(missing_columns) == 0, missing_columns, column_mapping
    
    def wildcard_match(self, pattern: str, text: str) -> bool:
        """
        é€šé…ç¬¦åŒ¹é…å‡½æ•°ï¼Œæ”¯æŒ * ä»£è¡¨ä»»æ„ä¸€ä¸ªå­—ç¬¦
        
        Args:
            pattern: åŒ…å« * çš„æ¨¡å¼å­—ç¬¦ä¸²
            text: è¦åŒ¹é…çš„æ–‡æœ¬
            
        Returns:
            æ˜¯å¦åŒ¹é…
        """
        if '*' not in pattern:
            return pattern == text
        
        # å°† * è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼çš„ . å­—ç¬¦
        regex_pattern = pattern.replace('*', '.')
        import re
        return bool(re.match(regex_pattern, text))
    
    def flexible_wildcard_match(self, pattern: str, text: str) -> bool:
        """
        çµæ´»çš„é€šé…ç¬¦åŒ¹é…å‡½æ•°ï¼Œæ”¯æŒ * ä»£è¡¨ä»»æ„å­—ç¬¦åºåˆ—
        
        Args:
            pattern: åŒ…å« * çš„æ¨¡å¼å­—ç¬¦ä¸²
            text: è¦åŒ¹é…çš„æ–‡æœ¬
            
        Returns:
            æ˜¯å¦åŒ¹é…
        """
        if '*' not in pattern:
            return pattern == text
        
        # å°† * è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼çš„ .* å­—ç¬¦ï¼ˆåŒ¹é…ä»»æ„å­—ç¬¦åºåˆ—ï¼‰
        regex_pattern = pattern.replace('*', '.*')
        import re
        return bool(re.match(regex_pattern, text))
    
    def enhanced_field_matching(self, pattern: str, all_fields: List[str]) -> Tuple[List[str], str]:
        """
        å¢å¼ºçš„å­—æ®µåŒ¹é…å‡½æ•°ï¼Œæ”¯æŒå¤šç§åŒ¹é…æ–¹å¼
        
        Args:
            pattern: åŒ¹é…æ¨¡å¼
            all_fields: æ‰€æœ‰å¯ç”¨å­—æ®µåˆ—è¡¨
            
        Returns:
            (åŒ¹é…çš„å­—æ®µåˆ—è¡¨, åŒ¹é…ç±»å‹æè¿°)
        """
        # 1. ç²¾ç¡®åŒ¹é…
        if pattern in all_fields:
            return [pattern], "ç²¾ç¡®åŒ¹é…"
        
        # 2. é€šé…ç¬¦åŒ¹é…
        if '*' in pattern:
            matched_fields = self.find_matching_fields(pattern, all_fields)
            if matched_fields:
                return matched_fields, "é€šé…ç¬¦åŒ¹é…"
        
        # 3. åŒ…å«åŒ¹é…ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰
        matched_fields = [field for field in all_fields if pattern.lower() in field.lower()]
        if matched_fields:
            return matched_fields, "åŒ…å«åŒ¹é…"
        
        # 4. æ— åŒ¹é…
        return [], "æ— åŒ¹é…"
    
    def find_matching_fields(self, pattern: str, all_fields: List[str]) -> List[str]:
        """
        æ ¹æ®é€šé…ç¬¦æ¨¡å¼æŸ¥æ‰¾åŒ¹é…çš„å­—æ®µ
        
        Args:
            pattern: åŒ…å« * çš„æ¨¡å¼å­—ç¬¦ä¸²
            all_fields: æ‰€æœ‰å¯ç”¨å­—æ®µåˆ—è¡¨
            
        Returns:
            åŒ¹é…çš„å­—æ®µåˆ—è¡¨
        """
        if '*' not in pattern:
            # ç²¾ç¡®åŒ¹é…
            return [field for field in all_fields if field == pattern]
        
        # é€šé…ç¬¦åŒ¹é…
        matched_fields = []
        for field in all_fields:
            if self.flexible_wildcard_match(pattern, field):
                matched_fields.append(field)
        
        return matched_fields
    
    def select_fields(self, all_fields: List[str]) -> List[str]:
        """
        å­—æ®µé€‰æ‹©åŠŸèƒ½
        
        Args:
            all_fields: æ‰€æœ‰å¯ç”¨å­—æ®µåˆ—è¡¨
            
        Returns:
            é€‰ä¸­çš„å­—æ®µåˆ—è¡¨
        """
        print(f"\n=== æ­¥éª¤3: å­—æ®µé€‰æ‹© ===")
        
        # è¯¢é—®æ˜¯å¦æ˜¾ç¤ºå­—æ®µå‡ºç°æ¬¡æ•°
        print("ğŸ¤” æ˜¯å¦æ˜¾ç¤ºå­—æ®µå‡ºç°æ¬¡æ•°ï¼Ÿ")
        print("âš ï¸  æ³¨æ„ï¼šé€‰æ‹© y å¯èƒ½ä¼šå¯¼è‡´ç¨‹åºå‡ºç°å¡é¡¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤§é‡æ–‡ä»¶æ—¶")
        show_occurrence = input("è¯·é€‰æ‹© (y/nï¼Œé»˜è®¤n): ").strip().lower()
        show_occurrence = show_occurrence in ['y', 'yes', 'æ˜¯']
        
        if show_occurrence:
            print("ğŸ“‹ å¯ç”¨å­—æ®µåˆ—è¡¨ï¼ˆæŒ‰å‡ºç°æ¬¡æ•°æ’åºï¼‰:")
        else:
            print("ğŸ“‹ å¯ç”¨å­—æ®µåˆ—è¡¨:")
        
        # åˆ†é¡µæ˜¾ç¤ºå­—æ®µ
        page_size = 10
        total_pages = (len(all_fields) + page_size - 1) // page_size
        
        for page in range(total_pages):
            start_idx = page * page_size
            end_idx = min(start_idx + page_size, len(all_fields))
            
            print(f"\n--- ç¬¬ {page + 1}/{total_pages} é¡µ ---")
            for i in range(start_idx, end_idx):
                field = all_fields[i]
                if show_occurrence:
                    # è®¡ç®—è¯¥å­—æ®µçš„å‡ºç°æ¬¡æ•°
                    occurrence_count = sum(1 for f in self.selected_files if field in self.get_file_fields(f))
                    print(f"{i + 1:2d}. {field:<25} (å‡ºç°åœ¨ {occurrence_count} ä¸ªæ–‡ä»¶ä¸­)")
                else:
                    print(f"{i + 1:2d}. {field}")
        
        print(f"\nè¯·é€‰æ‹©è¦å¯¼å…¥çš„å­—æ®µ:")
        print("ğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2,3ï¼‰")
        print("ğŸ“ è¾“å…¥å­—æ®µåç§°ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼šå­¦å·,å­¦ç”Ÿå§“åï¼‰")
        print("ğŸ“ æ”¯æŒé€šé…ç¬¦åŒ¹é…ï¼ˆ*ä»£è¡¨ä»»æ„ä¸€ä¸ªå­—ç¬¦ï¼Œå¦‚ï¼š*å­¦å·,å­¦*å·ï¼‰")
        print("ğŸ“ æ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚ï¼šå­¦å· å¯åŒ¹é… å­¦ç”Ÿå­¦å·ã€å­¦å·ä¿¡æ¯ç­‰ï¼‰")
        print("ğŸ“ è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰å­—æ®µ")
        print("ğŸ“ è¾“å…¥ 'page 1' æŸ¥çœ‹ç¬¬1é¡µï¼ˆå¯æ›¿æ¢é¡µç ï¼‰")
        
        try:
            choice = input("\nè¯·é€‰æ‹©: ").strip()
            
            if choice.startswith('page '):
                try:
                    page_num = int(choice.split()[1]) - 1
                    if 0 <= page_num < total_pages:
                        print(f"\n--- ç¬¬ {page_num + 1}/{total_pages} é¡µ ---")
                        start_idx = page_num * page_size
                        end_idx = min(start_idx + page_size, len(all_fields))
                        for i in range(start_idx, end_idx):
                            field = all_fields[i]
                            print(f"{i + 1:2d}. {field}")
                        return self.select_fields(all_fields)
                    else:
                        print("âŒ é¡µç è¶…å‡ºèŒƒå›´")
                        return self.select_fields(all_fields)
                except:
                    print("âŒ é¡µç æ ¼å¼é”™è¯¯")
                    return self.select_fields(all_fields)
            
            elif choice.lower() == 'all':
                self.selected_fields = all_fields
                print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(all_fields)} ä¸ªå­—æ®µ")
            else:
                # è§£æç”¨æˆ·é€‰æ‹©
                selected_items = [item.strip() for item in choice.split(',')]
                self.selected_fields = []
                
                for item in selected_items:
                    # å°è¯•ä½œä¸ºæ•°å­—å¤„ç†
                    try:
                        index = int(item) - 1
                        if 0 <= index < len(all_fields):
                            self.selected_fields.append(all_fields[index])
                        else:
                            print(f"âš ï¸  å­—æ®µç¼–å· {item} è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡")
                    except ValueError:
                        # ä½¿ç”¨å¢å¼ºçš„å­—æ®µåŒ¹é…å‡½æ•°
                        matched_fields, match_type = self.enhanced_field_matching(item, all_fields)
                        
                        if len(matched_fields) == 1:
                            # å•ä¸ªåŒ¹é…ï¼Œç›´æ¥æ·»åŠ 
                            self.selected_fields.append(matched_fields[0])
                            if match_type != "ç²¾ç¡®åŒ¹é…":
                                print(f"ğŸ“ {match_type}å­—æ®µ: {item} -> {matched_fields[0]}")
                        elif len(matched_fields) > 1:
                            # å¤šä¸ªåŒ¹é…ï¼Œè¯¢é—®ç”¨æˆ·
                            print(f"\nğŸ” {match_type} '{item}' åŒ¹é…åˆ° {len(matched_fields)} ä¸ªå­—æ®µ:")
                            for i, field in enumerate(matched_fields, 1):
                                print(f"  {i}. {field}")
                            
                            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä½¿ç”¨è¿™äº›åŒ¹é…çš„å­—æ®µ
                            print(f"\nğŸ¤” æ˜¯å¦ä½¿ç”¨è¿™äº›åŒ¹é…çš„å­—æ®µï¼Ÿ")
                            print(f"ğŸ“ è¾“å…¥ 'y' ä½¿ç”¨æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            print(f"ğŸ“ è¾“å…¥ 'n' è·³è¿‡æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            print(f"ğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼ˆå¦‚ï¼š1,3ï¼‰é€‰æ‹©ç‰¹å®šå­—æ®µ")
                            use_choice = input(f"\nè¯·é€‰æ‹©: ").strip().lower()
                            
                            if use_choice in ['y', 'yes', 'æ˜¯']:
                                self.selected_fields.extend(matched_fields)
                                print(f"âœ… å·²æ·»åŠ  {len(matched_fields)} ä¸ªåŒ¹é…å­—æ®µ")
                            elif use_choice in ['n', 'no', 'å¦']:
                                print(f"âš ï¸  è·³è¿‡ '{item}' çš„æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            else:
                                # ç”¨æˆ·é€‰æ‹©äº†ç‰¹å®šå­—æ®µç¼–å·
                                try:
                                    selected_indices = [int(x.strip()) - 1 for x in use_choice.split(',')]
                                    selected_fields = [matched_fields[i] for i in selected_indices if 0 <= i < len(matched_fields)]
                                    if selected_fields:
                                        self.selected_fields.extend(selected_fields)
                                        print(f"âœ… å·²æ·»åŠ  {len(selected_fields)} ä¸ªé€‰å®šå­—æ®µ")
                                    else:
                                        print(f"âš ï¸  æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè·³è¿‡")
                                except (ValueError, IndexError):
                                    print(f"âš ï¸  è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡æ‰€æœ‰åŒ¹é…å­—æ®µ")
                        else:
                            # æ— åŒ¹é…
                            print(f"âš ï¸  æœªæ‰¾åˆ°åŒ¹é…å­—æ®µ '{item}'ï¼Œè·³è¿‡")
                
                if not self.selected_fields:
                    print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè¯·é‡æ–°é€‰æ‹©")
                    return self.select_fields(all_fields)
                
                # å»é‡å¹¶ä¿æŒé¡ºåº
                seen = set()
                unique_fields = []
                for field in self.selected_fields:
                    if field not in seen:
                        seen.add(field)
                        unique_fields.append(field)
                self.selected_fields = unique_fields
                
                print(f"âœ… å·²é€‰æ‹© {len(self.selected_fields)} ä¸ªå­—æ®µ:")
                for field in self.selected_fields:
                    print(f"  ğŸ“‹ {field}")
                
            return self.selected_fields
            
        except Exception as e:
            print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {str(e)}ï¼Œè¯·é‡æ–°é€‰æ‹©")
            return self.select_fields(all_fields)
    
    def configure_deduplication(self) -> Tuple[bool, List[str]]:
        """
        å»é‡é…ç½®ï¼šè¿”å›(æ˜¯å¦å»é‡, å»é‡å­—æ®µåˆ—è¡¨)
        
        Returns:
            (æ˜¯å¦å»é‡, å»é‡å­—æ®µåˆ—è¡¨)
        """
        print(f"\n=== æ­¥éª¤4: å»é‡é…ç½® ===")
        
        # è¯¢é—®æ˜¯å¦éœ€è¦å»é‡
        print("ğŸ¤” æ˜¯å¦éœ€è¦å»é‡ï¼Ÿ")
        print("ğŸ“ å»é‡å°†åˆ é™¤é‡å¤çš„è®°å½•ï¼Œä¿ç•™ç¬¬ä¸€æ¡")
        dedup_choice = input("è¯·é€‰æ‹© (y/nï¼Œé»˜è®¤y): ").strip().lower()
        self.deduplicate = dedup_choice not in ['n', 'no', 'å¦']
        
        if not self.deduplicate:
            print("âœ… å·²é€‰æ‹©ä¸å»é‡ï¼Œå°†ä¿ç•™æ‰€æœ‰è®°å½•")
            return False, []
        
        # è¯¢é—®æ˜¯å¦å¯ç”¨äº¤äº’å¼å»é‡
        print(f"\nğŸ¤– å»é‡æ¨¡å¼é€‰æ‹©:")
        print(f"ğŸ“ è‡ªåŠ¨å»é‡: å­¦å·+å§“åç›¸åŒçš„è®°å½•è‡ªåŠ¨åˆå¹¶ï¼Œå­¦å·ç›¸åŒä½†å§“åä¸åŒçš„ä¿ç•™ç¬¬ä¸€æ¡")
        print(f"ğŸ¯ äº¤äº’å¼å»é‡: å­¦å·+å§“åç›¸åŒçš„è®°å½•è‡ªåŠ¨åˆå¹¶ï¼Œå­¦å·ç›¸åŒä½†å§“åä¸åŒæ—¶è¯¢é—®å¤„ç†æ–¹å¼")
        interactive_choice = input("æ˜¯å¦å¯ç”¨äº¤äº’å¼å»é‡ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        self.enable_interactive_dedup = interactive_choice not in ['n', 'no', 'å¦']
        
        if self.enable_interactive_dedup:
            print("âœ… å·²å¯ç”¨äº¤äº’å¼å»é‡ï¼Œå­¦å·ç›¸åŒä½†å§“åä¸åŒæ—¶ä¼šè¯¢é—®æ‚¨çš„å¤„ç†æ–¹å¼")
        else:
            print("âœ… ä½¿ç”¨è‡ªåŠ¨å»é‡æ¨¡å¼ï¼Œå­¦å·ç›¸åŒä½†å§“åä¸åŒæ—¶å°†è‡ªåŠ¨ä¿ç•™ç¬¬ä¸€æ¡è®°å½•")
        
        # å¦‚æœå»é‡ï¼Œé€‰æ‹©å»é‡å­—æ®µ
        print(f"\nğŸ“‹ è¯·é€‰æ‹©å»é‡å­—æ®µï¼ˆåŸºäºè¿™äº›å­—æ®µçš„ç»„åˆæ¥åˆ¤æ–­é‡å¤ï¼‰:")
        print("å¯ç”¨å­—æ®µåˆ—è¡¨:")
        for i, field in enumerate(self.selected_fields, 1):
            print(f"{i:2d}. {field}")
        
        print(f"\nğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2ï¼‰")
        print(f"ğŸ“ è¾“å…¥å­—æ®µåç§°ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼šå­¦å·,å­¦ç”Ÿå§“åï¼‰")
        print(f"ğŸ“ æ”¯æŒé€šé…ç¬¦åŒ¹é…ï¼ˆ*ä»£è¡¨ä»»æ„ä¸€ä¸ªå­—ç¬¦ï¼Œå¦‚ï¼š*å­¦å·,å­¦*å·ï¼‰")
        print(f"ğŸ“ æ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚ï¼šå­¦å· å¯åŒ¹é… å­¦ç”Ÿå­¦å·ã€å­¦å·ä¿¡æ¯ç­‰ï¼‰")
        print(f"ğŸ“ è¾“å…¥ 'all' ä½¿ç”¨æ‰€æœ‰é€‰ä¸­å­—æ®µè¿›è¡Œå»é‡")
        print(f"ğŸ“ è¾“å…¥ 'single 1' åªä½¿ç”¨ç¬¬1ä¸ªå­—æ®µå»é‡")
        
        try:
            choice = input("\nè¯·é€‰æ‹©å»é‡å­—æ®µ: ").strip().lower()
            
            if choice.lower() == 'all':
                self.dedup_fields = self.selected_fields.copy()
                print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(self.dedup_fields)} ä¸ªå­—æ®µè¿›è¡Œå»é‡")
            elif choice.startswith('single '):
                try:
                    field_idx = int(choice.split()[1]) - 1
                    if 0 <= field_idx < len(self.selected_fields):
                        self.dedup_fields = [self.selected_fields[field_idx]]
                        print(f"âœ… å·²é€‰æ‹©å•ä¸ªå­—æ®µè¿›è¡Œå»é‡: {self.dedup_fields[0]}")
                    else:
                        print("âŒ å­—æ®µç¼–å·è¶…å‡ºèŒƒå›´")
                        return self.configure_deduplication()
                except:
                    print("âŒ å­—æ®µç¼–å·æ ¼å¼é”™è¯¯")
                    return self.configure_deduplication()
            else:
                # è§£æç”¨æˆ·é€‰æ‹©
                selected_items = [item.strip() for item in choice.split(',')]
                self.dedup_fields = []
                
                for item in selected_items:
                    # å°è¯•ä½œä¸ºæ•°å­—å¤„ç†
                    try:
                        index = int(item) - 1
                        if 0 <= index < len(self.selected_fields):
                            self.dedup_fields.append(self.selected_fields[index])
                        else:
                            print(f"âš ï¸  å­—æ®µç¼–å· {item} è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡")
                    except ValueError:
                        # ä½¿ç”¨å¢å¼ºçš„å­—æ®µåŒ¹é…å‡½æ•°
                        matched_fields, match_type = self.enhanced_field_matching(item, self.selected_fields)
                        
                        if len(matched_fields) == 1:
                            # å•ä¸ªåŒ¹é…ï¼Œç›´æ¥æ·»åŠ 
                            self.dedup_fields.append(matched_fields[0])
                            if match_type != "ç²¾ç¡®åŒ¹é…":
                                print(f"ğŸ“ {match_type}å­—æ®µ: {item} -> {matched_fields[0]}")
                        elif len(matched_fields) > 1:
                            # å¤šä¸ªåŒ¹é…ï¼Œè¯¢é—®ç”¨æˆ·
                            print(f"\nğŸ” {match_type} '{item}' åŒ¹é…åˆ° {len(matched_fields)} ä¸ªå­—æ®µ:")
                            for i, field in enumerate(matched_fields, 1):
                                print(f"  {i}. {field}")
                            
                            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä½¿ç”¨è¿™äº›åŒ¹é…çš„å­—æ®µ
                            print(f"\nğŸ¤” æ˜¯å¦ä½¿ç”¨è¿™äº›åŒ¹é…çš„å­—æ®µè¿›è¡Œå»é‡ï¼Ÿ")
                            print(f"ğŸ“ è¾“å…¥ 'y' ä½¿ç”¨æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            print(f"ğŸ“ è¾“å…¥ 'n' è·³è¿‡æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            print(f"ğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼ˆå¦‚ï¼š1,3ï¼‰é€‰æ‹©ç‰¹å®šå­—æ®µ")
                            use_choice = input(f"\nè¯·é€‰æ‹©: ").strip().lower()
                            
                            if use_choice in ['y', 'yes', 'æ˜¯']:
                                self.dedup_fields.extend(matched_fields)
                                print(f"âœ… å·²æ·»åŠ  {len(matched_fields)} ä¸ªåŒ¹é…å­—æ®µ")
                            elif use_choice in ['n', 'no', 'å¦']:
                                print(f"âš ï¸  è·³è¿‡ '{item}' çš„æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            else:
                                # ç”¨æˆ·é€‰æ‹©äº†ç‰¹å®šå­—æ®µç¼–å·
                                try:
                                    selected_indices = [int(x.strip()) - 1 for x in use_choice.split(',')]
                                    selected_fields = [matched_fields[i] for i in selected_indices if 0 <= i < len(matched_fields)]
                                    if selected_fields:
                                        self.dedup_fields.extend(selected_fields)
                                        print(f"âœ… å·²æ·»åŠ  {len(selected_fields)} ä¸ªé€‰å®šå­—æ®µ")
                                    else:
                                        print(f"âš ï¸  æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè·³è¿‡")
                                except (ValueError, IndexError):
                                    print(f"âš ï¸  è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡æ‰€æœ‰åŒ¹é…å­—æ®µ")
                        else:
                            # æ— åŒ¹é…
                            print(f"âš ï¸  æœªæ‰¾åˆ°åŒ¹é…å­—æ®µ '{item}'ï¼Œè·³è¿‡")
                
                if not self.dedup_fields:
                    print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè¯·é‡æ–°é€‰æ‹©")
                    return self.configure_deduplication()
                
                # å»é‡å¹¶ä¿æŒé¡ºåº
                seen = set()
                unique_fields = []
                for field in self.dedup_fields:
                    if field not in seen:
                        seen.add(field)
                        unique_fields.append(field)
                self.dedup_fields = unique_fields
                
                print(f"âœ… å·²é€‰æ‹© {len(self.dedup_fields)} ä¸ªå­—æ®µè¿›è¡Œå»é‡:")
                for field in self.dedup_fields:
                    print(f"  ğŸ” {field}")
                
            return True, self.dedup_fields
            
        except Exception as e:
            print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {str(e)}ï¼Œè¯·é‡æ–°é€‰æ‹©")
            return self.configure_deduplication()
    
    def process_data(self, files: List[str], selected_fields: List[str], 
                    deduplicate: bool, dedup_fields: List[str]) -> pd.DataFrame:
        """
        æ•°æ®å¤„ç†ä¸»å‡½æ•°
        
        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            selected_fields: é€‰ä¸­çš„å­—æ®µ
            deduplicate: æ˜¯å¦å»é‡
            dedup_fields: å»é‡å­—æ®µåˆ—è¡¨
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ¡†
        """
        print(f"\n=== æ­¥éª¤5: æ•°æ®å¤„ç† ===")
        all_data = []
        total_rows = 0
        
        print("ğŸ”„ å¼€å§‹å¤„ç†æ–‡ä»¶...")
        
        for i, file in enumerate(files, 1):
            try:
                print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(files)}: {os.path.basename(file)}")
                df = pd.read_excel(file)
                
                # ä½¿ç”¨æ™ºèƒ½åˆ—ååŒ¹é…éªŒè¯å¿…éœ€å­—æ®µ
                is_valid, missing_fields, column_mapping = self.validate_required_columns(df, selected_fields)
                
                if not is_valid:
                    print(f"âš ï¸  è­¦å‘Šï¼šæ–‡ä»¶ç¼ºå°‘å­—æ®µ {missing_fields}")
                    
                    # è¯¢é—®ç”¨æˆ·æ˜¯å¦è¦å¤„ç†æ­¤æ–‡ä»¶
                    print(f"ğŸ¤” æ˜¯å¦è¦å¤„ç†æ­¤æ–‡ä»¶ï¼Ÿ")
                    print(f"  1. æ˜¯ï¼Œä¸ºç¼ºå¤±å­—æ®µå¡«å……é»˜è®¤å€¼")
                    print(f"  2. å¦ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
                    
                    while True:
                        try:
                            choice = input("è¯·é€‰æ‹© (1-2ï¼Œé»˜è®¤1): ").strip()
                            if not choice:
                                choice = "1"
                            
                            if choice == "1":
                                print("âœ… ç»§ç»­å¤„ç†ï¼Œä¸ºç¼ºå¤±å­—æ®µå¡«å……é»˜è®¤å€¼")
                                break
                            elif choice == "2":
                                print("â­ï¸  è·³è¿‡æ­¤æ–‡ä»¶")
                                continue
                            else:
                                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")
                        except (EOFError, KeyboardInterrupt):
                            print("âœ… ä½¿ç”¨é»˜è®¤é€‰æ‹©ï¼šç»§ç»­å¤„ç†")
                            break
                    
                    # ä¸ºç¼ºå¤±å­—æ®µå¡«å……é»˜è®¤å€¼
                    for field in missing_fields:
                        if field not in column_mapping:
                            # æ ¹æ®å­—æ®µç±»å‹å¡«å……åˆé€‚çš„é»˜è®¤å€¼
                            if self._is_money_field(field):
                                default_value = 0
                            elif "åç§°" in field or "å§“å" in field:
                                default_value = "<ç©ºå€¼>"
                            elif "ç¼–å·" in field or "ID" in field:
                                default_value = "<ç©ºå€¼>"
                            else:
                                default_value = "<ç©ºå€¼>"
                            
                            # åœ¨æ•°æ®æ¡†ä¸­æ·»åŠ ç¼ºå¤±å­—æ®µï¼Œå¡«å……é»˜è®¤å€¼
                            df[field] = default_value
                            print(f"ğŸ“ ä¸ºç¼ºå¤±å­—æ®µ '{field}' å¡«å……é»˜è®¤å€¼: {default_value}")
                    
                    # é‡æ–°éªŒè¯å­—æ®µ
                    is_valid, missing_fields, column_mapping = self.validate_required_columns(df, selected_fields)
                    if not is_valid:
                        print(f"âŒ å­—æ®µéªŒè¯ä»ç„¶å¤±è´¥ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
                        continue
                
                # ä½¿ç”¨æ˜ å°„åçš„åˆ—å
                mapped_fields = [column_mapping.get(field, field) for field in selected_fields]
                print(f"ğŸ“‹ ä½¿ç”¨æ˜ å°„åçš„åˆ—å: {mapped_fields}")
                
                # ä½¿ç”¨æ˜ å°„åçš„åˆ—åæå–æ•°æ®
                selected_data = df[mapped_fields].copy()
                
                # å°†åˆ—åé‡å‘½åä¸ºæ ‡å‡†åç§°ï¼Œå¹¶æŒ‰ç…§ç”¨æˆ·é€‰æ‹©çš„é¡ºåºé‡æ–°æ’åˆ—
                rename_mapping = {}
                for i, field in enumerate(selected_fields):
                    if mapped_fields[i] != field:
                        rename_mapping[mapped_fields[i]] = field
                
                if rename_mapping:
                    selected_data = selected_data.rename(columns=rename_mapping)
                    print(f"ğŸ“ åˆ—åé‡å‘½å: {rename_mapping}")
                
                # æŒ‰ç…§ç”¨æˆ·é€‰æ‹©çš„å­—æ®µé¡ºåºé‡æ–°æ’åˆ—åˆ—
                selected_data = selected_data[selected_fields]
                print(f"ğŸ“‹ æŒ‰ç”¨æˆ·é€‰æ‹©é¡ºåºæ’åˆ—å­—æ®µ: {selected_fields}")
                
                # æ·»åŠ æ–‡ä»¶æ¥æºä¿¡æ¯
                selected_data['æ•°æ®æ¥æºæ–‡ä»¶'] = os.path.basename(file)
                selected_data['æ•°æ®æ¥æºè·¯å¾„'] = os.path.abspath(file)
                
                all_data.append(selected_data)
                file_rows = len(selected_data)
                total_rows += file_rows
                print(f"âœ… æˆåŠŸè¯»å– {file_rows} è¡Œæ•°æ®")
                
            except Exception as e:
                print(f"âŒ é”™è¯¯ï¼šå¤„ç†æ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
                continue
        
        if not all_data:
            print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ•°æ®")
            return pd.DataFrame()
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        print(f"\nğŸ”„ æ­£åœ¨åˆå¹¶æ•°æ®...")
        combined_df = pd.concat(all_data, ignore_index=True)
        print(f"âœ… åˆå¹¶å®Œæˆï¼Œæ€»è¡Œæ•°: {len(combined_df)}")
        

        
        # å»é‡å¤„ç†
        if deduplicate and dedup_fields:
            print(f"\nğŸ”„ æ­£åœ¨æŒ‰å­—æ®µ {dedup_fields} å»é‡...")
            before_count = len(combined_df)
            
            # æ™ºèƒ½è¯†åˆ«å­¦å·å’Œå§“åå­—æ®µ
            student_id_field = None
            student_name_field = None
            
            # æ™ºèƒ½è¯†åˆ«å­¦å·å­—æ®µ
            student_id_field = self._identify_student_id_field(dedup_fields, combined_df.columns)
            
            # æ™ºèƒ½è¯†åˆ«å§“åå­—æ®µ
            student_name_field = self._identify_name_field(combined_df.columns)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å­¦å·å­—æ®µï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå»é‡å­—æ®µä½œä¸ºä¸»é”®å­—æ®µ
            if not student_id_field and dedup_fields:
                student_id_field = dedup_fields[0]
            
            print(f"ğŸ“‹ æ£€æµ‹åˆ°çš„å­—æ®µ:")
            if student_id_field:
                field_icon = self._get_field_icon(student_id_field)
                print(f"  {field_icon} ä¸»é”®å­—æ®µ: {student_id_field}")
            else:
                print(f"  ğŸ”‘ ä¸»é”®å­—æ®µ: {dedup_fields[0] if dedup_fields else 'None'}")
            
            if student_name_field:
                field_icon = self._get_field_icon(student_name_field)
                print(f"  {field_icon} å§“åå­—æ®µ: {student_name_field}")
            else:
                print(f"  ğŸ‘¤ å§“åå­—æ®µ: None")
            
            # æŸ¥æ‰¾é‡å¤è®°å½•ï¼ˆåŸºäºå»é‡å­—æ®µï¼‰
            duplicated_mask = combined_df.duplicated(subset=dedup_fields, keep=False)
            duplicated_records = combined_df[duplicated_mask]
            
            # ä¿å­˜é‡å¤è®°å½•åˆ°å®ä¾‹å˜é‡
            self.duplicate_records = duplicated_records.copy()
            self.duplicate_count = len(duplicated_records)
            
            if len(duplicated_records) > 0:
                print(f"\n" + "ğŸ”" + "="*58)
                print(f"ğŸ“‹ å‘ç°é‡å¤è®°å½•è¯¦æƒ…")
                print(f"ğŸ”" + "="*58)
                print(f"ğŸ“Š é‡å¤è®°å½•æ€»æ•°: {len(duplicated_records)} æ¡")
                print(f"ğŸ“Š é‡å¤ç»„æ•°é‡: {duplicated_records.groupby(dedup_fields).ngroups} ç»„")
                print(f"ğŸ”‘ å»é‡ä¾æ®å­—æ®µ: {', '.join(dedup_fields)}")
                
                # æŒ‰å»é‡å­—æ®µåˆ†ç»„æ˜¾ç¤ºé‡å¤è®°å½•
                duplicate_groups = duplicated_records.groupby(dedup_fields)
                group_count = 0
                conflict_group_count = 0  # æœ‰å†²çªçš„ç»„æ•°é‡
                
                for group_key, group_df in duplicate_groups:
                    # æ£€æŸ¥è¿™ä¸ªç»„æ˜¯å¦æœ‰çœŸæ­£çš„å†²çªï¼ˆå­¦å·ç›¸åŒä½†å§“åä¸åŒï¼‰
                    has_conflict = self._group_has_student_name_conflict(group_df, dedup_fields, student_name_field)
                    
                    if has_conflict:
                        conflict_group_count += 1
                        if conflict_group_count <= 10:  # æœ€å¤šæ˜¾ç¤ºå‰10ç»„æœ‰å†²çªçš„é‡å¤è®°å½•
                            print(f"\n  {'='*50}")
                            print(f"  ğŸ“ å†²çªé‡å¤ç»„ {conflict_group_count} (å…± {len(group_df)} æ¡é‡å¤è®°å½•)")
                            print(f"  {'='*50}")
                            
                            # æ˜¾ç¤ºé‡å¤å­—æ®µçš„å€¼
                            if isinstance(group_key, tuple):
                                for i, field in enumerate(dedup_fields):
                                    display_value = self._format_display_value(group_key[i])
                                    print(f"  ğŸ”‘ {field}: {display_value}")
                            else:
                                display_value = self._format_display_value(group_key)
                                print(f"  ğŸ”‘ {dedup_fields[0]}: {display_value}")
                            
                            # å®šä¹‰éå»é‡å­—æ®µåˆ—è¡¨ï¼ˆåœ¨ä½¿ç”¨å‰å®šä¹‰ï¼‰
                            non_dedup_fields = [field for field in group_df.columns if field not in dedup_fields]
                            
                            # æ˜¾ç¤ºæ¶‰åŠçš„æ–‡ä»¶
                            if 'æ•°æ®æ¥æºæ–‡ä»¶' in group_df.columns:
                                # åŸºäºæ–‡ä»¶å+è·¯å¾„å»é‡
                                file_refs = group_df[['æ•°æ®æ¥æºæ–‡ä»¶', 'æ•°æ®æ¥æºè·¯å¾„']].drop_duplicates()
                                # å…ˆåšé€æ–‡ä»¶æ ¡éªŒï¼Œå¾—åˆ°å¯ç”¨æ–‡ä»¶æ¸…å•
                                verified_by_path: Dict[str, bool] = {}
                                for _, ref in file_refs.iterrows():
                                    full_path = str(ref['æ•°æ®æ¥æºè·¯å¾„'])
                                    try:
                                        ok = self._verify_group_key_in_file(full_path, dedup_fields, group_key)
                                    except Exception:
                                        ok = False
                                    verified_by_path[full_path] = ok

                                # ä»…å±•ç¤ºæ ¡éªŒé€šè¿‡çš„æ–‡ä»¶
                                verified_files = [str(ref['æ•°æ®æ¥æºæ–‡ä»¶']) for _, ref in file_refs.iterrows() if verified_by_path.get(str(ref['æ•°æ®æ¥æºè·¯å¾„']), False)]
                                skipped_files = [str(ref['æ•°æ®æ¥æºæ–‡ä»¶']) for _, ref in file_refs.iterrows() if not verified_by_path.get(str(ref['æ•°æ®æ¥æºè·¯å¾„']), False)]

                                if verified_files:
                                    print(f"  ğŸ“ æ¶‰åŠæ–‡ä»¶: {', '.join(verified_files)}")
                                if skipped_files:
                                    print(f"  âš ï¸ å·²å¿½ç•¥æœªåœ¨æºæ–‡ä»¶æ‰¾åˆ°çš„æ–‡ä»¶: {', '.join(skipped_files)}")
                                
                                # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ¯ä¸ªæ–‡ä»¶çš„è®°å½•æ•°å’Œå…·ä½“å†…å®¹ï¼ˆå¹¶æ ¡éªŒæ˜¯å¦çœŸå®å­˜åœ¨ï¼‰
                                print(f"  ğŸ” è¯¦ç»†åˆ†å¸ƒ:")
                                for _, ref in file_refs.iterrows():
                                    base_name = str(ref['æ•°æ®æ¥æºæ–‡ä»¶'])
                                    full_path = str(ref['æ•°æ®æ¥æºè·¯å¾„'])
                                    file_records = group_df[group_df['æ•°æ®æ¥æºè·¯å¾„'] == full_path]
                                    exists_in_src = verified_by_path.get(full_path, False)
                                    # åªæ˜¾ç¤ºæ ¡éªŒé€šè¿‡çš„æ–‡ä»¶è¯¦æƒ…
                                    if not exists_in_src:
                                        continue
                                    print(f"     â€¢ {base_name}: {len(file_records)} æ¡è®°å½•")
                                    print(f"       æ ¡éªŒ: âœ… å·²åœ¨æºæ–‡ä»¶æ‰¾åˆ°")
                                    
                                    # æ˜¾ç¤ºè¯¥æ–‡ä»¶ä¸­çš„å…·ä½“è®°å½•å†…å®¹ï¼ˆæ˜¾ç¤ºæ‰€æœ‰å­—æ®µç”¨äºè°ƒè¯•ï¼‰
                                    for idx, (_, record) in enumerate(file_records.iterrows()):
                                        if idx >= 2:  # æœ€å¤šæ˜¾ç¤º2æ¡è®°å½•
                                            if len(file_records) > 2:
                                                print(f"       ... è¿˜æœ‰ {len(file_records) - 2} æ¡è®°å½•")
                                            break
                                        
                                        record_info = []
                                        # æ˜¾ç¤ºæ‰€æœ‰å­—æ®µï¼ˆåŒ…æ‹¬å»é‡å­—æ®µï¼‰ç”¨äºè°ƒè¯•
                                        for field in group_df.columns:
                                            if field in ('æ•°æ®æ¥æºæ–‡ä»¶', 'æ•°æ®æ¥æºè·¯å¾„'):
                                                continue
                                            value = record[field]
                                            if pd.notna(value) and str(value).strip():
                                                display_value = self._format_display_value(value)
                                                record_info.append(f"{field}={display_value}")
                                            else:
                                                record_info.append(f"{field}=<ç©ºå€¼>")
                                        
                                        print(f"       [{idx+1}] {', '.join(record_info)}")
                            
                            print(f"  {'-'*40}")
                            
                            # è°ƒè¯•ï¼šæ˜¾ç¤ºæ•°æ®æ¡†çš„å®Œæ•´ç»“æ„ä¿¡æ¯
                            print(f"  ğŸ”§ è°ƒè¯•ä¿¡æ¯:")
                            # åªåŸºäºæ ¡éªŒé€šè¿‡çš„è¡Œç»Ÿè®¡
                            if 'æ•°æ®æ¥æºè·¯å¾„' in group_df.columns:
                                verified_mask = group_df['æ•°æ®æ¥æºè·¯å¾„'].map(lambda p: verified_by_path.get(str(p), False))
                                group_df_verified = group_df[verified_mask] if verified_mask.any() else group_df.iloc[0:0]
                            else:
                                group_df_verified = group_df

                            print(f"     â€¢ æ•°æ®æ¡†å½¢çŠ¶: {group_df_verified.shape}")
                            print(f"     â€¢ æ‰€æœ‰å­—æ®µ: {list(group_df.columns)}")
                            print(f"     â€¢ å»é‡å­—æ®µ: {dedup_fields}")
                            print(f"     â€¢ éå»é‡å­—æ®µ: {non_dedup_fields}")
                            
                            # åˆ†æå¹¶æ˜¾ç¤ºå†²çªçš„å…·ä½“æƒ…å†µ
                            conflict_summary = {}
                            
                            # æ‰¾å‡ºæ¯ä¸ªå­—æ®µçš„ä¸åŒå€¼ï¼ˆæ’é™¤æ–‡ä»¶æ¥æºå­—æ®µï¼‰
                            for field in non_dedup_fields:
                                if field in ('æ•°æ®æ¥æºæ–‡ä»¶', 'æ•°æ®æ¥æºè·¯å¾„'):  # è·³è¿‡æ–‡ä»¶æ¥æºå­—æ®µ
                                    continue
                                unique_vals = []
                                seen = set()
                                for value in group_df_verified[field] if not group_df_verified.empty else []:
                                    if pd.isna(value):
                                        str_val = "<ç©ºå€¼>"
                                    else:
                                        str_val = str(value).strip()
                                    if str_val not in seen:
                                        seen.add(str_val)
                                        unique_vals.append(str_val)
                                
                                if len([v for v in unique_vals if v != "<ç©ºå€¼>"]) > 1:
                                    conflict_summary[field] = unique_vals
                            
                            # æ˜¾ç¤ºå†²çªå­—æ®µçš„ä¸åŒå€¼ï¼ˆæ±‡æ€»ï¼šæ¯ä¸ªå–å€¼çš„æ•°é‡ä¸æ¥æºæ–‡ä»¶ï¼‰
                            if conflict_summary:
                                print(f"  ğŸ” å†²çªå­—æ®µåŠå…¶ä¸åŒå€¼ï¼ˆæŒ‰å–å€¼ç»Ÿè®¡ï¼‰:")
                                for field in conflict_summary:
                                    # ä¸ºè¯¥å­—æ®µç»Ÿè®¡ä¸åŒå–å€¼çš„æ•°é‡ä¸æ¥æºæ–‡ä»¶
                                    value_to_count: Dict[str, int] = {}
                                    value_to_files: Dict[str, set] = {}

                                    for _, row in group_df_verified.iterrows() if not group_df_verified.empty else []:
                                        raw_val = row[field]
                                        if pd.isna(raw_val) or (isinstance(raw_val, str) and raw_val.strip() == ""):
                                            disp_val = "<ç©ºå€¼>"
                                        else:
                                            disp_val = self._format_display_value(raw_val).strip()

                                        value_to_count[disp_val] = value_to_count.get(disp_val, 0) + 1
                                        if 'æ•°æ®æ¥æºæ–‡ä»¶' in group_df.columns:
                                            src_file = row['æ•°æ®æ¥æºæ–‡ä»¶']
                                            value_to_files.setdefault(disp_val, set()).add(str(src_file))

                                    # ä»…ä¿ç•™éç©ºå€¼ç”¨äºå†²çªå±•ç¤º
                                    non_empty_items = [(v, c) for v, c in value_to_count.items() if v != "<ç©ºå€¼>"]
                                    # æŒ‰æ•°é‡é™åº
                                    non_empty_items.sort(key=lambda x: x[1], reverse=True)

                                    print(f"     â€¢ {field}: å…± {len(non_empty_items)} ç§ä¸åŒå–å€¼")
                                    for val, cnt in non_empty_items:
                                        files_list = sorted(list(value_to_files.get(val, [])))
                                        files_str = ", ".join(files_list) if files_list else "-"
                                        print(f"       - {val}: {cnt} æ¡ (æ¥æº: {files_str})")

                                print(f"  {'-'*40}")

                            # ç»Ÿè®¡è¯´æ˜ï¼ˆä¸å†å±•ç¤ºæ ·æœ¬è®°å½•ï¼Œé¿å…é‡å¤ä¸è¯¯è§£ï¼‰
                            total_shown = len(group_df_verified) if not group_df_verified.empty else 0
                            print(f"  ğŸ’¡ å·²åŸºäºæ ¡éªŒé€šè¿‡çš„ {total_shown} æ¡è®°å½•è¿›è¡Œç»Ÿè®¡å±•ç¤ºã€‚")

                            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                            if len(group_df_verified) > 0:
                                remaining = 0  # å·²ä»¥æ±‡æ€»æ–¹å¼å±•ç¤ºï¼Œä¸å†å•ç‹¬æ˜¾ç¤ºæ ·æœ¬ä¸å‰©ä½™æ¡ç›®
                                if remaining > 0:
                                    print(f"  ğŸ’¡ è¿˜æœ‰ {remaining} æ¡è®°å½•ä¸ä¸Šè¿°å–å€¼é‡å¤")
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤º
                total_duplicate_groups = duplicated_records.groupby(dedup_fields).ngroups
                if conflict_group_count > 0:
                    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
                    print(f"  ğŸ“‹ æ€»é‡å¤ç»„æ•°: {total_duplicate_groups}")
                    print(f"  âš ï¸  æœ‰å†²çªçš„é‡å¤ç»„: {conflict_group_count}")
                    print(f"  âœ… å®Œå…¨ç›¸åŒçš„é‡å¤ç»„: {total_duplicate_groups - conflict_group_count}")
                    if conflict_group_count > 10:
                        print(f"  ğŸ’¡ åªæ˜¾ç¤ºäº†å‰10ç»„æœ‰å†²çªçš„é‡å¤è®°å½•")
                else:
                    print(f"\nâœ… æ‰€æœ‰é‡å¤è®°å½•éƒ½æ˜¯å®Œå…¨ç›¸åŒçš„ï¼Œå°†è‡ªåŠ¨å»é™¤ï¼Œæ— éœ€ç”¨æˆ·å¤„ç†")
                
                # å»é‡ç­–ç•¥è¯´æ˜å·²ç§»é™¤
            
            # æ‰§è¡Œå»é‡å¤„ç†
            if len(duplicated_records) > 0:
                processed_records = []
                duplicate_groups = duplicated_records.groupby(dedup_fields)
                conflicts_found = 0
                
                for group_key, group_df in duplicate_groups:
                    resolved_records, had_conflict = self.resolve_student_conflicts(group_key, group_df, dedup_fields, student_name_field, student_id_field)
                    if not resolved_records.empty:
                        processed_records.append(resolved_records)
                    if had_conflict:
                        conflicts_found += 1
                
                if processed_records:
                    # é‡æ–°æ„å»ºæ•°æ®æ¡†ï¼šéé‡å¤è®°å½• + å¤„ç†åçš„é‡å¤è®°å½•
                    non_duplicated_records = combined_df[~duplicated_mask]
                    processed_duplicates = pd.concat(processed_records, ignore_index=True)
                    combined_df = pd.concat([non_duplicated_records, processed_duplicates], ignore_index=True)
                else:
                    # å¦‚æœæ‰€æœ‰é‡å¤ç»„éƒ½è¢«è·³è¿‡ï¼Œåªä¿ç•™éé‡å¤è®°å½•
                    combined_df = combined_df[~duplicated_mask]
                
                after_count = len(combined_df)
                removed_count = before_count - after_count
                
                # æ˜¾ç¤ºå¤„ç†ç»“æœ
                if conflicts_found > 0:
                    print(f"\nğŸ”„ å»é‡å¤„ç†å®Œæˆ:")
                    if student_id_field and student_name_field:
                        id_icon = self._get_field_icon(student_id_field)
                        name_icon = self._get_field_icon(student_name_field)
                        print(f"  ğŸ“Š å‘ç°{name_icon}å†²çªçš„{id_icon}: {conflicts_found} ä¸ª")
                    else:
                        print(f"  ğŸ“Š å‘ç°å­—æ®µå†²çªçš„é‡å¤ç»„: {conflicts_found} ä¸ª")
                    print(f"  âœ… è‡ªåŠ¨åˆå¹¶çš„é‡å¤è®°å½•: {len(duplicate_groups) - conflicts_found} ç»„")
                else:
                    if student_id_field and student_name_field:
                        id_icon = self._get_field_icon(student_id_field)
                        name_icon = self._get_field_icon(student_name_field)
                        print(f"\nâœ… å»é‡å¤„ç†å®Œæˆ: æ‰€æœ‰é‡å¤è®°å½•éƒ½æ˜¯{id_icon}+{name_icon}å®Œå…¨ç›¸åŒï¼Œå·²è‡ªåŠ¨åˆå¹¶")
                    else:
                        print(f"\nâœ… å»é‡å¤„ç†å®Œæˆ: æ‰€æœ‰é‡å¤è®°å½•éƒ½æ˜¯å®Œå…¨ç›¸åŒçš„ï¼Œå·²è‡ªåŠ¨åˆå¹¶")
                
                # æ›´æ–°é‡å¤è®°å½•ç»Ÿè®¡ï¼Œé¿å…å¯¼å‡ºæ—¶é•¿åº¦ä¸åŒ¹é…
                # é‡æ–°è®¡ç®—å®é™…è¢«å¤„ç†çš„é‡å¤è®°å½•
                if processed_records:
                    # ä¿å­˜åŸå§‹çš„é‡å¤è®°å½•ç”¨äºå¯¼å‡º
                    self.duplicate_records = duplicated_records.copy()
                    # æ›´æ–°é‡å¤è®°å½•æ•°é‡ä¸ºå®é™…å¤„ç†çš„æ•°é‡
                    self.duplicate_count = len(duplicated_records)
            else:
                # ä¼ ç»Ÿè‡ªåŠ¨å»é‡
                combined_df = combined_df.drop_duplicates(subset=dedup_fields, keep='first')
                after_count = len(combined_df)
                removed_count = before_count - after_count
            
            print(f"\nâœ… å»é‡å®Œæˆ:")
            print(f"  ğŸ“Š å»é‡å‰è¡Œæ•°: {before_count}")
            print(f"  ğŸ“Š å»é‡åè¡Œæ•°: {after_count}")
            print(f"  ğŸ—‘ï¸  åˆ é™¤é‡å¤è®°å½•: {removed_count}")
            
            if removed_count > 0:
                print(f"  ğŸ“ˆ å»é‡ç‡: {removed_count/before_count*100:.1f}%")
        
        return combined_df
    
    def export_to_excel(self, df: pd.DataFrame, output_filename: str = None):
        """
        å¯¼å‡ºåˆ°Excel
        
        Args:
            df: æ•°æ®æ¡†
            output_filename: è¾“å‡ºæ–‡ä»¶å
        """
        if output_filename is None:
            output_filename = self.output_filename
        
        print(f"\n=== æ­¥éª¤6: å¯¼å‡ºç»“æœ ===")
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        output_path = output_filename
        if not os.path.dirname(output_path):
            output_path = os.path.join(".", output_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(output_path):
            print(f"âš ï¸  æ–‡ä»¶ '{output_filename}' å·²å­˜åœ¨")
            overwrite = input("æ˜¯å¦è¦†ç›–ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            if overwrite not in ['y', 'yes', 'æ˜¯']:
                # ç”Ÿæˆæ–°æ–‡ä»¶å
                base_name = os.path.splitext(output_filename)[0]
                extension = os.path.splitext(output_filename)[1]
                counter = 1
                while True:
                    new_filename = f"{base_name}_{counter}{extension}"
                    new_output_path = os.path.join(".", new_filename)
                    if not os.path.exists(new_output_path):
                        output_path = new_output_path
                        output_filename = new_filename
                        print(f"ğŸ“ ä½¿ç”¨æ–°æ–‡ä»¶å: {new_filename}")
                        break
                    counter += 1
            else:
                # å°è¯•åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶
                try:
                    os.remove(output_path)
                    print(f"âœ… å·²åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶: {output_filename}")
                except PermissionError:
                    print(f"âŒ æ— æ³•åˆ é™¤æ–‡ä»¶ '{output_filename}'ï¼Œæ–‡ä»¶å¯èƒ½è¢«å…¶ä»–ç¨‹åºå ç”¨")
                    print("è¯·å…³é—­Excelæˆ–å…¶ä»–å¯èƒ½æ‰“å¼€è¯¥æ–‡ä»¶çš„ç¨‹åºï¼Œç„¶åé‡è¯•")
                    return None
                except Exception as e:
                    print(f"âŒ åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                    return None
        
        try:
            # åˆ›å»ºExcelå†™å…¥å™¨ï¼Œæ”¯æŒå¤šä¸ªå·¥ä½œè¡¨
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # ä¸»æ•°æ®è¡¨
                df.to_excel(writer, sheet_name='åˆå¹¶æ•°æ®', index=False)
                
                # ç»Ÿè®¡ä¿¡æ¯è¡¨
                stats_items = [
                    'æ€»è®°å½•æ•°',
                    'å¤„ç†æ–‡ä»¶æ•°',
                    'é€‰æ‹©å­—æ®µæ•°',
                    'æ˜¯å¦å»é‡',
                    'å»é‡å­—æ®µæ•°',
                    'åˆ é™¤é‡å¤è®°å½•æ•°'
                ]
                stats_values = [
                    len(df),
                    len(self.selected_files),
                    len(self.selected_fields),
                    'æ˜¯' if self.deduplicate else 'å¦',
                    len(self.dedup_fields) if self.deduplicate else 0,
                    self.duplicate_count - len(df) if self.deduplicate and self.duplicate_count > 0 else 0
                ]
                

                
                stats_items.append('å¤„ç†æ—¶é—´')
                stats_values.append(pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'))
                
                stats_data = {
                    'ç»Ÿè®¡é¡¹ç›®': stats_items,
                    'æ•°å€¼': stats_values
                }
                stats_df = pd.DataFrame(stats_data)
                stats_df.to_excel(writer, sheet_name='å¤„ç†ç»Ÿè®¡', index=False)
                
                # å­—æ®µä¿¡æ¯è¡¨
                field_info = {
                    'å­—æ®µåç§°': self.selected_fields,
                    'å­—æ®µç±»å‹': [str(df[field].dtype) for field in self.selected_fields],
                    'éç©ºå€¼æ•°é‡': [df[field].notna().sum() for field in self.selected_fields],
                    'ç©ºå€¼æ•°é‡': [df[field].isna().sum() for field in self.selected_fields]
                }
                field_df = pd.DataFrame(field_info)
                field_df.to_excel(writer, sheet_name='å­—æ®µä¿¡æ¯', index=False)
                
                # é‡å¤è®°å½•è¡¨ï¼ˆå¦‚æœæœ‰é‡å¤è®°å½•ï¼‰
                sheet_names = ['åˆå¹¶æ•°æ®', 'å¤„ç†ç»Ÿè®¡', 'å­—æ®µä¿¡æ¯']
                if not self.duplicate_records.empty:
                    # æ·»åŠ é‡å¤æ ‡è®°åˆ—
                    duplicate_export = self.duplicate_records.copy()
                    
                    # ä¸ºé‡å¤è®°å½•æ·»åŠ åˆ†ç»„ä¿¡æ¯
                    if self.dedup_fields:
                        try:
                            duplicate_groups = duplicate_export.groupby(self.dedup_fields)
                            group_ids = []
                            group_sizes = []
                            
                            for group_id, (group_key, group_df) in enumerate(duplicate_groups, 1):
                                for _ in range(len(group_df)):
                                    group_ids.append(group_id)
                                    group_sizes.append(len(group_df))
                            
                            # ç¡®ä¿é•¿åº¦åŒ¹é…
                            if len(group_ids) == len(duplicate_export):
                                duplicate_export.insert(0, 'é‡å¤ç»„ID', group_ids)
                                duplicate_export.insert(1, 'ç»„å†…é‡å¤æ•°', group_sizes)
                            else:
                                print(f"âš ï¸  é‡å¤è®°å½•åˆ†ç»„ä¿¡æ¯é•¿åº¦ä¸åŒ¹é…ï¼Œè·³è¿‡åˆ†ç»„æ ‡è®°")
                                print(f"   è®°å½•æ•°: {len(duplicate_export)}, åˆ†ç»„æ ‡è®°æ•°: {len(group_ids)}")
                        except Exception as e:
                            print(f"âš ï¸  å¤„ç†é‡å¤è®°å½•åˆ†ç»„ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
                            print(f"   å°†å¯¼å‡ºåŸå§‹é‡å¤è®°å½•ï¼Œä¸åŒ…å«åˆ†ç»„ä¿¡æ¯")
                    
                    duplicate_export.to_excel(writer, sheet_name='é‡å¤è®°å½•', index=False)
                    sheet_names.append('é‡å¤è®°å½•')
                    print(f"ğŸ“‹ é‡å¤è®°å½•å·²ä¿å­˜åˆ° 'é‡å¤è®°å½•' å·¥ä½œè¡¨ï¼Œå…± {len(self.duplicate_records)} æ¡è®°å½•")
            
            print(f"âœ… æ•°æ®å·²æˆåŠŸå¯¼å‡ºåˆ°: {output_path}")
            print(f"æ€»å…±å¯¼å‡º {len(df)} æ¡è®°å½•")
            print(f"ğŸ“‹ åŒ…å«å·¥ä½œè¡¨: {', '.join(sheet_names)}")
            
            return output_path
            
        except PermissionError:
            print(f"âŒ æƒé™é”™è¯¯ï¼šæ— æ³•ä¿å­˜åˆ° {output_path}")
            print("è¯·ç¡®ä¿æ–‡ä»¶æ²¡æœ‰è¢«å…¶ä»–ç¨‹åºï¼ˆå¦‚Excelï¼‰æ‰“å¼€")
            print("å»ºè®®ï¼š")
            print("1. å…³é—­å¯èƒ½æ‰“å¼€è¯¥æ–‡ä»¶çš„Excelç¨‹åº")
            print("2. ä½¿ç”¨ä¸åŒçš„æ–‡ä»¶å")
            print("3. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«è®¾ç½®ä¸ºåªè¯»")
            return None
        except Exception as e:
            print(f"âŒ å¯¼å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return None
    
    def set_output_filename(self):
        """è®¾ç½®è¾“å‡ºæ–‡ä»¶å"""
        print(f"\n=== æ­¥éª¤4.5: è¾“å‡ºè®¾ç½® ===")
        print(f"ğŸ“ å½“å‰è¾“å‡ºæ–‡ä»¶å: {self.output_filename}")
        filename = input("è¯·è¾“å…¥æ–°çš„è¾“å‡ºæ–‡ä»¶ååˆ—å¦‚G:\\wang\\excelï¼ˆé»˜è®¤æ ¼å¼ä¸ºxlsxï¼‰: ").strip()
        if filename:
            # ç¡®ä¿æ–‡ä»¶æ‰©å±•åæ­£ç¡®
            if not filename.endswith(('.xlsx', '.xls')):
                filename += '.xlsx'
            self.output_filename = filename
        print(f"âœ… è¾“å‡ºæ–‡ä»¶å: {self.output_filename}")
    

    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        
        
        # æ˜¾ç¤ºæ™ºèƒ½åŒ¹é…é…ç½®ï¼ˆé»˜è®¤å¯ç”¨ï¼Œä¸è¯¢é—®ç”¨æˆ·ï¼‰
        print(f"\n=== æ™ºèƒ½åŒ¹é…é…ç½® ===")
        print(f"ğŸ¤– æ™ºèƒ½åŒ¹é…è®¾ç½®ï¼ˆå·²å¯ç”¨ï¼‰:")
        print(f"  â€¢ æ™ºèƒ½åŒ¹é…: {'å¯ç”¨' if self.enable_smart_matching else 'ç¦ç”¨'}")
        print(f"  â€¢ è‡ªåŠ¨æ¸…ç†åˆ—å: {'å¯ç”¨' if self.auto_clean_columns else 'ç¦ç”¨'}")
        print(f"  â€¢ ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold}")
        print(f"âœ… ä½¿ç”¨é»˜è®¤æ™ºèƒ½åŒ¹é…è®¾ç½®ï¼Œæå‡å¤„ç†æ•ˆç‡")
        
        try:
            # 1. æ–‡ä»¶é€‰æ‹©
            folder_path = input("è¯·è¾“å…¥åŒ…å«Excelæ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆæˆ–æŒ‰å›è½¦ä½¿ç”¨å½“å‰ç›®å½•ï¼‰: ").strip()
            if not folder_path:
                folder_path = "."
            
            files = self.select_files(folder_path)
            if not files:
                print("âŒ æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶ï¼Œç¨‹åºé€€å‡º")
                return
            
            # 1.5. æ–‡ä»¶å¤‡ä»½
            if not self.backup_files(files):
                print("âŒ å¤‡ä»½å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
                return
            
            # 2. å­—æ®µåˆ†æ
            all_fields = self.get_field_list(files)
            if not all_fields:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•å­—æ®µï¼Œç¨‹åºé€€å‡º")
                return
            
            # 3. å­—æ®µé€‰æ‹©
            selected_fields = self.select_fields(all_fields)
            if not selected_fields:
                print("âŒ æœªé€‰æ‹©ä»»ä½•å­—æ®µï¼Œç¨‹åºé€€å‡º")
                return
            

            
            # 4. å»é‡é…ç½®
            deduplicate, dedup_fields = self.configure_deduplication()
            
            # 4.5. è¾“å‡ºè®¾ç½®
            self.set_output_filename()
            
            # 5. æ•°æ®å¤„ç†
            result_df = self.process_data(files, selected_fields, deduplicate, dedup_fields)
            if result_df.empty:
                print("âŒ æ²¡æœ‰æ•°æ®å¯å¤„ç†ï¼Œç¨‹åºé€€å‡º")
                return
            
            # 6. å¯¼å‡ºç»“æœ
            output_path = self.export_to_excel(result_df)
            
            if output_path:
                print(f"\n" + "=" * 60)
                print("ğŸ‰ å¤„ç†å®Œæˆï¼")
                print("=" * 60)
                print(f"ğŸ“„ ç»“æœæ–‡ä»¶: {output_path}")
                print(f"ğŸ“Š å¤„ç†è®°å½•æ•°: {len(result_df)}")
                print(f"ğŸ“ å¤„ç†æ–‡ä»¶æ•°: {len(files)}")
                print(f"ğŸ“‹ é€‰æ‹©å­—æ®µæ•°: {len(selected_fields)}")
                if deduplicate and dedup_fields:
                    print(f"ğŸ” å»é‡å­—æ®µ: {', '.join(dedup_fields)}")
                    if self.duplicate_count > 0:
                        removed_count = self.duplicate_count - len(result_df)
                        print(f"ğŸ“Š å‘ç°é‡å¤è®°å½•: {self.duplicate_count} æ¡")
                        print(f"ğŸ—‘ï¸  åˆ é™¤é‡å¤è®°å½•: {removed_count} æ¡")
                        print(f"ğŸ’¾ é‡å¤è®°å½•å·²ä¿å­˜åˆ° 'é‡å¤è®°å½•' å·¥ä½œè¡¨")
                    else:
                        print(f"âœ… æœªå‘ç°é‡å¤è®°å½•")

                

            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
    
    def resolve_field_conflicts(self, group_key, group_df: pd.DataFrame, dedup_fields: List[str]) -> pd.DataFrame:
        """
        è§£å†³å­—æ®µå€¼å†²çªï¼Œè®©ç”¨æˆ·é€‰æ‹©å¦‚ä½•å¤„ç†ä¸åŒçš„å­—æ®µå€¼
        
        Args:
            group_key: é‡å¤ç»„çš„é”®å€¼
            group_df: é‡å¤ç»„çš„æ•°æ®æ¡†
            dedup_fields: å»é‡å­—æ®µåˆ—è¡¨
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ¡†
        """
        if len(group_df) <= 1:
            return group_df.head(1)  # åªæœ‰ä¸€æ¡è®°å½•ï¼Œç›´æ¥è¿”å›
        
        if not self.enable_interactive_dedup and not self.enable_smart_dedup:
            return group_df.head(1)  # é»˜è®¤ä¿ç•™ç¬¬ä¸€æ¡
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è®°å½•å®Œå…¨ç›¸åŒï¼ˆæ’é™¤æ•°æ®æ¥æºæ–‡ä»¶å­—æ®µï¼‰
        all_fields = [field for field in group_df.columns if field != 'æ•°æ®æ¥æºæ–‡ä»¶']
        first_record = group_df.iloc[0]
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è®°å½•éƒ½ä¸ç¬¬ä¸€æ¡è®°å½•å®Œå…¨ç›¸åŒ
        all_identical = True
        for _, row in group_df.iterrows():
            for field in all_fields:
                # å¤„ç†NaNå€¼çš„æ¯”è¾ƒ
                first_val = first_record[field]
                current_val = row[field]
                
                # å¦‚æœä¸¤ä¸ªå€¼éƒ½æ˜¯NaNï¼Œè®¤ä¸ºç›¸åŒ
                if pd.isna(first_val) and pd.isna(current_val):
                    continue
                # å¦‚æœä¸€ä¸ªæ˜¯NaNå¦ä¸€ä¸ªä¸æ˜¯ï¼Œè®¤ä¸ºä¸åŒ
                elif pd.isna(first_val) or pd.isna(current_val):
                    all_identical = False
                    break
                # å¦‚æœä¸¤ä¸ªå€¼éƒ½ä¸æ˜¯NaNï¼Œæ¯”è¾ƒå­—ç¬¦ä¸²å½¢å¼
                elif str(first_val).strip() != str(current_val).strip():
                    all_identical = False
                    break
            
            if not all_identical:
                break
        
        if all_identical:
            # æ‰€æœ‰è®°å½•å®Œå…¨ç›¸åŒï¼Œè¿™æ˜¯çœŸæ­£çš„é‡å¤ï¼Œç›´æ¥ä¿ç•™ç¬¬ä¸€æ¡
            return group_df.head(1)
        
        # æ£€æŸ¥éå»é‡å­—æ®µæ˜¯å¦æœ‰å†²çªï¼ˆæ’é™¤æ–‡ä»¶æ¥æºå­—æ®µï¼‰
        non_dedup_fields = [field for field in group_df.columns if field not in dedup_fields and field != 'æ•°æ®æ¥æºæ–‡ä»¶']
        conflicts = {}
        
        for field in non_dedup_fields:
            # è·å–å”¯ä¸€å€¼ï¼Œä¿æŒå‡ºç°é¡ºåºï¼ŒåŒ…æ‹¬NaNå€¼çš„å¤„ç†
            seen = set()
            unique_values = []
            
            for value in group_df[field]:
                # å¤„ç†NaNå€¼
                if pd.isna(value):
                    str_value = "<NaN>"
                else:
                    str_value = str(value).strip()
                
                if str_value not in seen:
                    seen.add(str_value)
                    unique_values.append(value)
            
            # åªæœ‰å½“ç¡®å®æœ‰ä¸åŒçš„éNaNå€¼æ—¶æ‰è®¤ä¸ºæ˜¯å†²çª
            non_nan_values = [v for v in unique_values if not pd.isna(v)]
            if len(non_nan_values) > 1:
                conflicts[field] = unique_values
        
        if not conflicts:
            return group_df.head(1)  # æ²¡æœ‰å†²çªï¼Œä¿ç•™ç¬¬ä¸€æ¡
        
        # è¿™ä¸ªå‡½æ•°ç°åœ¨å·²ç»è¢« resolve_student_conflicts æ›¿ä»£
        # ç›´æ¥è¿”å›ç¬¬ä¸€æ¡è®°å½•ä½œä¸ºåå¤‡æ–¹æ¡ˆ
        print("âš ï¸  ä½¿ç”¨åå¤‡å¤„ç†æ–¹æ¡ˆï¼šä¿ç•™ç¬¬ä¸€æ¡è®°å½•")
        return group_df.head(1)
    
    def _manual_resolve_conflicts(self, group_df: pd.DataFrame, conflicts: Dict, dedup_fields: List[str]) -> pd.DataFrame:
        """æ‰‹åŠ¨è§£å†³å†²çª"""
        result_record = group_df.iloc[0].copy()  # åŸºäºç¬¬ä¸€æ¡è®°å½•
        
        print(f"\nğŸ”§ å¼€å§‹æ‰‹åŠ¨è§£å†³å†²çª...")
        print(f"ğŸ“„ åŸºç¡€è®°å½•ï¼ˆç¬¬ä¸€æ¡ï¼‰: {dict(result_record)}")
        
        for field, values in conflicts.items():
            print(f"\nğŸ“ è¯·é€‰æ‹©å­—æ®µ '{field}' çš„å€¼:")
            print(f"ğŸ” å½“å‰å€¼: {result_record[field]}")
            print(f"ğŸ“‹ å¯é€‰å€¼:")
            
            for i, value in enumerate(values, 1):
                if pd.isna(value):
                    print(f"  {i}. <ç©ºå€¼>")
                else:
                    print(f"  {i}. {value}")
            
            while True:
                try:
                    choice = input(f"è¯·é€‰æ‹© (1-{len(values)}): ").strip()
                    choice_idx = int(choice) - 1
                    if 0 <= choice_idx < len(values):
                        selected_value = values[choice_idx]
                        old_value = result_record[field]
                        result_record[field] = selected_value
                        
                        if pd.isna(selected_value):
                            print(f"âœ… å·²é€‰æ‹©: <ç©ºå€¼>")
                        else:
                            print(f"âœ… å·²é€‰æ‹©: {selected_value}")
                        
                        print(f"ğŸ”„ å­—æ®µ '{field}' æ›´æ–°: {old_value} â†’ {selected_value}")
                        break
                    else:
                        print("âŒ ç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°é€‰æ‹©")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        print(f"\nâœ… å†²çªè§£å†³å®Œæˆï¼")
        print(f"ğŸ“„ æœ€ç»ˆè®°å½•: {dict(result_record)}")
        return pd.DataFrame([result_record])
    
    def _create_separate_records(self, group_df: pd.DataFrame, conflicts: Dict, dedup_fields: List[str]) -> pd.DataFrame:
        """ä¸ºä¸åŒå€¼åˆ›å»ºå•ç‹¬è®°å½•"""
        # æ‰¾åˆ°æœ€å¤šå€¼çš„å­—æ®µä½œä¸ºä¸»å­—æ®µ
        main_field = max(conflicts.keys(), key=lambda f: len(conflicts[f]))
        main_values = conflicts[main_field]
        
        print(f"ğŸ“ ä»¥å­—æ®µ '{main_field}' ä¸ºä¸»å­—æ®µåˆ›å»º {len(main_values)} æ¡è®°å½•")
        
        result_records = []
        base_record = group_df.iloc[0].copy()
        
        for i, main_value in enumerate(main_values):
            new_record = base_record.copy()
            new_record[main_field] = main_value
            
            # ä¸ºå…¶ä»–å†²çªå­—æ®µé€‰æ‹©å¯¹åº”çš„å€¼
            for field in conflicts:
                if field != main_field:
                    # æ‰¾åˆ°ä¸main_valueå¯¹åº”çš„è®°å½•ä¸­è¯¥å­—æ®µçš„å€¼
                    matching_records = group_df[group_df[main_field] == main_value]
                    if not matching_records.empty:
                        new_record[field] = matching_records.iloc[0][field]
                    # å¦‚æœæ²¡æœ‰å®Œå…¨åŒ¹é…çš„è®°å½•ï¼Œä¿æŒåŸå€¼
            
            result_records.append(new_record)
            print(f"  ğŸ“„ è®°å½• {i+1}: {main_field}={main_value}")
        
        return pd.DataFrame(result_records)
    
    def _keep_most_frequent_values(self, group_df: pd.DataFrame, conflicts: Dict, dedup_fields: List[str]) -> pd.DataFrame:
        """ä¿ç•™å‡ºç°æ¬¡æ•°æœ€å¤šçš„å€¼"""
        result_record = group_df.iloc[0].copy()  # åŸºäºç¬¬ä¸€æ¡è®°å½•
        
        print(f"\nğŸ”§ å¼€å§‹æŒ‰å‡ºç°æ¬¡æ•°æœ€å¤šçš„å€¼è§£å†³å†²çª...")
        
        for field, values in conflicts.items():
            # ç»Ÿè®¡æ¯ä¸ªå€¼çš„å‡ºç°æ¬¡æ•°
            value_counts = {}
            for _, row in group_df.iterrows():
                value = row[field]
                # å½’ä¸€åŒ–å€¼ç”¨äºæ¯”è¾ƒ
                if pd.isna(value):
                    normalized_value = "<ç©ºå€¼>"
                else:
                    normalized_value = str(value).strip()
                
                value_counts[normalized_value] = value_counts.get(normalized_value, 0) + 1
            
            # æ‰¾åˆ°å‡ºç°æ¬¡æ•°æœ€å¤šçš„å€¼
            most_frequent_normalized = max(value_counts.keys(), key=lambda k: value_counts[k])
            most_frequent_count = value_counts[most_frequent_normalized]
            
            # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹å€¼
            if most_frequent_normalized == "<ç©ºå€¼>":
                most_frequent_original = None
            else:
                # åœ¨åŸå§‹æ•°æ®ä¸­æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„å€¼
                most_frequent_original = None
                for _, row in group_df.iterrows():
                    value = row[field]
                    if not pd.isna(value) and str(value).strip() == most_frequent_normalized:
                        most_frequent_original = value
                        break
                if most_frequent_original is None:
                    most_frequent_original = most_frequent_normalized
            
            # æ›´æ–°ç»“æœè®°å½•
            old_value = result_record[field]
            result_record[field] = most_frequent_original
            
            print(f"ğŸ“Š å­—æ®µ '{field}': é€‰æ‹©å‡ºç°æ¬¡æ•°æœ€å¤šçš„å€¼")
            print(f"   â€¢ é€‰æ‹©çš„å€¼: {self._format_display_value(most_frequent_original)} (å‡ºç° {most_frequent_count} æ¬¡)")
            print(f"   â€¢ å…¶ä»–å€¼çš„ç»Ÿè®¡:")
            for norm_val, count in sorted(value_counts.items(), key=lambda x: x[1], reverse=True)[1:]:
                print(f"     - {norm_val}: {count} æ¬¡")
            print(f"ğŸ”„ å­—æ®µ '{field}' æ›´æ–°: {self._format_display_value(old_value)} â†’ {self._format_display_value(most_frequent_original)}")
        
        print(f"\nâœ… å†²çªè§£å†³å®Œæˆï¼å·²é€‰æ‹©å‡ºç°æ¬¡æ•°æœ€å¤šçš„å€¼")
        return pd.DataFrame([result_record])
    
    def resolve_student_conflicts(self, group_key, group_df: pd.DataFrame, dedup_fields: List[str], student_name_field: str, student_id_field: str = None) -> tuple:
        """
        è§£å†³å­¦ç”Ÿè®°å½•å†²çªï¼šå­¦å·ç›¸åŒä½†å§“åä¸åŒçš„æƒ…å†µ
        
        Args:
            group_key: é‡å¤ç»„çš„é”®å€¼
            group_df: é‡å¤ç»„çš„æ•°æ®æ¡†
            dedup_fields: å»é‡å­—æ®µåˆ—è¡¨
            student_name_field: å­¦ç”Ÿå§“åå­—æ®µå
            student_id_field: å­¦ç”Ÿå­¦å·å­—æ®µåï¼ˆå¯é€‰ï¼‰
            
        Returns:
            (å¤„ç†åçš„æ•°æ®æ¡†, æ˜¯å¦æœ‰å†²çª)
        """
        if len(group_df) <= 1:
            return group_df, False  # åªæœ‰ä¸€æ¡è®°å½•ï¼Œç›´æ¥è¿”å›
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å§“åå†²çª
        has_name_conflict = self._group_has_student_name_conflict(group_df, dedup_fields, student_name_field)
        
        if not has_name_conflict:
            # æ²¡æœ‰å§“åå†²çªï¼Œå­¦å·+å§“åå®Œå…¨ç›¸åŒï¼Œé™é»˜åˆå¹¶ï¼ˆä¿ç•™ç¬¬ä¸€æ¡ï¼‰
            return group_df.head(1), False
        
        # æœ‰å†²çªï¼Œéœ€è¦å¤„ç†
        print(f"\n{'âš ï¸' + '='*60}")
        
        # æ™ºèƒ½åˆ¤æ–­å†²çªç±»å‹
        if student_id_field and student_name_field:
            id_icon = self._get_field_icon(student_id_field)
            name_icon = self._get_field_icon(student_name_field)
            print(f"å‘ç°{id_icon}ç›¸åŒä½†{name_icon}ä¸åŒçš„è®°å½•ï¼")
        else:
            print(f"å‘ç°é‡å¤è®°å½•å­˜åœ¨å­—æ®µå†²çªï¼")
        
        print(f"{'âš ï¸' + '='*60}")
        
        # æ˜¾ç¤ºä¸»é”®ä¿¡æ¯
        if isinstance(group_key, tuple):
            for i, field in enumerate(dedup_fields):
                display_value = self._format_display_value(group_key[i])
                print(f"ğŸ”‘ {field}: {display_value}")
        else:
            display_value = self._format_display_value(group_key)
            print(f"ğŸ”‘ {dedup_fields[0]}: {display_value}")
        
        # æ˜¾ç¤ºå†²çªçš„å­—æ®µä¿¡æ¯
        conflict_info = {}
        exclude_fields = set(['æ•°æ®æ¥æºæ–‡ä»¶', 'æ•°æ®æ¥æºè·¯å¾„'] + dedup_fields)
        
        for field in group_df.columns:
            if field in exclude_fields:
                continue
            
            unique_values = set()
            for value in group_df[field]:
                # ä¿®æ”¹ï¼šåŒ…å«ç©ºå€¼ï¼Œå› ä¸ºç©ºå€¼ä¹Ÿæ˜¯ä¸€ç§æœ‰æ•ˆçš„å€¼ï¼Œéœ€è¦ç”¨æˆ·é€‰æ‹©
                if pd.notna(value):
                    normalized_value = str(value).strip() if str(value).strip() else "<ç©ºå€¼>"
                    unique_values.add(normalized_value)
                else:
                    unique_values.add("<ç©ºå€¼>")
            
            if len(unique_values) > 1:
                conflict_info[field] = unique_values
        
        if conflict_info:
            print(f"\nğŸ“‹ å‘ç°å†²çªçš„å­—æ®µ:")
            for field, values in conflict_info.items():
                # ä½¿ç”¨è¾…åŠ©å‡½æ•°æ™ºèƒ½é€‰æ‹©å›¾æ ‡
                field_icon = self._get_field_icon(field)
                
                print(f"  {field_icon} {field}: {len(values)} ä¸ªä¸åŒå€¼")
                for i, value in enumerate(sorted(values), 1):
                    print(f"    {i}. {value}")
        
        # å¦‚æœæœ‰å§“åå­—æ®µï¼Œæ˜¾ç¤ºå§“åå†²çªè¯¦æƒ…
        if student_name_field and student_name_field in group_df.columns:
            unique_names = {}
            for _, row in group_df.iterrows():
                name = row[student_name_field]
                # ä¿®æ”¹ï¼šåŒ…å«ç©ºå€¼ï¼Œå› ä¸ºç©ºå€¼ä¹Ÿæ˜¯ä¸€ç§æœ‰æ•ˆçš„å€¼ï¼Œéœ€è¦ç”¨æˆ·é€‰æ‹©
                if pd.notna(name):
                    normalized_name = str(name).strip() if str(name).strip() else "<ç©ºå€¼>"
                else:
                    normalized_name = "<ç©ºå€¼>"
                
                if normalized_name not in unique_names:
                    unique_names[normalized_name] = []
                unique_names[normalized_name].append(row)
            
            if len(unique_names) > 1:
                # ä½¿ç”¨è¾…åŠ©å‡½æ•°æ™ºèƒ½é€‰æ‹©å›¾æ ‡
                field_icon = self._get_field_icon(student_name_field)
                print(f"\n{field_icon} å‘ç° {len(unique_names)} ä¸ªä¸åŒçš„å€¼:")
                
                for i, (name, records) in enumerate(unique_names.items(), 1):
                    # ç»Ÿè®¡è¯¥å§“åå‡ºç°çš„æ–‡ä»¶
                    files = set()
                    for record in records:
                        if 'æ•°æ®æ¥æºæ–‡ä»¶' in record:
                            files.add(str(record['æ•°æ®æ¥æºæ–‡ä»¶']))
                    
                    print(f"  {i}. {name} (å‡ºç°åœ¨ {len(records)} æ¡è®°å½•ä¸­)")
                    if files:
                        print(f"     æ¥æºæ–‡ä»¶: {', '.join(sorted(files))}")
        
        if not self.enable_interactive_dedup:
            # è‡ªåŠ¨æ¨¡å¼ï¼šä¿ç•™ç¬¬ä¸€æ¡è®°å½•
            print(f"\nâœ… è‡ªåŠ¨æ¨¡å¼ï¼šä¿ç•™ç¬¬ä¸€æ¡è®°å½•")
            return group_df.head(1), True
        
        # äº¤äº’å¼æ¨¡å¼ï¼šè¯¢é—®ç”¨æˆ·å¦‚ä½•å¤„ç†
        print(f"\nğŸ¤” è¯·é€‰æ‹©å¤„ç†æ–¹å¼:")
        print(f"  1. ä¿ç•™ç¬¬ä¸€æ¡è®°å½• (é»˜è®¤)")
        
        # æ™ºèƒ½åˆ¤æ–­å­—æ®µç±»å‹å¹¶æ˜¾ç¤ºç›¸åº”é€‰é¡¹
        if student_name_field:
            field_icon = self._get_field_icon(student_name_field)
            print(f"  2. æ‰‹åŠ¨é€‰æ‹©è¦ä¿ç•™çš„è®°å½•")
            print(f"  3. ä¸ºæ¯ä¸ªä¸åŒå€¼åˆ›å»ºå•ç‹¬è®°å½•")
        else:
            print(f"  2. æ‰‹åŠ¨é€‰æ‹©è¦ä¿ç•™çš„è®°å½•")
            print(f"  3. ä¸ºæ¯ä¸ªä¸åŒå€¼åˆ›å»ºå•ç‹¬è®°å½•")
        
        print(f"  4. è·³è¿‡æ­¤ç»„ï¼Œä¸åšå¤„ç†")
        
        while True:
            try:
                choice = input("\nè¯·é€‰æ‹©å¤„ç†æ–¹å¼ (1-4ï¼Œé»˜è®¤1): ").strip()
                if not choice:
                    choice = "1"
                
                if choice == "1":
                    print("âœ… ä¿ç•™ç¬¬ä¸€æ¡è®°å½•")
                    
                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–å†²çªå­—æ®µéœ€è¦å¤„ç†
                    if student_name_field:
                        # å¦‚æœæœ‰å§“åå­—æ®µï¼Œæ£€æŸ¥å…¶ä»–å†²çªå­—æ®µ
                        conflict_info = self._get_remaining_conflicts(group_df, [group_df.iloc[0]], student_name_field)
                        
                        if conflict_info:
                            print(f"\nâš ï¸  å‘ç°å…¶ä»–å†²çªå­—æ®µï¼Œéœ€è¦è¿›ä¸€æ­¥å¤„ç†:")
                            for field, values in conflict_info.items():
                                field_icon = self._get_field_icon(field)
                                print(f"  {field_icon} {field}: {len(values)} ä¸ªä¸åŒå€¼")
                                for i, value in enumerate(sorted(values), 1):
                                    print(f"    {i}. {value}")
                            
                            # è¯¢é—®ç”¨æˆ·æ˜¯å¦è¦å¤„ç†å…¶ä»–å†²çªå­—æ®µ
                            print(f"\nğŸ¤” æ˜¯å¦è¦å¤„ç†å…¶ä»–å†²çªå­—æ®µï¼Ÿ")
                            print(f"  1. æ˜¯ï¼Œæ‰‹åŠ¨é€‰æ‹©æ¯ä¸ªå­—æ®µçš„å€¼")
                            print(f"  2. å¦ï¼Œä½¿ç”¨ç¬¬ä¸€æ¡è®°å½•çš„å€¼")
                            
                            conflict_choice = input("è¯·é€‰æ‹© (1-2ï¼Œé»˜è®¤2): ").strip()
                            if conflict_choice == "1":
                                # æ‰‹åŠ¨å¤„ç†å…¶ä»–å†²çªå­—æ®µ
                                result_record = self._manual_resolve_remaining_conflicts(group_df.iloc[0], conflict_info)
                                return pd.DataFrame([result_record]), True
                            else:
                                # ä½¿ç”¨ç¬¬ä¸€æ¡è®°å½•
                                print("âœ… ä½¿ç”¨ç¬¬ä¸€æ¡è®°å½•çš„å€¼")
                                return group_df.head(1), True
                        else:
                            # æ²¡æœ‰å…¶ä»–å†²çªå­—æ®µï¼Œç›´æ¥è¿”å›ç¬¬ä¸€æ¡è®°å½•
                            return group_df.head(1), True
                    else:
                        # æ²¡æœ‰å§“åå­—æ®µï¼Œç›´æ¥è¿”å›ç¬¬ä¸€æ¡è®°å½•
                        return group_df.head(1), True
                
                elif choice == "2":
                    if student_name_field:
                        result = self._manual_select_student_name(group_df, unique_names, student_name_field)
                        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–å†²çªå­—æ®µéœ€è¦å¤„ç†
                        if hasattr(result, 'iloc') and len(result) > 0:
                            remaining_conflicts = self._get_remaining_conflicts(group_df, [result.iloc[0]], student_name_field)
                            if remaining_conflicts:
                                print(f"\nâš ï¸  å‘ç°å…¶ä»–å†²çªå­—æ®µï¼Œéœ€è¦è¿›ä¸€æ­¥å¤„ç†:")
                                for field, values in remaining_conflicts.items():
                                    field_icon = self._get_field_icon(field)
                                    print(f"  {field_icon} {field}: {len(values)} ä¸ªä¸åŒå€¼")
                                    for i, value in enumerate(sorted(values), 1):
                                        print(f"    {i}. {value}")
                                
                                # è¯¢é—®ç”¨æˆ·æ˜¯å¦è¦å¤„ç†å…¶ä»–å†²çªå­—æ®µ
                                print(f"\nğŸ¤” æ˜¯å¦è¦å¤„ç†å…¶ä»–å†²çªå­—æ®µï¼Ÿ")
                                print(f"  1. æ˜¯ï¼Œæ‰‹åŠ¨é€‰æ‹©æ¯ä¸ªå­—æ®µçš„å€¼")
                                print(f"  2. å¦ï¼Œä½¿ç”¨å·²é€‰æ‹©è®°å½•çš„å€¼")
                                
                                conflict_choice = input("è¯·é€‰æ‹© (1-2ï¼Œé»˜è®¤2): ").strip()
                                if conflict_choice == "1":
                                    # æ‰‹åŠ¨å¤„ç†å…¶ä»–å†²çªå­—æ®µ
                                    result_record = self._manual_resolve_remaining_conflicts(result.iloc[0], remaining_conflicts)
                                    return pd.DataFrame([result_record]), True
                                else:
                                    # ä½¿ç”¨å·²é€‰æ‹©çš„è®°å½•
                                    print("âœ… ä½¿ç”¨å·²é€‰æ‹©è®°å½•çš„å€¼")
                                    return result, True
                    else:
                        result = self._manual_select_record(group_df, conflict_info)
                    return result, True
                
                elif choice == "3":
                    if student_name_field:
                        print("âœ… ä¸ºæ¯ä¸ªä¸åŒå€¼åˆ›å»ºå•ç‹¬è®°å½•")
                        result = self._create_records_by_name(group_df, unique_names, student_name_field)
                        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–å†²çªå­—æ®µéœ€è¦å¤„ç†
                        if len(result) > 0:
                            # ä¸ºæ¯ä¸ªè®°å½•æ£€æŸ¥å…¶ä»–å†²çªå­—æ®µ
                            final_records = []
                            for _, record in result.iterrows():
                                remaining_conflicts = self._get_remaining_conflicts(group_df, [record], student_name_field)
                                if remaining_conflicts:
                                    print(f"\nâš ï¸  è®°å½• '{record[student_name_field]}' å‘ç°å…¶ä»–å†²çªå­—æ®µ:")
                                    for field, values in remaining_conflicts.items():
                                        field_icon = self._get_field_icon(field)
                                        print(f"  {field_icon} {field}: {len(values)} ä¸ªä¸åŒå€¼")
                                    
                                    # è¯¢é—®ç”¨æˆ·æ˜¯å¦è¦å¤„ç†å…¶ä»–å†²çªå­—æ®µ
                                    print(f"\nğŸ¤” æ˜¯å¦è¦å¤„ç†è®°å½• '{record[student_name_field]}' çš„å…¶ä»–å†²çªå­—æ®µï¼Ÿ")
                                    print(f"  1. æ˜¯ï¼Œæ‰‹åŠ¨é€‰æ‹©æ¯ä¸ªå­—æ®µçš„å€¼")
                                    print(f"  2. å¦ï¼Œä½¿ç”¨å½“å‰è®°å½•çš„å€¼")
                                    
                                    conflict_choice = input("è¯·é€‰æ‹© (1-2ï¼Œé»˜è®¤2): ").strip()
                                    if conflict_choice == "1":
                                        # æ‰‹åŠ¨å¤„ç†å…¶ä»–å†²çªå­—æ®µ
                                        resolved_record = self._manual_resolve_remaining_conflicts(record, remaining_conflicts)
                                        final_records.append(resolved_record)
                                    else:
                                        # ä½¿ç”¨å½“å‰è®°å½•
                                        print("âœ… ä½¿ç”¨å½“å‰è®°å½•çš„å€¼")
                                        final_records.append(record)
                                else:
                                    final_records.append(record)
                            
                            if final_records:
                                result = pd.DataFrame(final_records)
                    else:
                        print("âœ… ä¸ºæ¯ä¸ªä¸åŒå€¼åˆ›å»ºå•ç‹¬è®°å½•")
                        result = self._create_records_by_conflict_fields(group_df, conflict_info)
                    return result, True
                
                elif choice == "4":
                    print("âš ï¸  è·³è¿‡æ­¤ç»„")
                    return pd.DataFrame(), True  # è¿”å›ç©ºæ•°æ®æ¡†
                
                else:
                    print("âŒ è¯·è¾“å…¥ 1-4 ä¹‹é—´çš„æ•°å­—")
                    
            except KeyboardInterrupt:
                print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œä¿ç•™ç¬¬ä¸€æ¡è®°å½•")
                return group_df.head(1), True
    
    def _manual_select_student_name(self, group_df: pd.DataFrame, unique_names: dict, student_name_field: str) -> pd.DataFrame:
        """æ‰‹åŠ¨é€‰æ‹©è¦ä¿ç•™çš„å­¦ç”Ÿå§“åï¼Œå¹¶å¤„ç†å…¶ä»–å†²çªå­—æ®µ"""
        print(f"\nğŸ“ è¯·é€‰æ‹©è¦ä¿ç•™çš„å§“å:")
        name_list = list(unique_names.keys())
        for i, name in enumerate(name_list, 1):
            records_count = len(unique_names[name])
            print(f"  {i}. {name} ({records_count} æ¡è®°å½•)")
        
        while True:
            try:
                choice = input(f"è¯·é€‰æ‹©å§“åç¼–å· (1-{len(name_list)}): ").strip()
                choice_idx = int(choice) - 1
                if 0 <= choice_idx < len(name_list):
                    selected_name = name_list[choice_idx]
                    selected_records = unique_names[selected_name]
                    
                    print(f"âœ… å·²é€‰æ‹©å§“å: {selected_name}")
                    
                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–å†²çªå­—æ®µéœ€è¦å¤„ç†
                    conflict_info = self._get_remaining_conflicts(group_df, selected_records, student_name_field)
                    
                    if conflict_info:
                        print(f"\nâš ï¸  å‘ç°å…¶ä»–å†²çªå­—æ®µï¼Œéœ€è¦è¿›ä¸€æ­¥å¤„ç†:")
                        for field, values in conflict_info.items():
                            field_icon = self._get_field_icon(field)
                            print(f"  {field_icon} {field}: {len(values)} ä¸ªä¸åŒå€¼")
                            for i, value in enumerate(sorted(values), 1):
                                print(f"    {i}. {value}")
                        
                        # è¯¢é—®ç”¨æˆ·æ˜¯å¦è¦å¤„ç†å…¶ä»–å†²çªå­—æ®µ
                        print(f"\nğŸ¤” æ˜¯å¦è¦å¤„ç†å…¶ä»–å†²çªå­—æ®µï¼Ÿ")
                        print(f"  1. æ˜¯ï¼Œæ‰‹åŠ¨é€‰æ‹©æ¯ä¸ªå­—æ®µçš„å€¼")
                        print(f"  2. å¦ï¼Œä½¿ç”¨ç¬¬ä¸€æ¡è®°å½•çš„å€¼")
                        
                        conflict_choice = input("è¯·é€‰æ‹© (1-2ï¼Œé»˜è®¤2): ").strip()
                        if conflict_choice == "1":
                            # æ‰‹åŠ¨å¤„ç†å…¶ä»–å†²çªå­—æ®µ
                            result_record = self._manual_resolve_remaining_conflicts(selected_records[0], conflict_info)
                            return pd.DataFrame([result_record])
                        else:
                            # ä½¿ç”¨ç¬¬ä¸€æ¡è®°å½•
                            print("âœ… ä½¿ç”¨ç¬¬ä¸€æ¡è®°å½•çš„å€¼")
                            return pd.DataFrame([selected_records[0]])
                    else:
                        # æ²¡æœ‰å…¶ä»–å†²çªå­—æ®µï¼Œç›´æ¥è¿”å›ç¬¬ä¸€æ¡åŒ¹é…çš„è®°å½•
                        return pd.DataFrame([selected_records[0]])
                else:
                    print("âŒ ç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°é€‰æ‹©")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    def _get_remaining_conflicts(self, group_df: pd.DataFrame, selected_records: list, student_name_field: str) -> dict:
        """è·å–é™¤äº†å§“åå­—æ®µä¹‹å¤–çš„å…¶ä»–å†²çªå­—æ®µ"""
        conflict_info = {}
        exclude_fields = set(['æ•°æ®æ¥æºæ–‡ä»¶', 'æ•°æ®æ¥æºè·¯å¾„', student_name_field])
        
        # æ£€æŸ¥æ•´ä¸ª group_df ä¸­æ˜¯å¦è¿˜æœ‰å…¶ä»–å†²çªå­—æ®µ
        for field in group_df.columns:
            if field in exclude_fields:
                continue
            
            # æ£€æŸ¥è¯¥å­—æ®µåœ¨æ•´ä¸ªç»„ä¸­æ˜¯å¦æœ‰å†²çª
            unique_values = set()
            for _, record in group_df.iterrows():
                value = record[field]
                # ä¿®æ”¹ï¼šåŒ…å«ç©ºå€¼ï¼Œå› ä¸ºç©ºå€¼ä¹Ÿæ˜¯ä¸€ç§æœ‰æ•ˆçš„å€¼ï¼Œéœ€è¦ç”¨æˆ·é€‰æ‹©
                if pd.notna(value):
                    normalized_value = str(value).strip() if str(value).strip() else "<ç©ºå€¼>"
                    unique_values.add(normalized_value)
                else:
                    unique_values.add("<ç©ºå€¼>")
            
            if len(unique_values) > 1:
                conflict_info[field] = unique_values
        
        return conflict_info
    
    def _manual_resolve_remaining_conflicts(self, base_record: pd.Series, conflict_info: dict) -> pd.Series:
        """æ‰‹åŠ¨è§£å†³å‰©ä½™å†²çªå­—æ®µ"""
        result_record = base_record.copy()
        
        print(f"\nğŸ”§ å¼€å§‹å¤„ç†å…¶ä»–å†²çªå­—æ®µ...")
        print(f"ğŸ“„ åŸºç¡€è®°å½•: {dict(result_record)}")
        
        for field, values in conflict_info.items():
            print(f"\nğŸ“ è¯·é€‰æ‹©å­—æ®µ '{field}' çš„å€¼:")
            print(f"ğŸ” å½“å‰å€¼: {result_record[field]}")
            print(f"ğŸ“‹ å¯é€‰å€¼:")
            
            # å°† set è½¬æ¢ä¸º list ä»¥ä¾¿ç´¢å¼•è®¿é—®
            values_list = list(values)
            
            for i, value in enumerate(values_list, 1):
                if pd.isna(value):
                    print(f"  {i}. <ç©ºå€¼>")
                else:
                    print(f"  {i}. {value}")
            
            while True:
                try:
                    choice = input(f"è¯·é€‰æ‹© (1-{len(values_list)}): ").strip()
                    choice_idx = int(choice) - 1
                    if 0 <= choice_idx < len(values_list):
                        selected_value = values_list[choice_idx]
                        old_value = result_record[field]
                        result_record[field] = selected_value
                        
                        if pd.isna(selected_value):
                            print(f"âœ… å·²é€‰æ‹©: <ç©ºå€¼>")
                        else:
                            print(f"âœ… å·²é€‰æ‹©: {selected_value}")
                        
                        print(f"ğŸ”„ å­—æ®µ '{field}' æ›´æ–°: {old_value} â†’ {selected_value}")
                        break
                    else:
                        print("âŒ ç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°é€‰æ‹©")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        print(f"\nâœ… æ‰€æœ‰å†²çªå­—æ®µå¤„ç†å®Œæˆï¼")
        print(f"ğŸ“„ æœ€ç»ˆè®°å½•: {dict(result_record)}")
        return result_record
    
    def _create_records_by_name(self, group_df: pd.DataFrame, unique_names: dict, student_name_field: str) -> pd.DataFrame:
        """ä¸ºæ¯ä¸ªä¸åŒå§“ååˆ›å»ºå•ç‹¬è®°å½•"""
        result_records = []
        
        print(f"\nğŸ“ ä¸ºæ¯ä¸ªä¸åŒå§“ååˆ›å»ºè®°å½•:")
        for i, (name, records) in enumerate(unique_names.items(), 1):
            # ä½¿ç”¨è¯¥å§“åçš„ç¬¬ä¸€æ¡è®°å½•
            record = records[0]
            result_records.append(record)
            print(f"  {i}. åˆ›å»ºè®°å½•: å§“å={name}")
        
        return pd.DataFrame(result_records)

    def backup_files(self, files: List[str]) -> bool:
        """
        å¤‡ä»½é€‰ä¸­çš„Excelæ–‡ä»¶
        
        Args:
            files: è¦å¤‡ä»½çš„æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            å¤‡ä»½æ˜¯å¦æˆåŠŸ
        """
        print(f"\n=== æ–‡ä»¶å¤‡ä»½ ===")
        
        # è¯¢é—®æ˜¯å¦è¦å¤‡ä»½
        backup_choice = input("ğŸ¤” æ˜¯å¦è¦å¤‡ä»½é€‰ä¸­çš„Excelæ–‡ä»¶ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        if backup_choice in ['n', 'no', 'å¦']:
            print("âœ… è·³è¿‡å¤‡ä»½ï¼Œç›´æ¥å¤„ç†æ–‡ä»¶")
            return True
        
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = f"backup_{timestamp}"
        
        try:
            if not os.path.exists(backup_dir):
                os.makedirs(backup_dir)
            
            print(f"ğŸ“ åˆ›å»ºå¤‡ä»½ç›®å½•: {backup_dir}")
            
            # å¤‡ä»½æ¯ä¸ªæ–‡ä»¶
            backup_success = 0
            backup_failed = 0
            
            for file_path in files:
                try:
                    filename = os.path.basename(file_path)
                    backup_path = os.path.join(backup_dir, filename)
                    
                    # å¦‚æœå¤‡ä»½ç›®å½•ä¸­å·²æœ‰åŒåæ–‡ä»¶ï¼Œæ·»åŠ åºå·
                    counter = 1
                    original_backup_path = backup_path
                    while os.path.exists(backup_path):
                        name, ext = os.path.splitext(original_backup_path)
                        backup_path = f"{name}_{counter}{ext}"
                        counter += 1
                    
                    # å¤åˆ¶æ–‡ä»¶
                    import shutil
                    shutil.copy2(file_path, backup_path)
                    print(f"âœ… å·²å¤‡ä»½: {filename} -> {os.path.basename(backup_path)}")
                    backup_success += 1
                    
                except Exception as e:
                    print(f"âŒ å¤‡ä»½å¤±è´¥: {os.path.basename(file_path)} - {str(e)}")
                    backup_failed += 1
            
            print(f"\nğŸ“Š å¤‡ä»½ç»“æœ:")
            print(f"  âœ… æˆåŠŸå¤‡ä»½: {backup_success} ä¸ªæ–‡ä»¶")
            if backup_failed > 0:
                print(f"  âŒ å¤‡ä»½å¤±è´¥: {backup_failed} ä¸ªæ–‡ä»¶")
            print(f"  ğŸ“ å¤‡ä»½ä½ç½®: {os.path.abspath(backup_dir)}")
            
            if backup_failed > 0:
                continue_choice = input("\nâš ï¸  éƒ¨åˆ†æ–‡ä»¶å¤‡ä»½å¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­å¤„ç†ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
                if continue_choice in ['n', 'no', 'å¦']:
                    print("âŒ ç”¨æˆ·é€‰æ‹©é€€å‡º")
                    return False
            
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºå¤‡ä»½ç›®å½•å¤±è´¥: {str(e)}")
            continue_choice = input("âš ï¸  å¤‡ä»½å¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­å¤„ç†ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            return continue_choice in ['y', 'yes', 'æ˜¯']

    def _is_money_field(self, field_name: str) -> bool:
        """åˆ¤æ–­å­—æ®µæ˜¯å¦ä¸ºé‡‘é’±å­—æ®µ"""
        field_lower = field_name.lower()
        money_keywords = ['é‡‘é¢', 'ä»·æ ¼', 'price', 'amount', 'è´¹ç”¨', 'æˆæœ¬', 'money', 'money', 'å…ƒ', 'ï¿¥', '$', 'Â¥']
        return any(keyword in field_lower for keyword in money_keywords)
    
    def _is_money_value_equal(self, val1, val2) -> bool:
        """
        æ¯”è¾ƒä¸¤ä¸ªé‡‘é’±å€¼æ˜¯å¦ç›¸ç­‰
        
        Args:
            val1: ç¬¬ä¸€ä¸ªå€¼
            val2: ç¬¬äºŒä¸ªå€¼
            
        Returns:
            bool: å¦‚æœé‡‘é’±å€¼ç›¸ç­‰è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        # å¦‚æœä¸¤ä¸ªå€¼éƒ½æ˜¯NaNï¼Œè®¤ä¸ºç›¸ç­‰
        if pd.isna(val1) and pd.isna(val2):
            return True
        
        # å¦‚æœä¸€ä¸ªæ˜¯NaNå¦ä¸€ä¸ªä¸æ˜¯ï¼Œè®¤ä¸ºä¸ç›¸ç­‰
        if pd.isna(val1) or pd.isna(val2):
            return False
        
        try:
            # å°è¯•è½¬æ¢ä¸ºæ•°å€¼è¿›è¡Œæ¯”è¾ƒ
            num1 = float(str(val1).replace(',', '').replace('ï¿¥', '').replace('$', '').replace('Â¥', '').replace('å…ƒ', ''))
            num2 = float(str(val2).replace(',', '').replace('ï¿¥', '').replace('$', '').replace('Â¥', '').replace('å…ƒ', ''))
            
            # ä½¿ç”¨å°çš„å®¹å·®å€¼æ¯”è¾ƒæµ®ç‚¹æ•°
            return abs(num1 - num2) < 0.01
        except (ValueError, TypeError):
            # å¦‚æœæ— æ³•è½¬æ¢ä¸ºæ•°å€¼ï¼Œå›é€€åˆ°å­—ç¬¦ä¸²æ¯”è¾ƒ
            return str(val1).strip() == str(val2).strip()
    
    def _get_field_icon(self, field_name: str) -> str:
        """æ ¹æ®å­—æ®µåç§°æ™ºèƒ½é€‰æ‹©å›¾æ ‡"""
        field_lower = field_name.lower()
        
        # å§“åç›¸å…³å­—æ®µ
        if any(keyword in field_lower for keyword in ['å§“å', 'åå­—', 'name', 'å§“', 'å']):
            return "ğŸ‘¤"
        # åç§°/æ ‡é¢˜ç›¸å…³å­—æ®µ
        elif any(keyword in field_lower for keyword in ['åç§°', 'æ ‡é¢˜', 'title', 'åç§°']):
            return "ğŸ·ï¸"
        # åœ°å€ç›¸å…³å­—æ®µ
        elif any(keyword in field_name.lower() for keyword in ['åœ°å€', 'ä½å€', 'address', 'ä½ç½®']):
            return "ğŸ“"
        # ç”µè¯ç›¸å…³å­—æ®µ
        elif any(keyword in field_name.lower() for keyword in ['ç”µè¯', 'æ‰‹æœº', 'phone', 'tel', 'å·ç ']):
            return "ğŸ“"
        # é‚®ç®±ç›¸å…³å­—æ®µ
        elif any(keyword in field_name.lower() for keyword in ['é‚®ç®±', 'é‚®ä»¶', 'email', 'ä¿¡ç®±']):
            return "ğŸ“§"
        # æ—¥æœŸæ—¶é—´ç›¸å…³å­—æ®µ
        elif any(keyword in field_name.lower() for keyword in ['æ—¥æœŸ', 'æ—¶é—´', 'date', 'time', 'å¹´', 'æœˆ', 'æ—¥']):
            return "ğŸ“…"
        # æ•°é‡é‡‘é¢ç›¸å…³å­—æ®µ
        elif any(keyword in field_name.lower() for keyword in ['æ•°é‡', 'é‡‘é¢', 'ä»·æ ¼', 'price', 'amount', 'è´¹ç”¨', 'æˆæœ¬']):
            return "ğŸ’°"
        # é»˜è®¤å›¾æ ‡
        else:
            return "ğŸ”"

    def _format_display_value(self, value) -> str:
        """
        æ ¼å¼åŒ–æ˜¾ç¤ºå€¼ï¼Œå¤„ç†æ•°å€¼ç±»å‹çš„æ˜¾ç¤ºæ ¼å¼
        
        Args:
            value: è¦æ ¼å¼åŒ–çš„å€¼
            
        Returns:
            æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        if pd.isna(value):
            return "<ç©ºå€¼>"
        
        # å¦‚æœæ˜¯æµ®ç‚¹æ•°ä¸”å°æ•°éƒ¨åˆ†ä¸º0ï¼Œæ˜¾ç¤ºä¸ºæ•´æ•°
        if isinstance(value, float) and value.is_integer():
            return str(int(value))
        
        # å…¶ä»–æƒ…å†µç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        return str(value)

    def _has_field_conflicts(self, group_df: pd.DataFrame) -> bool:
        """
        æ£€æŸ¥é‡å¤ç»„æ˜¯å¦æœ‰å­—æ®µå†²çªï¼ˆä¸æ˜¯æ‰€æœ‰è®°å½•éƒ½å®Œå…¨ç›¸åŒï¼‰
        
        Args:
            group_df: é‡å¤ç»„çš„æ•°æ®æ¡†
            
        Returns:
            bool: å¦‚æœæœ‰å†²çªè¿”å›Trueï¼Œå¦‚æœæ‰€æœ‰è®°å½•å®Œå…¨ç›¸åŒè¿”å›False
        """
        if len(group_df) <= 1:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è®°å½•å®Œå…¨ç›¸åŒï¼ˆæ’é™¤æ•°æ®æ¥æºæ–‡ä»¶å­—æ®µï¼‰
        all_fields = [field for field in group_df.columns if field != 'æ•°æ®æ¥æºæ–‡ä»¶']
        first_record = group_df.iloc[0]
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è®°å½•éƒ½ä¸ç¬¬ä¸€æ¡è®°å½•å®Œå…¨ç›¸åŒ
        for _, row in group_df.iterrows():
            for field in all_fields:
                # å¤„ç†NaNå€¼çš„æ¯”è¾ƒ
                first_val = first_record[field]
                current_val = row[field]
                
                # å¦‚æœä¸¤ä¸ªå€¼éƒ½æ˜¯NaNï¼Œè®¤ä¸ºç›¸åŒ
                if pd.isna(first_val) and pd.isna(current_val):
                    continue
                # å¦‚æœä¸€ä¸ªæ˜¯NaNå¦ä¸€ä¸ªä¸æ˜¯ï¼Œè®¤ä¸ºä¸åŒ
                elif pd.isna(first_val) or pd.isna(current_val):
                    return True  # æœ‰å†²çª
                
                # ç‰¹æ®Šå¤„ç†é‡‘é’±å­—æ®µ
                if self._is_money_field(field):
                    if not self._is_money_value_equal(first_val, current_val):
                        return True  # é‡‘é’±å€¼ä¸åŒï¼Œæœ‰å†²çª
                else:
                    # éé‡‘é’±å­—æ®µï¼Œæ¯”è¾ƒå­—ç¬¦ä¸²å½¢å¼
                    if str(first_val).strip() != str(current_val).strip():
                        return True  # æœ‰å†²çª
        
        return False  # æ‰€æœ‰è®°å½•å®Œå…¨ç›¸åŒï¼Œæ— å†²çª

    def _manual_select_column(self, required_field: str, available_columns: List[str]) -> str:
        """æ‰‹åŠ¨é€‰æ‹©åˆ—å"""
        if not available_columns:
            print(f"  âš ï¸  æ²¡æœ‰å¯ç”¨çš„åˆ—åå¯é€‰æ‹©")
            return None
        
        print(f"\n  ğŸ“‹ å¯ç”¨çš„åˆ—å:")
        for i, column in enumerate(available_columns, 1):
            print(f"    {i:2d}. {column}")
        
        print(f"\n  ğŸ“ è¯·é€‰æ‹©è¦æ˜ å°„åˆ°å­—æ®µ '{required_field}' çš„åˆ—å:")
        while True:
            try:
                choice = input("  è¯·è¾“å…¥åˆ—åç¼–å·: ").strip()
                choice_idx = int(choice) - 1
                if 0 <= choice_idx < len(available_columns):
                    selected_column = available_columns[choice_idx]
                    print(f"  âœ… é€‰æ‹©äº†åˆ—å: {selected_column}")
                    return selected_column
                else:
                    print("  âŒ ç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°é€‰æ‹©")
            except ValueError:
                print("  âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")

    def _normalize_for_compare(self, value) -> str:
        """
        å½’ä¸€åŒ–æ¯”è¾ƒå€¼ï¼š
        - NaN -> ""
        - æµ®ç‚¹æ•´æ•° -> å»æ‰ .0
        - å…¶ä»– -> å»é¦–å°¾ç©ºæ ¼çš„å­—ç¬¦ä¸²
        """
        if pd.isna(value):
            return ""
        if isinstance(value, float) and value.is_integer():
            return str(int(value))
        return str(value).strip()

    def _find_actual_field_name_silent(self, df: pd.DataFrame, target_field: str) -> str:
        """
        é™é»˜åˆ—ååŒ¹é…ï¼šä¸æ‰“å°ã€ä¸äº¤äº’ã€‚
        åŒ¹é…é¡ºåºï¼šç²¾ç¡® -> ä¸åŒºåˆ†å¤§å°å†™ -> æ¸…æ´—åçš„åˆ—ååŒ¹é… -> å¸¸è§å˜ä½“ -> ç›¸ä¼¼åº¦æœ€é«˜ï¼ˆ>=é˜ˆå€¼ï¼‰
        """
        available = list(df.columns)
        # 1) ç²¾ç¡®
        if target_field in available:
            return target_field

        # 2) ä¸åŒºåˆ†å¤§å°å†™
        lower_map = {c.lower(): c for c in available}
        if target_field.lower() in lower_map:
            return lower_map[target_field.lower()]

        # 3) æ¸…æ´—åçš„åˆ—å
        cleaned_target = self.clean_column_name(target_field)
        cleaned_map = {self.clean_column_name(c): c for c in available}
        if cleaned_target in cleaned_map:
            return cleaned_map[cleaned_target]

        # 4) å¸¸è§å˜ä½“
        if hasattr(self, 'common_column_variants') and target_field in self.common_column_variants:
            for variant in self.common_column_variants[target_field]:
                # å…ˆç²¾ç¡®
                if variant in available:
                    return variant
                # å¤§å°å†™
                if variant.lower() in lower_map:
                    return lower_map[variant.lower()]
                # æ¸…æ´—å
                cv = self.clean_column_name(variant)
                if cv in cleaned_map:
                    return cleaned_map[cv]

        # 5) ç›¸ä¼¼åº¦
        best_col = None
        best_sim = 0.0
        for col in available:
            sim = SequenceMatcher(None, cleaned_target.lower(), self.clean_column_name(col).lower()).ratio()
            if sim > best_sim:
                best_sim = sim
                best_col = col
        if best_col and best_sim >= getattr(self, 'similarity_threshold', 0.8):
            return best_col

        return None

    def _verify_group_key_in_file(self, file_path: str, dedup_fields: List[str], group_key) -> bool:
        """
        æ ¡éªŒï¼šåœ¨æŒ‡å®šçš„æºæ–‡ä»¶ä¸­ï¼Œæ˜¯å¦å­˜åœ¨ä¸å½“å‰é‡å¤ç»„é”®ä¸€è‡´çš„è®°å½•ã€‚
        é™é»˜åŒ¹é…åˆ—åï¼Œé¿å…æ‰“å°å’Œäº¤äº’ï¼Œä¸”è¿›è¡Œå€¼å½’ä¸€åŒ–æ¯”è¾ƒã€‚
        """
        try:
            df_src = pd.read_excel(file_path)
        except Exception:
            return False

        # å®šä½å®é™…åˆ—åï¼ˆé™é»˜ï¼‰
        actual_cols = []
        for field in dedup_fields:
            actual = self._find_actual_field_name_silent(df_src, field)
            if not actual:
                return False
            actual_cols.append(actual)

        # ç»„è£…ç»„é”®å€¼
        if isinstance(group_key, tuple):
            key_values = list(group_key)
        else:
            key_values = [group_key]
        if len(key_values) != len(actual_cols):
            return False

        # æ„å»ºæ©ç è¿›è¡Œæ¯”è¾ƒï¼ˆç»Ÿä¸€å½’ä¸€åŒ–ï¼‰
        mask = pd.Series([True] * len(df_src))
        for actual_col, key_value in zip(actual_cols, key_values):
            series_obj = df_src[actual_col]
            # å½’ä¸€åŒ–åˆ—
            series_norm = series_obj.apply(self._normalize_for_compare)
            cmp_val = self._normalize_for_compare(key_value)
            mask = mask & (series_norm == cmp_val)

        return bool(mask.any())

    def _group_has_student_name_conflict(self, group_df: pd.DataFrame, dedup_fields: List[str], student_name_field: str) -> bool:
        """
        æ£€æŸ¥é‡å¤ç»„æ˜¯å¦å­˜åœ¨å†²çªï¼ˆå­¦å·ç›¸åŒä½†å§“åä¸åŒï¼Œæˆ–å…¶ä»–å­—æ®µä¸åŒï¼‰
        
        Args:
            group_df: é‡å¤ç»„çš„æ•°æ®æ¡†
            dedup_fields: å»é‡å­—æ®µåˆ—è¡¨
            student_name_field: å­¦ç”Ÿå§“åå­—æ®µå
            
        Returns:
            bool: å¦‚æœå­˜åœ¨å†²çªè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        if len(group_df) <= 1:
            return False
        
        # å¦‚æœæœ‰å§“åå­—æ®µï¼Œæ£€æŸ¥å§“åå†²çª
        if student_name_field and student_name_field in group_df.columns:
            unique_names = set()
            for name in group_df[student_name_field]:
                if pd.notna(name) and str(name).strip():
                    normalized_name = str(name).strip()
                    unique_names.add(normalized_name)
            
            # å¦‚æœæœ‰è¶…è¿‡1ä¸ªä¸åŒçš„å§“åï¼Œåˆ™è®¤ä¸ºæœ‰å†²çª
            if len(unique_names) > 1:
                return True
        
        # æ£€æŸ¥å…¶ä»–éå»é‡å­—æ®µæ˜¯å¦å­˜åœ¨å†²çª
        exclude_fields = set(['æ•°æ®æ¥æºæ–‡ä»¶', 'æ•°æ®æ¥æºè·¯å¾„'] + dedup_fields)
        for field in group_df.columns:
            if field in exclude_fields:
                continue
            
            # æ£€æŸ¥è¯¥å­—æ®µæ˜¯å¦æœ‰ä¸åŒçš„å€¼
            unique_values = set()
            for value in group_df[field]:
                if pd.notna(value) and str(value).strip():
                    normalized_value = str(value).strip()
                    unique_values.add(normalized_value)
            
            # å¦‚æœæœ‰è¶…è¿‡1ä¸ªä¸åŒçš„å€¼ï¼Œåˆ™è®¤ä¸ºæœ‰å†²çª
            if len(unique_values) > 1:
                return True
        
        return False
    
    def _group_has_conflict_normalized(self, group_df: pd.DataFrame, dedup_fields: List[str]) -> bool:
        """
        ä½¿ç”¨å½’ä¸€åŒ–åçš„å–å€¼æ¥åˆ¤æ–­æ˜¯å¦å­˜åœ¨çœŸå®å†²çªï¼š
        - ä»…æ£€æŸ¥éå»é‡å­—æ®µï¼Œä¸”æ’é™¤æ¥æºå­—æ®µ
        - å¿½ç•¥ç©ºå€¼
        - åŒå€¼ä¸åŒç±»å‹ï¼ˆå¦‚ 2020062959.0 ä¸ '2020062959'ï¼‰è§†ä¸ºç›¸åŒ
        """
        exclude_fields = set(['æ•°æ®æ¥æºæ–‡ä»¶', 'æ•°æ®æ¥æºè·¯å¾„'])
        for field in group_df.columns:
            if field in dedup_fields or field in exclude_fields:
                continue
            normalized_values = set()
            for v in group_df[field].tolist():
                nv = self._normalize_for_compare(v)
                if nv != "":
                    normalized_values.add(nv)
            if len(normalized_values) > 1:
                return True
        return False
    
    def _manual_select_record(self, group_df: pd.DataFrame, conflict_info: Dict[str, set]) -> pd.DataFrame:
        """
        æ‰‹åŠ¨é€‰æ‹©è¦ä¿ç•™çš„è®°å½•ï¼ˆé€‚ç”¨äºéå§“åå­—æ®µå†²çªï¼‰
        
        Args:
            group_df: é‡å¤ç»„çš„æ•°æ®æ¡†
            conflict_info: å†²çªå­—æ®µä¿¡æ¯å­—å…¸
            
        Returns:
            é€‰æ‹©ä¿ç•™çš„è®°å½•
        """
        print(f"\nğŸ“‹ è¯·é€‰æ‹©è¦ä¿ç•™çš„è®°å½•:")
        
        # æ˜¾ç¤ºæ¯æ¡è®°å½•çš„è¯¦ç»†ä¿¡æ¯
        for i, (_, record) in enumerate(group_df.iterrows(), 1):
            print(f"\n  ğŸ“ è®°å½• {i}:")
            for field, value in record.items():
                if field in ['æ•°æ®æ¥æºæ–‡ä»¶', 'æ•°æ®æ¥æºè·¯å¾„']:
                    continue
                display_value = self._format_display_value(value)
                if field in conflict_info:
                    print(f"    ğŸ” {field}: {display_value} (å†²çªå­—æ®µ)")
                else:
                    print(f"    ğŸ“Š {field}: {display_value}")
        
        while True:
            try:
                choice = input(f"\nè¯·é€‰æ‹©è¦ä¿ç•™çš„è®°å½• (1-{len(group_df)}): ").strip()
                if not choice:
                    choice = "1"
                
                choice_num = int(choice)
                if 1 <= choice_num <= len(group_df):
                    selected_record = group_df.iloc[choice_num - 1:choice_num]
                    print(f"âœ… å·²é€‰æ‹©è®°å½• {choice_num}")
                    return selected_record
                else:
                    print(f"âŒ è¯·è¾“å…¥ 1-{len(group_df)} ä¹‹é—´çš„æ•°å­—")
                    
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            except KeyboardInterrupt:
                print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œä¿ç•™ç¬¬ä¸€æ¡è®°å½•")
                return group_df.head(1)
    
    def _create_records_by_conflict_fields(self, group_df: pd.DataFrame, conflict_info: Dict[str, set]) -> pd.DataFrame:
        """
        ä¸ºæ¯ä¸ªä¸åŒå€¼åˆ›å»ºå•ç‹¬è®°å½•ï¼ˆé€‚ç”¨äºéå§“åå­—æ®µå†²çªï¼‰
        
        Args:
            group_df: é‡å¤ç»„çš„æ•°æ®æ¡†
            conflict_info: å†²çªå­—æ®µä¿¡æ¯å­—å…¸
            
        Returns:
            å¤„ç†åçš„è®°å½•
        """
        result_records = []
        
        # æŒ‰å†²çªå­—æ®µåˆ†ç»„
        for field, unique_values in conflict_info.items():
            for value in unique_values:
                # æ‰¾åˆ°è¯¥å€¼çš„æ‰€æœ‰è®°å½•
                field_records = group_df[group_df[field] == value]
                if not field_records.empty:
                    # ä¿ç•™ç¬¬ä¸€æ¡è®°å½•
                    result_records.append(field_records.head(1))
        
        if result_records:
            return pd.concat(result_records, ignore_index=True)
        else:
            return group_df.head(1)
    
    def _identify_student_id_field(self, dedup_fields: List[str], all_columns: List[str]) -> str:
        """
        æ™ºèƒ½è¯†åˆ«å­¦å·å­—æ®µ
        
        Args:
            dedup_fields: å»é‡å­—æ®µåˆ—è¡¨
            all_columns: æ‰€æœ‰å¯ç”¨å­—æ®µåˆ—è¡¨
            
        Returns:
            è¯†åˆ«å‡ºçš„å­¦å·å­—æ®µåï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°è¿”å›None
        """
        # å­¦å·å­—æ®µçš„å¸¸è§å…³é”®è¯å’Œæ¨¡å¼
        id_keywords = [
            'å­¦å·', 'å­¦ç”Ÿå·', 'å­¦ç±å·', 'ç¼–å·', 'ID', 'id', 'Id',
            'å·¥å·', 'å‘˜å·¥å·', 'èŒå·¥å·', 'ç¼–å·', 'å·ç ',
            'å•ä½å·', 'éƒ¨é—¨å·', 'æœºæ„å·', 'ç»„ç»‡å·',
            'è´¦å·', 'ç”¨æˆ·å·', 'ä¼šå‘˜å·', 'å®¢æˆ·å·',
            'è®¢å•å·', 'æµæ°´å·', 'åºåˆ—å·', 'ç¼–ç '
        ]
        
        # ä¼˜å…ˆåœ¨å»é‡å­—æ®µä¸­æŸ¥æ‰¾
        for field in dedup_fields:
            field_lower = field.lower()
            for keyword in id_keywords:
                if keyword in field_lower:
                    return field
        
        # åœ¨å»é‡å­—æ®µä¸­æŸ¥æ‰¾åŒ…å«æ•°å­—çš„å­—æ®µ
        for field in dedup_fields:
            if any(char.isdigit() for char in field):
                return field
        
        # åœ¨æ‰€æœ‰å­—æ®µä¸­æŸ¥æ‰¾å­¦å·ç›¸å…³å­—æ®µ
        for field in all_columns:
            field_lower = field.lower()
            for keyword in id_keywords:
                if keyword in field_lower:
                    return field
        
        return None
    
    def _identify_name_field(self, all_columns: List[str]) -> str:
        """
        æ™ºèƒ½è¯†åˆ«å§“åå­—æ®µ
        
        Args:
            all_columns: æ‰€æœ‰å¯ç”¨å­—æ®µåˆ—è¡¨
            
        Returns:
            è¯†åˆ«å‡ºçš„å§“åå­—æ®µåï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°è¿”å›None
        """
        # å§“åå­—æ®µçš„å¸¸è§å…³é”®è¯å’Œæ¨¡å¼
        name_keywords = [
            'å§“å', 'åå­—', 'åç§°', 'å…¨å', 'ä¸­æ–‡å', 'è‹±æ–‡å',
            'å§“', 'å', 'åå­—', 'ç§°è°“',
            'å•ä½åç§°', 'éƒ¨é—¨åç§°', 'æœºæ„åç§°', 'ç»„ç»‡åç§°',
            'äº§å“åç§°', 'å•†å“åç§°', 'é¡¹ç›®åç§°', 'æ ‡é¢˜',
            'åç§°', 'åå­—', 'æ ‡é¢˜', 'æè¿°'
        ]
        
        # åœ¨æ‰€æœ‰å­—æ®µä¸­æŸ¥æ‰¾å§“åç›¸å…³å­—æ®µ
        for field in all_columns:
            field_lower = field.lower()
            for keyword in name_keywords:
                if keyword in field_lower:
                    return field
        
        return None

def main():
    """ä¸»å‡½æ•°"""
    processor = ExcelProcessor()
    processor.run()

if __name__ == "__main__":
    main()