import pandas as pd
import os
import glob
import re
from typing import List, Tuple, Dict, Optional
from difflib import SequenceMatcher

class ExcelProcessor:
    """Excelæ–‡ä»¶å¤„ç†å·¥å…·"""
    
    def __init__(self):
        self.selected_files = []
        self.all_fields = []
        self.selected_fields = []
        self.deduplicate = False
        self.dedup_fields = []
        self.output_filename = "result.xlsx"
        
        # é‡å¤è®°å½•ç›¸å…³å±æ€§
        self.duplicate_records = pd.DataFrame()  # å­˜å‚¨å‘ç°çš„é‡å¤è®°å½•
        self.duplicate_count = 0  # é‡å¤è®°å½•æ•°é‡
        self.enable_interactive_dedup = True  # æ˜¯å¦å¯ç”¨äº¤äº’å¼å»é‡
        self.conflict_resolution_choices = {}  # å­˜å‚¨ç”¨æˆ·çš„å†²çªè§£å†³é€‰æ‹©

        
        # æ–°å¢ï¼šæ™ºèƒ½åˆ—ååŒ¹é…ç›¸å…³å±æ€§
        self.column_mapping = {}  # åˆ—åæ˜ å°„å…³ç³»
        self.enable_smart_matching = True  # æ˜¯å¦å¯ç”¨æ™ºèƒ½åŒ¹é…
        self.similarity_threshold = 0.8  # ç›¸ä¼¼åº¦é˜ˆå€¼
        self.auto_clean_columns = True  # æ˜¯å¦è‡ªåŠ¨æ¸…ç†åˆ—å
        
        # å¸¸è§åˆ—åå˜ä½“æ˜ å°„ï¼ˆå»é‡ï¼‰
        self.common_column_variants = {
            'å­¦å·': ['å­¦å·', 'å­¦å·å·', 'å­¦å­¦å·', 'xuehao', 'student_id', 'å­¦ç”Ÿç¼–å·', 'å­¦ç”Ÿå­¦å·'],
            'å­¦ç”Ÿå§“å': ['å­¦ç”Ÿå§“å', 'å­¦ç”Ÿå§“åå', 'å­¦å­¦ç”Ÿå§“å', 'student_name', 'å§“å', 'å­¦ç”Ÿå', 'å­¦ç”Ÿå§“åï¼ˆä¸­æ–‡ï¼‰'],
            'ç­çº§': ['ç­çº§', 'ç­', 'class', 'ç­çº§åç§°', 'class_name'],
            'æˆç»©': ['æˆç»©', 'åˆ†æ•°', 'score', 'grade', 'è€ƒè¯•åˆ†æ•°'],
            'è¯¾ç¨‹': ['è¯¾ç¨‹', 'ç§‘ç›®', 'course', 'subject', 'è¯¾ç¨‹åç§°']
        }
    
    def clean_column_name(self, column_name: str) -> str:
        """
        æ¸…ç†åˆ—åï¼Œå»é™¤ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
        
        Args:
            column_name: åŸå§‹åˆ—å
            
        Returns:
            æ¸…ç†åçš„åˆ—å
        """
        if not self.auto_clean_columns:
            return column_name
        
        # å»é™¤é¦–å°¾ç©ºæ ¼
        cleaned = column_name.strip()
        
        # å»é™¤å¤šä½™çš„ç©ºæ ¼
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰
        cleaned = re.sub(r'[^\w\s\u4e00-\u9fff]', '', cleaned)
        
        # å†æ¬¡å»é™¤ç©ºæ ¼
        cleaned = cleaned.strip()
        
        return cleaned
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦
        
        Args:
            str1: å­—ç¬¦ä¸²1
            str2: å­—ç¬¦ä¸²2
            
        Returns:
            ç›¸ä¼¼åº¦ (0-1)
        """
        # ä½¿ç”¨SequenceMatcherè®¡ç®—ç›¸ä¼¼åº¦
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def find_similar_columns(self, target_column: str, available_columns: List[str]) -> List[Tuple[str, float]]:
        """
        æŸ¥æ‰¾ä¸ç›®æ ‡åˆ—åç›¸ä¼¼çš„åˆ—å
        
        Args:
            target_column: ç›®æ ‡åˆ—å
            available_columns: å¯ç”¨åˆ—ååˆ—è¡¨
            
        Returns:
            ç›¸ä¼¼åˆ—ååˆ—è¡¨ï¼ŒåŒ…å«ç›¸ä¼¼åº¦
        """
        similar_columns = []
        cleaned_target = self.clean_column_name(target_column)
        
        for column in available_columns:
            cleaned_column = self.clean_column_name(column)
            
            # ç²¾ç¡®åŒ¹é…
            if cleaned_target == cleaned_column:
                similar_columns.append((column, 1.0))
                continue
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = self.calculate_similarity(cleaned_target, cleaned_column)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§å˜ä½“
            for standard_name, variants in self.common_column_variants.items():
                if cleaned_target in variants and cleaned_column in variants:
                    similarity = max(similarity, 0.9)  # æé«˜å˜ä½“çš„ç›¸ä¼¼åº¦
                    break
            
            if similarity >= self.similarity_threshold:
                similar_columns.append((column, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similar_columns.sort(key=lambda x: x[1], reverse=True)
        return similar_columns
    
    def smart_column_mapping(self, required_columns: List[str], available_columns: List[str]) -> Dict[str, str]:
        """
        æ™ºèƒ½åˆ—åæ˜ å°„
        
        Args:
            required_columns: éœ€è¦çš„åˆ—å
            available_columns: å¯ç”¨çš„åˆ—å
            
        Returns:
            åˆ—åæ˜ å°„å­—å…¸
        """
        mapping = {}
        unmapped_required = []
        unmapped_available = available_columns.copy()
        
        print(f"\nğŸ” æ™ºèƒ½åˆ—åæ˜ å°„åˆ†æ...")
        print(f"ğŸ“‹ éœ€è¦çš„åˆ—å: {required_columns}")
        print(f"ğŸ“‹ å¯ç”¨çš„åˆ—å: {available_columns}")
        
        # ç¬¬ä¸€è½®ï¼šç²¾ç¡®åŒ¹é…å’Œå¸¸è§å˜ä½“åŒ¹é…
        for required in required_columns:
            matched = False
            
            # æ£€æŸ¥ç²¾ç¡®åŒ¹é…
            if required in available_columns:
                mapping[required] = required
                unmapped_available.remove(required)
                print(f"âœ… ç²¾ç¡®åŒ¹é…: {required} -> {required}")
                matched = True
                continue
            
            # æ£€æŸ¥å¸¸è§å˜ä½“
            if required in self.common_column_variants:
                variants = self.common_column_variants[required]
                for variant in variants:
                    if variant in available_columns:
                        mapping[required] = variant
                        unmapped_available.remove(variant)
                        print(f"âœ… å˜ä½“åŒ¹é…: {variant} -> {required}")
                        matched = True
                        break
            
            if not matched:
                unmapped_required.append(required)
        
        # ç¬¬äºŒè½®ï¼šæ¨¡ç³ŠåŒ¹é…
        if unmapped_required and unmapped_available:
            print(f"\nğŸ” è¿›è¡Œæ¨¡ç³ŠåŒ¹é…...")
            for required in unmapped_required:
                similar_columns = self.find_similar_columns(required, unmapped_available)
                
                if similar_columns:
                    best_match, similarity = similar_columns[0]
                    print(f"ğŸ” æ‰¾åˆ°ç›¸ä¼¼åˆ—å: {best_match} -> {required} (ç›¸ä¼¼åº¦: {similarity:.2f})")
                    
                    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç¡®è®¤æ˜ å°„
                    confirm = input(f"æ˜¯å¦å°†æ–‡ä»¶åˆ—å '{best_match}' æ˜ å°„åˆ°æ ‡å‡†å­—æ®µ '{required}'ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
                    if confirm not in ['n', 'no', 'å¦']:
                        mapping[required] = best_match
                        unmapped_available.remove(best_match)
                        print(f"âœ… ç¡®è®¤æ˜ å°„: {best_match} -> {required}")
                    else:
                        print(f"âš ï¸  è·³è¿‡æ˜ å°„: {required}")
                else:
                    print(f"âŒ æœªæ‰¾åˆ°ä¸ '{required}' ç›¸ä¼¼çš„åˆ—å")
                    print(f"ğŸ¤” è¯·é€‰æ‹©:")
                    print(f"  1. æ‰‹åŠ¨é€‰æ‹©åˆ—å (è¾“å…¥ 'm')")
                    print(f"  2. è·³è¿‡æ­¤å­—æ®µ (è¾“å…¥ 's')")
                    
                    while True:
                        choice = input(f"å¯¹äºå­—æ®µ '{required}' è¯·é€‰æ‹©: ").strip().lower()
                        if choice == 's':
                            print(f"âš ï¸  è·³è¿‡æ˜ å°„: {required}")
                            break
                        elif choice == 'm':
                            selected_column = self._manual_select_column(required, unmapped_available)
                            if selected_column:
                                mapping[required] = selected_column
                                unmapped_available.remove(selected_column)
                                unmapped_required.remove(required)
                                print(f"âœ… æ‰‹åŠ¨æ˜ å°„: {selected_column} -> {required}")
                            break
                        else:
                            print("âŒ è¯·è¾“å…¥ 'm' æˆ– 's'")
        
        # æ˜¾ç¤ºæ˜ å°„ç»“æœ
        if mapping:
            print(f"\nğŸ“‹ åˆ—åæ˜ å°„ç»“æœ:")
            for required, mapped in mapping.items():
                print(f"  {mapped} -> {required}")
        
        if unmapped_required:
            print(f"\nâš ï¸  æœªæ˜ å°„çš„åˆ—å: {unmapped_required}")
        
        return mapping
    
    def validate_required_columns(self, df: pd.DataFrame, required_columns: List[str]) -> Tuple[bool, List[str], Dict[str, str]]:
        """
        éªŒè¯å¿…éœ€çš„åˆ—åæ˜¯å¦å­˜åœ¨ï¼Œæ”¯æŒæ™ºèƒ½åŒ¹é…
        
        Args:
            df: æ•°æ®æ¡†
            required_columns: å¿…éœ€çš„åˆ—ååˆ—è¡¨
            
        Returns:
            (æ˜¯å¦éªŒè¯é€šè¿‡, ç¼ºå¤±çš„åˆ—ååˆ—è¡¨, åˆ—åæ˜ å°„å­—å…¸)
        """
        available_columns = list(df.columns)
        missing_columns = []
        column_mapping = {}
        
        if not self.enable_smart_matching:
            # ä¼ ç»Ÿä¸¥æ ¼åŒ¹é…
            for required in required_columns:
                if required not in available_columns:
                    missing_columns.append(required)
                else:
                    column_mapping[required] = required
        else:
            # æ™ºèƒ½åŒ¹é…
            column_mapping = self.smart_column_mapping(required_columns, available_columns)
            
            # æ£€æŸ¥å“ªäº›åˆ—åæ²¡æœ‰è¢«æ˜ å°„
            for required in required_columns:
                if required not in column_mapping:
                    missing_columns.append(required)
        
        return len(missing_columns) == 0, missing_columns, column_mapping
    
    def select_files(self, folder_path: str = ".") -> List[str]:
        """
        æ–‡ä»¶é€‰æ‹©åŠŸèƒ½
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•
            
        Returns:
            é€‰ä¸­çš„æ–‡ä»¶åˆ—è¡¨
        """
        print(f"\n=== æ­¥éª¤1: æ–‡ä»¶é€‰æ‹© ===")
        print(f"æ­£åœ¨æ‰«ææ–‡ä»¶å¤¹: {folder_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰Excelæ–‡ä»¶
        excel_patterns = ['*.xlsx', '*.xls']
        excel_files = []
        
        for pattern in excel_patterns:
            excel_files.extend(glob.glob(os.path.join(folder_path, pattern)))
        
        if not excel_files:
            print(f"âŒ åœ¨æ–‡ä»¶å¤¹ '{folder_path}' ä¸­æ²¡æœ‰æ‰¾åˆ°Excelæ–‡ä»¶")
            return []
        
        # æ˜¾ç¤ºæ‰¾åˆ°çš„æ–‡ä»¶
        print(f"\nâœ… æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶:")
        for i, file in enumerate(excel_files, 1):
            filename = os.path.basename(file)
            file_size = os.path.getsize(file) / 1024  # KB
            print(f"{i:2d}. {filename:<30} ({file_size:.1f} KB)")
        
        # ç”¨æˆ·é€‰æ‹©æ–‡ä»¶
        print(f"\nè¯·é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶:")
        print("- è¾“å…¥æ–‡ä»¶ç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2,3ï¼‰")
        print("- è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰æ–‡ä»¶")
        print("ğŸ“ è¾“å…¥ 'q' é€€å‡ºç¨‹åº")
        
        try:
            choice = input("\nè¯·é€‰æ‹©: ").strip().lower()
            
            if choice == 'q':
                print("ç¨‹åºé€€å‡º")
                return []
            elif choice == 'all':
                self.selected_files = excel_files
                print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(excel_files)} ä¸ªæ–‡ä»¶")
            else:
                # è§£æç”¨æˆ·é€‰æ‹©çš„æ–‡ä»¶ç¼–å·
                indices = [int(x.strip()) - 1 for x in choice.split(',')]
                self.selected_files = [excel_files[i] for i in indices if 0 <= i < len(excel_files)]
                
                if not self.selected_files:
                    print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆæ–‡ä»¶ï¼Œè¯·é‡æ–°é€‰æ‹©")
                    return self.select_files(folder_path)
                
                print(f"âœ… å·²é€‰æ‹© {len(self.selected_files)} ä¸ªæ–‡ä»¶:")
                for file in self.selected_files:
                    print(f"  ğŸ“„ {os.path.basename(file)}")
                
            return self.selected_files
            
        except (ValueError, IndexError) as e:
            print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {str(e)}ï¼Œè¯·é‡æ–°é€‰æ‹©")
            return self.select_files(folder_path)
    
    def get_field_list(self, files: List[str]) -> List[str]:
        """
        è·å–æ‰€æœ‰æ–‡ä»¶çš„å­—æ®µåˆ—è¡¨
        
        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            æ‰€æœ‰å­—æ®µçš„åˆ—è¡¨
        """
        print(f"\n=== æ­¥éª¤2: å­—æ®µåˆ†æ ===")
        all_fields = set()
        file_field_info = {}
        
        for file in files:
            try:
                df = pd.read_excel(file)
                file_fields = list(df.columns)
                
                # è¿‡æ»¤æ‰æ— æ•ˆå­—æ®µï¼ˆè¯´æ˜æ–‡å­—ã€Unnamedå­—æ®µç­‰ï¼‰
                valid_fields = []
                for field in file_fields:
                    # è·³è¿‡Unnamedå­—æ®µ
                    if field.startswith('Unnamed:'):
                        continue
                    # è·³è¿‡è¯´æ˜æ–‡å­—ï¼ˆé€šå¸¸åŒ…å«å¾ˆé•¿çš„æè¿°æ€§æ–‡å­—ï¼‰
                    if len(field) > 100:
                        continue
                    # è·³è¿‡ç©ºå­—æ®µ
                    if not field or field.strip() == '':
                        continue
                    # è·³è¿‡çº¯è¯´æ˜æ€§å­—æ®µ
                    if field in ['è¯´æ˜', 'è¯´æ˜æ–‡å­—', 'å¤‡æ³¨', 'æ³¨é‡Š']:
                        continue
                    # è·³è¿‡åŒ…å«è¯´æ˜å…³é”®è¯çš„å­—æ®µ
                    if any(keyword in field for keyword in ['è¯´æ˜', 'å¤‡æ³¨', 'æ³¨é‡Š', 'æ³¨æ„', 'æç¤º']):
                        continue
                    
                    # å¦‚æœå¯ç”¨è‡ªåŠ¨æ¸…ç†ï¼Œæ˜¾ç¤ºæ¸…ç†åçš„åˆ—å
                    if self.auto_clean_columns:
                        cleaned_field = self.clean_column_name(field)
                        if cleaned_field != field:
                            print(f"ğŸ“ åˆ—åæ¸…ç†: '{field}' -> '{cleaned_field}'")
                        valid_fields.append(cleaned_field)
                    else:
                        valid_fields.append(field)
                
                all_fields.update(valid_fields)
                file_field_info[os.path.basename(file)] = {
                    'field_count': len(valid_fields),
                    'fields': valid_fields
                }
                print(f"ğŸ“Š æ–‡ä»¶ '{os.path.basename(file)}' åŒ…å« {len(valid_fields)} ä¸ªæœ‰æ•ˆå­—æ®µ")
                
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
        
        # è®¡ç®—æ¯ä¸ªå­—æ®µçš„å‡ºç°æ¬¡æ•°å¹¶æ’åº
        field_occurrence = {}
        for field in all_fields:
            files_with_field = [f for f, info in file_field_info.items() if field in info['fields']]
            field_occurrence[field] = len(files_with_field)
        
        # æŒ‰å‡ºç°æ¬¡æ•°ä»é«˜åˆ°ä½æ’åº
        sorted_fields = sorted(field_occurrence.items(), key=lambda x: x[1], reverse=True)
        self.all_fields = [field for field, count in sorted_fields]
        
        print(f"\nâœ… æ€»å…±å‘ç° {len(self.all_fields)} ä¸ªä¸åŒæœ‰æ•ˆå­—æ®µ")
        
        return self.all_fields
    

    

    

    

    
    def get_file_fields(self, file_path: str) -> List[str]:
        """
        è·å–å•ä¸ªæ–‡ä»¶çš„å­—æ®µåˆ—è¡¨
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            å­—æ®µåˆ—è¡¨
        """
        try:
            df = pd.read_excel(file_path)
            file_fields = list(df.columns)
            
            # è¿‡æ»¤æ‰æ— æ•ˆå­—æ®µï¼ˆè¯´æ˜æ–‡å­—ã€Unnamedå­—æ®µç­‰ï¼‰
            valid_fields = []
            for field in file_fields:
                # è·³è¿‡Unnamedå­—æ®µ
                if field.startswith('Unnamed:'):
                    continue
                # è·³è¿‡è¯´æ˜æ–‡å­—ï¼ˆé€šå¸¸åŒ…å«å¾ˆé•¿çš„æè¿°æ€§æ–‡å­—ï¼‰
                if len(field) > 100:
                    continue
                # è·³è¿‡ç©ºå­—æ®µ
                if not field or field.strip() == '':
                    continue
                valid_fields.append(field)
            
            return valid_fields
        except Exception as e:
            return []
    
    def clean_column_name(self, column_name: str) -> str:
        """
        æ¸…ç†åˆ—åï¼Œå»é™¤ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
        
        Args:
            column_name: åŸå§‹åˆ—å
            
        Returns:
            æ¸…ç†åçš„åˆ—å
        """
        if not self.auto_clean_columns:
            return column_name
        
        # å»é™¤é¦–å°¾ç©ºæ ¼
        cleaned = column_name.strip()
        
        # å»é™¤å¤šä½™çš„ç©ºæ ¼
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰
        cleaned = re.sub(r'[^\w\s\u4e00-\u9fff]', '', cleaned)
        
        # å†æ¬¡å»é™¤ç©ºæ ¼
        cleaned = cleaned.strip()
        
        return cleaned
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦
        
        Args:
            str1: å­—ç¬¦ä¸²1
            str2: å­—ç¬¦ä¸²2
            
        Returns:
            ç›¸ä¼¼åº¦ (0-1)
        """
        # ä½¿ç”¨SequenceMatcherè®¡ç®—ç›¸ä¼¼åº¦
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def find_similar_columns(self, target_column: str, available_columns: List[str]) -> List[Tuple[str, float]]:
        """
        æŸ¥æ‰¾ä¸ç›®æ ‡åˆ—åç›¸ä¼¼çš„åˆ—å
        
        Args:
            target_column: ç›®æ ‡åˆ—å
            available_columns: å¯ç”¨åˆ—ååˆ—è¡¨
            
        Returns:
            ç›¸ä¼¼åˆ—ååˆ—è¡¨ï¼ŒåŒ…å«ç›¸ä¼¼åº¦
        """
        similar_columns = []
        cleaned_target = self.clean_column_name(target_column)
        
        for column in available_columns:
            cleaned_column = self.clean_column_name(column)
            
            # ç²¾ç¡®åŒ¹é…
            if cleaned_target == cleaned_column:
                similar_columns.append((column, 1.0))
                continue
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = self.calculate_similarity(cleaned_target, cleaned_column)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§å˜ä½“
            for standard_name, variants in self.common_column_variants.items():
                if cleaned_target in variants and cleaned_column in variants:
                    similarity = max(similarity, 0.9)  # æé«˜å˜ä½“çš„ç›¸ä¼¼åº¦
                    break
            
            if similarity >= self.similarity_threshold:
                similar_columns.append((column, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similar_columns.sort(key=lambda x: x[1], reverse=True)
        return similar_columns
    
    def smart_column_mapping(self, required_columns: List[str], available_columns: List[str]) -> Dict[str, str]:
        """
        æ™ºèƒ½åˆ—åæ˜ å°„
        
        Args:
            required_columns: éœ€è¦çš„åˆ—å
            available_columns: å¯ç”¨çš„åˆ—å
            
        Returns:
            åˆ—åæ˜ å°„å­—å…¸
        """
        mapping = {}
        unmapped_required = []
        unmapped_available = available_columns.copy()
        
        print(f"\nğŸ” æ™ºèƒ½åˆ—åæ˜ å°„åˆ†æ...")
        print(f"ğŸ“‹ éœ€è¦çš„åˆ—å: {required_columns}")
        print(f"ğŸ“‹ å¯ç”¨çš„åˆ—å: {available_columns}")
        
        # ç¬¬ä¸€è½®ï¼šç²¾ç¡®åŒ¹é…å’Œå¸¸è§å˜ä½“åŒ¹é…
        for required in required_columns:
            matched = False
            
            # æ£€æŸ¥ç²¾ç¡®åŒ¹é…
            if required in available_columns:
                mapping[required] = required
                unmapped_available.remove(required)
                print(f"âœ… ç²¾ç¡®åŒ¹é…: {required} -> {required}")
                matched = True
                continue
            
            # æ£€æŸ¥å¸¸è§å˜ä½“
            if required in self.common_column_variants:
                variants = self.common_column_variants[required]
                for variant in variants:
                    if variant in available_columns:
                        mapping[required] = variant
                        unmapped_available.remove(variant)
                        print(f"âœ… å˜ä½“åŒ¹é…: {variant} -> {required}")
                        matched = True
                        break
            
            if not matched:
                unmapped_required.append(required)
        
        # ç¬¬äºŒè½®ï¼šæ¨¡ç³ŠåŒ¹é…
        if unmapped_required and unmapped_available:
            print(f"\nğŸ” è¿›è¡Œæ¨¡ç³ŠåŒ¹é…...")
            for required in unmapped_required:
                similar_columns = self.find_similar_columns(required, unmapped_available)
                
                if similar_columns:
                    best_match, similarity = similar_columns[0]
                    print(f"ğŸ” æ‰¾åˆ°ç›¸ä¼¼åˆ—å: {best_match} -> {required} (ç›¸ä¼¼åº¦: {similarity:.2f})")
                    
                    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç¡®è®¤æ˜ å°„
                    confirm = input(f"æ˜¯å¦å°†æ–‡ä»¶åˆ—å '{best_match}' æ˜ å°„åˆ°æ ‡å‡†å­—æ®µ '{required}'ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
                    if confirm not in ['n', 'no', 'å¦']:
                        mapping[required] = best_match
                        unmapped_available.remove(best_match)
                        print(f"âœ… ç¡®è®¤æ˜ å°„: {best_match} -> {required}")
                    else:
                        print(f"âš ï¸  è·³è¿‡æ˜ å°„: {required}")
                else:
                    print(f"âŒ æœªæ‰¾åˆ°ä¸ '{required}' ç›¸ä¼¼çš„åˆ—å")
                    print(f"ğŸ¤” è¯·é€‰æ‹©:")
                    print(f"  1. æ‰‹åŠ¨é€‰æ‹©åˆ—å (è¾“å…¥ 'm')")
                    print(f"  2. è·³è¿‡æ­¤å­—æ®µ (è¾“å…¥ 's')")
                    
                    while True:
                        choice = input(f"å¯¹äºå­—æ®µ '{required}' è¯·é€‰æ‹©: ").strip().lower()
                        if choice == 's':
                            print(f"âš ï¸  è·³è¿‡æ˜ å°„: {required}")
                            break
                        elif choice == 'm':
                            selected_column = self._manual_select_column(required, unmapped_available)
                            if selected_column:
                                mapping[required] = selected_column
                                unmapped_available.remove(selected_column)
                                unmapped_required.remove(required)
                                print(f"âœ… æ‰‹åŠ¨æ˜ å°„: {selected_column} -> {required}")
                            break
                        else:
                            print("âŒ è¯·è¾“å…¥ 'm' æˆ– 's'")
        
        # æ˜¾ç¤ºæ˜ å°„ç»“æœ
        if mapping:
            print(f"\nğŸ“‹ åˆ—åæ˜ å°„ç»“æœ:")
            for required, mapped in mapping.items():
                print(f"  {mapped} -> {required}")
        
        if unmapped_required:
            print(f"\nâš ï¸  æœªæ˜ å°„çš„åˆ—å: {unmapped_required}")
        
        return mapping
    
    def validate_required_columns(self, df: pd.DataFrame, required_columns: List[str]) -> Tuple[bool, List[str], Dict[str, str]]:
        """
        éªŒè¯å¿…éœ€çš„åˆ—åæ˜¯å¦å­˜åœ¨ï¼Œæ”¯æŒæ™ºèƒ½åŒ¹é…
        
        Args:
            df: æ•°æ®æ¡†
            required_columns: å¿…éœ€çš„åˆ—ååˆ—è¡¨
            
        Returns:
            (æ˜¯å¦éªŒè¯é€šè¿‡, ç¼ºå¤±çš„åˆ—ååˆ—è¡¨, åˆ—åæ˜ å°„å­—å…¸)
        """
        available_columns = list(df.columns)
        missing_columns = []
        column_mapping = {}
        
        if not self.enable_smart_matching:
            # ä¼ ç»Ÿä¸¥æ ¼åŒ¹é…
            for required in required_columns:
                if required not in available_columns:
                    missing_columns.append(required)
                else:
                    column_mapping[required] = required
        else:
            # æ™ºèƒ½åŒ¹é…
            column_mapping = self.smart_column_mapping(required_columns, available_columns)
            
            # æ£€æŸ¥å“ªäº›åˆ—åæ²¡æœ‰è¢«æ˜ å°„
            for required in required_columns:
                if required not in column_mapping:
                    missing_columns.append(required)
        
        return len(missing_columns) == 0, missing_columns, column_mapping
    
    def wildcard_match(self, pattern: str, text: str) -> bool:
        """
        é€šé…ç¬¦åŒ¹é…å‡½æ•°ï¼Œæ”¯æŒ * ä»£è¡¨ä»»æ„ä¸€ä¸ªå­—ç¬¦
        
        Args:
            pattern: åŒ…å« * çš„æ¨¡å¼å­—ç¬¦ä¸²
            text: è¦åŒ¹é…çš„æ–‡æœ¬
            
        Returns:
            æ˜¯å¦åŒ¹é…
        """
        if '*' not in pattern:
            return pattern == text
        
        # å°† * è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼çš„ . å­—ç¬¦
        regex_pattern = pattern.replace('*', '.')
        import re
        return bool(re.match(regex_pattern, text))
    
    def flexible_wildcard_match(self, pattern: str, text: str) -> bool:
        """
        çµæ´»çš„é€šé…ç¬¦åŒ¹é…å‡½æ•°ï¼Œæ”¯æŒ * ä»£è¡¨ä»»æ„å­—ç¬¦åºåˆ—
        
        Args:
            pattern: åŒ…å« * çš„æ¨¡å¼å­—ç¬¦ä¸²
            text: è¦åŒ¹é…çš„æ–‡æœ¬
            
        Returns:
            æ˜¯å¦åŒ¹é…
        """
        if '*' not in pattern:
            return pattern == text
        
        # å°† * è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼çš„ .* å­—ç¬¦ï¼ˆåŒ¹é…ä»»æ„å­—ç¬¦åºåˆ—ï¼‰
        regex_pattern = pattern.replace('*', '.*')
        import re
        return bool(re.match(regex_pattern, text))
    
    def enhanced_field_matching(self, pattern: str, all_fields: List[str]) -> Tuple[List[str], str]:
        """
        å¢å¼ºçš„å­—æ®µåŒ¹é…å‡½æ•°ï¼Œæ”¯æŒå¤šç§åŒ¹é…æ–¹å¼
        
        Args:
            pattern: åŒ¹é…æ¨¡å¼
            all_fields: æ‰€æœ‰å¯ç”¨å­—æ®µåˆ—è¡¨
            
        Returns:
            (åŒ¹é…çš„å­—æ®µåˆ—è¡¨, åŒ¹é…ç±»å‹æè¿°)
        """
        # 1. ç²¾ç¡®åŒ¹é…
        if pattern in all_fields:
            return [pattern], "ç²¾ç¡®åŒ¹é…"
        
        # 2. é€šé…ç¬¦åŒ¹é…
        if '*' in pattern:
            matched_fields = self.find_matching_fields(pattern, all_fields)
            if matched_fields:
                return matched_fields, "é€šé…ç¬¦åŒ¹é…"
        
        # 3. åŒ…å«åŒ¹é…ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰
        matched_fields = [field for field in all_fields if pattern.lower() in field.lower()]
        if matched_fields:
            return matched_fields, "åŒ…å«åŒ¹é…"
        
        # 4. æ— åŒ¹é…
        return [], "æ— åŒ¹é…"
    
    def find_matching_fields(self, pattern: str, all_fields: List[str]) -> List[str]:
        """
        æ ¹æ®é€šé…ç¬¦æ¨¡å¼æŸ¥æ‰¾åŒ¹é…çš„å­—æ®µ
        
        Args:
            pattern: åŒ…å« * çš„æ¨¡å¼å­—ç¬¦ä¸²
            all_fields: æ‰€æœ‰å¯ç”¨å­—æ®µåˆ—è¡¨
            
        Returns:
            åŒ¹é…çš„å­—æ®µåˆ—è¡¨
        """
        if '*' not in pattern:
            # ç²¾ç¡®åŒ¹é…
            return [field for field in all_fields if field == pattern]
        
        # é€šé…ç¬¦åŒ¹é…
        matched_fields = []
        for field in all_fields:
            if self.flexible_wildcard_match(pattern, field):
                matched_fields.append(field)
        
        return matched_fields
    
    def select_fields(self, all_fields: List[str]) -> List[str]:
        """
        å­—æ®µé€‰æ‹©åŠŸèƒ½
        
        Args:
            all_fields: æ‰€æœ‰å¯ç”¨å­—æ®µåˆ—è¡¨
            
        Returns:
            é€‰ä¸­çš„å­—æ®µåˆ—è¡¨
        """
        print(f"\n=== æ­¥éª¤3: å­—æ®µé€‰æ‹© ===")
        
        # è¯¢é—®æ˜¯å¦æ˜¾ç¤ºå­—æ®µå‡ºç°æ¬¡æ•°
        print("ğŸ¤” æ˜¯å¦æ˜¾ç¤ºå­—æ®µå‡ºç°æ¬¡æ•°ï¼Ÿ")
        print("âš ï¸  æ³¨æ„ï¼šé€‰æ‹© y å¯èƒ½ä¼šå¯¼è‡´ç¨‹åºå‡ºç°å¡é¡¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤§é‡æ–‡ä»¶æ—¶")
        show_occurrence = input("è¯·é€‰æ‹© (y/nï¼Œé»˜è®¤n): ").strip().lower()
        show_occurrence = show_occurrence in ['y', 'yes', 'æ˜¯']
        
        if show_occurrence:
            print("ğŸ“‹ å¯ç”¨å­—æ®µåˆ—è¡¨ï¼ˆæŒ‰å‡ºç°æ¬¡æ•°æ’åºï¼‰:")
        else:
            print("ğŸ“‹ å¯ç”¨å­—æ®µåˆ—è¡¨:")
        
        # åˆ†é¡µæ˜¾ç¤ºå­—æ®µ
        page_size = 10
        total_pages = (len(all_fields) + page_size - 1) // page_size
        
        for page in range(total_pages):
            start_idx = page * page_size
            end_idx = min(start_idx + page_size, len(all_fields))
            
            print(f"\n--- ç¬¬ {page + 1}/{total_pages} é¡µ ---")
            for i in range(start_idx, end_idx):
                field = all_fields[i]
                if show_occurrence:
                    # è®¡ç®—è¯¥å­—æ®µçš„å‡ºç°æ¬¡æ•°
                    occurrence_count = sum(1 for f in self.selected_files if field in self.get_file_fields(f))
                    print(f"{i + 1:2d}. {field:<25} (å‡ºç°åœ¨ {occurrence_count} ä¸ªæ–‡ä»¶ä¸­)")
                else:
                    print(f"{i + 1:2d}. {field}")
        
        print(f"\nè¯·é€‰æ‹©è¦å¯¼å…¥çš„å­—æ®µ:")
        print("ğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2,3ï¼‰")
        print("ğŸ“ è¾“å…¥å­—æ®µåç§°ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼šå­¦å·,å­¦ç”Ÿå§“åï¼‰")
        print("ğŸ“ æ”¯æŒé€šé…ç¬¦åŒ¹é…ï¼ˆ*ä»£è¡¨ä»»æ„ä¸€ä¸ªå­—ç¬¦ï¼Œå¦‚ï¼š*å­¦å·,å­¦*å·ï¼‰")
        print("ğŸ“ æ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚ï¼šå­¦å· å¯åŒ¹é… å­¦ç”Ÿå­¦å·ã€å­¦å·ä¿¡æ¯ç­‰ï¼‰")
        print("ğŸ“ è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰å­—æ®µ")
        print("ğŸ“ è¾“å…¥ 'page 1' æŸ¥çœ‹ç¬¬1é¡µï¼ˆå¯æ›¿æ¢é¡µç ï¼‰")
        
        try:
            choice = input("\nè¯·é€‰æ‹©: ").strip()
            
            if choice.startswith('page '):
                try:
                    page_num = int(choice.split()[1]) - 1
                    if 0 <= page_num < total_pages:
                        print(f"\n--- ç¬¬ {page_num + 1}/{total_pages} é¡µ ---")
                        start_idx = page_num * page_size
                        end_idx = min(start_idx + page_size, len(all_fields))
                        for i in range(start_idx, end_idx):
                            field = all_fields[i]
                            print(f"{i + 1:2d}. {field}")
                        return self.select_fields(all_fields)
                    else:
                        print("âŒ é¡µç è¶…å‡ºèŒƒå›´")
                        return self.select_fields(all_fields)
                except:
                    print("âŒ é¡µç æ ¼å¼é”™è¯¯")
                    return self.select_fields(all_fields)
            
            elif choice.lower() == 'all':
                self.selected_fields = all_fields
                print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(all_fields)} ä¸ªå­—æ®µ")
            else:
                # è§£æç”¨æˆ·é€‰æ‹©
                selected_items = [item.strip() for item in choice.split(',')]
                self.selected_fields = []
                
                for item in selected_items:
                    # å°è¯•ä½œä¸ºæ•°å­—å¤„ç†
                    try:
                        index = int(item) - 1
                        if 0 <= index < len(all_fields):
                            self.selected_fields.append(all_fields[index])
                        else:
                            print(f"âš ï¸  å­—æ®µç¼–å· {item} è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡")
                    except ValueError:
                        # ä½¿ç”¨å¢å¼ºçš„å­—æ®µåŒ¹é…å‡½æ•°
                        matched_fields, match_type = self.enhanced_field_matching(item, all_fields)
                        
                        if len(matched_fields) == 1:
                            # å•ä¸ªåŒ¹é…ï¼Œç›´æ¥æ·»åŠ 
                            self.selected_fields.append(matched_fields[0])
                            if match_type != "ç²¾ç¡®åŒ¹é…":
                                print(f"ğŸ“ {match_type}å­—æ®µ: {item} -> {matched_fields[0]}")
                        elif len(matched_fields) > 1:
                            # å¤šä¸ªåŒ¹é…ï¼Œè¯¢é—®ç”¨æˆ·
                            print(f"\nğŸ” {match_type} '{item}' åŒ¹é…åˆ° {len(matched_fields)} ä¸ªå­—æ®µ:")
                            for i, field in enumerate(matched_fields, 1):
                                print(f"  {i}. {field}")
                            
                            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä½¿ç”¨è¿™äº›åŒ¹é…çš„å­—æ®µ
                            print(f"\nğŸ¤” æ˜¯å¦ä½¿ç”¨è¿™äº›åŒ¹é…çš„å­—æ®µï¼Ÿ")
                            print(f"ğŸ“ è¾“å…¥ 'y' ä½¿ç”¨æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            print(f"ğŸ“ è¾“å…¥ 'n' è·³è¿‡æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            print(f"ğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼ˆå¦‚ï¼š1,3ï¼‰é€‰æ‹©ç‰¹å®šå­—æ®µ")
                            use_choice = input(f"\nè¯·é€‰æ‹©: ").strip().lower()
                            
                            if use_choice in ['y', 'yes', 'æ˜¯']:
                                self.selected_fields.extend(matched_fields)
                                print(f"âœ… å·²æ·»åŠ  {len(matched_fields)} ä¸ªåŒ¹é…å­—æ®µ")
                            elif use_choice in ['n', 'no', 'å¦']:
                                print(f"âš ï¸  è·³è¿‡ '{item}' çš„æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            else:
                                # ç”¨æˆ·é€‰æ‹©äº†ç‰¹å®šå­—æ®µç¼–å·
                                try:
                                    selected_indices = [int(x.strip()) - 1 for x in use_choice.split(',')]
                                    selected_fields = [matched_fields[i] for i in selected_indices if 0 <= i < len(matched_fields)]
                                    if selected_fields:
                                        self.selected_fields.extend(selected_fields)
                                        print(f"âœ… å·²æ·»åŠ  {len(selected_fields)} ä¸ªé€‰å®šå­—æ®µ")
                                    else:
                                        print(f"âš ï¸  æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè·³è¿‡")
                                except (ValueError, IndexError):
                                    print(f"âš ï¸  è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡æ‰€æœ‰åŒ¹é…å­—æ®µ")
                        else:
                            # æ— åŒ¹é…
                            print(f"âš ï¸  æœªæ‰¾åˆ°åŒ¹é…å­—æ®µ '{item}'ï¼Œè·³è¿‡")
                
                if not self.selected_fields:
                    print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè¯·é‡æ–°é€‰æ‹©")
                    return self.select_fields(all_fields)
                
                # å»é‡å¹¶ä¿æŒé¡ºåº
                seen = set()
                unique_fields = []
                for field in self.selected_fields:
                    if field not in seen:
                        seen.add(field)
                        unique_fields.append(field)
                self.selected_fields = unique_fields
                
                print(f"âœ… å·²é€‰æ‹© {len(self.selected_fields)} ä¸ªå­—æ®µ:")
                for field in self.selected_fields:
                    print(f"  ğŸ“‹ {field}")
                
            return self.selected_fields
            
        except Exception as e:
            print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {str(e)}ï¼Œè¯·é‡æ–°é€‰æ‹©")
            return self.select_fields(all_fields)
    
    def configure_deduplication(self) -> Tuple[bool, List[str]]:
        """
        å»é‡é…ç½®ï¼šè¿”å›(æ˜¯å¦å»é‡, å»é‡å­—æ®µåˆ—è¡¨)
        
        Returns:
            (æ˜¯å¦å»é‡, å»é‡å­—æ®µåˆ—è¡¨)
        """
        print(f"\n=== æ­¥éª¤4: å»é‡é…ç½® ===")
        
        # è¯¢é—®æ˜¯å¦éœ€è¦å»é‡
        print("ğŸ¤” æ˜¯å¦éœ€è¦å»é‡ï¼Ÿ")
        print("ğŸ“ å»é‡å°†åˆ é™¤é‡å¤çš„è®°å½•ï¼Œä¿ç•™ç¬¬ä¸€æ¡")
        dedup_choice = input("è¯·é€‰æ‹© (y/nï¼Œé»˜è®¤y): ").strip().lower()
        self.deduplicate = dedup_choice not in ['n', 'no', 'å¦']
        
        if not self.deduplicate:
            print("âœ… å·²é€‰æ‹©ä¸å»é‡ï¼Œå°†ä¿ç•™æ‰€æœ‰è®°å½•")
            return False, []
        
        # è¯¢é—®æ˜¯å¦å¯ç”¨äº¤äº’å¼å»é‡
        print(f"\nğŸ¤– å»é‡æ¨¡å¼é€‰æ‹©:")
        print(f"ğŸ“ è‡ªåŠ¨å»é‡: è‡ªåŠ¨ä¿ç•™æ¯ç»„çš„ç¬¬ä¸€æ¡è®°å½•")
        print(f"ğŸ¯ äº¤äº’å¼å»é‡: å½“å‘ç°å­—æ®µå€¼å†²çªæ—¶ï¼Œè®©æ‚¨é€‰æ‹©å¦‚ä½•å¤„ç†")
        interactive_choice = input("æ˜¯å¦å¯ç”¨äº¤äº’å¼å»é‡ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        self.enable_interactive_dedup = interactive_choice not in ['n', 'no', 'å¦']
        
        if self.enable_interactive_dedup:
            print("âœ… å·²å¯ç”¨äº¤äº’å¼å»é‡ï¼Œé‡åˆ°å†²çªæ—¶ä¼šè¯¢é—®æ‚¨çš„å¤„ç†æ–¹å¼")
        else:
            print("âœ… ä½¿ç”¨è‡ªåŠ¨å»é‡æ¨¡å¼ï¼Œå°†è‡ªåŠ¨ä¿ç•™ç¬¬ä¸€æ¡è®°å½•")
        
        # å¦‚æœå»é‡ï¼Œé€‰æ‹©å»é‡å­—æ®µ
        print(f"\nğŸ“‹ è¯·é€‰æ‹©å»é‡å­—æ®µï¼ˆåŸºäºè¿™äº›å­—æ®µçš„ç»„åˆæ¥åˆ¤æ–­é‡å¤ï¼‰:")
        print("å¯ç”¨å­—æ®µåˆ—è¡¨:")
        for i, field in enumerate(self.selected_fields, 1):
            print(f"{i:2d}. {field}")
        
        print(f"\nğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2ï¼‰")
        print(f"ğŸ“ è¾“å…¥å­—æ®µåç§°ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼šå­¦å·,å­¦ç”Ÿå§“åï¼‰")
        print(f"ğŸ“ æ”¯æŒé€šé…ç¬¦åŒ¹é…ï¼ˆ*ä»£è¡¨ä»»æ„ä¸€ä¸ªå­—ç¬¦ï¼Œå¦‚ï¼š*å­¦å·,å­¦*å·ï¼‰")
        print(f"ğŸ“ æ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚ï¼šå­¦å· å¯åŒ¹é… å­¦ç”Ÿå­¦å·ã€å­¦å·ä¿¡æ¯ç­‰ï¼‰")
        print(f"ğŸ“ è¾“å…¥ 'all' ä½¿ç”¨æ‰€æœ‰é€‰ä¸­å­—æ®µè¿›è¡Œå»é‡")
        print(f"ğŸ“ è¾“å…¥ 'single 1' åªä½¿ç”¨ç¬¬1ä¸ªå­—æ®µå»é‡")
        
        try:
            choice = input("\nè¯·é€‰æ‹©å»é‡å­—æ®µ: ").strip().lower()
            
            if choice.lower() == 'all':
                self.dedup_fields = self.selected_fields.copy()
                print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(self.dedup_fields)} ä¸ªå­—æ®µè¿›è¡Œå»é‡")
            elif choice.startswith('single '):
                try:
                    field_idx = int(choice.split()[1]) - 1
                    if 0 <= field_idx < len(self.selected_fields):
                        self.dedup_fields = [self.selected_fields[field_idx]]
                        print(f"âœ… å·²é€‰æ‹©å•ä¸ªå­—æ®µè¿›è¡Œå»é‡: {self.dedup_fields[0]}")
                    else:
                        print("âŒ å­—æ®µç¼–å·è¶…å‡ºèŒƒå›´")
                        return self.configure_deduplication()
                except:
                    print("âŒ å­—æ®µç¼–å·æ ¼å¼é”™è¯¯")
                    return self.configure_deduplication()
            else:
                # è§£æç”¨æˆ·é€‰æ‹©
                selected_items = [item.strip() for item in choice.split(',')]
                self.dedup_fields = []
                
                for item in selected_items:
                    # å°è¯•ä½œä¸ºæ•°å­—å¤„ç†
                    try:
                        index = int(item) - 1
                        if 0 <= index < len(self.selected_fields):
                            self.dedup_fields.append(self.selected_fields[index])
                        else:
                            print(f"âš ï¸  å­—æ®µç¼–å· {item} è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡")
                    except ValueError:
                        # ä½¿ç”¨å¢å¼ºçš„å­—æ®µåŒ¹é…å‡½æ•°
                        matched_fields, match_type = self.enhanced_field_matching(item, self.selected_fields)
                        
                        if len(matched_fields) == 1:
                            # å•ä¸ªåŒ¹é…ï¼Œç›´æ¥æ·»åŠ 
                            self.dedup_fields.append(matched_fields[0])
                            if match_type != "ç²¾ç¡®åŒ¹é…":
                                print(f"ğŸ“ {match_type}å­—æ®µ: {item} -> {matched_fields[0]}")
                        elif len(matched_fields) > 1:
                            # å¤šä¸ªåŒ¹é…ï¼Œè¯¢é—®ç”¨æˆ·
                            print(f"\nğŸ” {match_type} '{item}' åŒ¹é…åˆ° {len(matched_fields)} ä¸ªå­—æ®µ:")
                            for i, field in enumerate(matched_fields, 1):
                                print(f"  {i}. {field}")
                            
                            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä½¿ç”¨è¿™äº›åŒ¹é…çš„å­—æ®µ
                            print(f"\nğŸ¤” æ˜¯å¦ä½¿ç”¨è¿™äº›åŒ¹é…çš„å­—æ®µè¿›è¡Œå»é‡ï¼Ÿ")
                            print(f"ğŸ“ è¾“å…¥ 'y' ä½¿ç”¨æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            print(f"ğŸ“ è¾“å…¥ 'n' è·³è¿‡æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            print(f"ğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼ˆå¦‚ï¼š1,3ï¼‰é€‰æ‹©ç‰¹å®šå­—æ®µ")
                            use_choice = input(f"\nè¯·é€‰æ‹©: ").strip().lower()
                            
                            if use_choice in ['y', 'yes', 'æ˜¯']:
                                self.dedup_fields.extend(matched_fields)
                                print(f"âœ… å·²æ·»åŠ  {len(matched_fields)} ä¸ªåŒ¹é…å­—æ®µ")
                            elif use_choice in ['n', 'no', 'å¦']:
                                print(f"âš ï¸  è·³è¿‡ '{item}' çš„æ‰€æœ‰åŒ¹é…å­—æ®µ")
                            else:
                                # ç”¨æˆ·é€‰æ‹©äº†ç‰¹å®šå­—æ®µç¼–å·
                                try:
                                    selected_indices = [int(x.strip()) - 1 for x in use_choice.split(',')]
                                    selected_fields = [matched_fields[i] for i in selected_indices if 0 <= i < len(matched_fields)]
                                    if selected_fields:
                                        self.dedup_fields.extend(selected_fields)
                                        print(f"âœ… å·²æ·»åŠ  {len(selected_fields)} ä¸ªé€‰å®šå­—æ®µ")
                                    else:
                                        print(f"âš ï¸  æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè·³è¿‡")
                                except (ValueError, IndexError):
                                    print(f"âš ï¸  è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡æ‰€æœ‰åŒ¹é…å­—æ®µ")
                        else:
                            # æ— åŒ¹é…
                            print(f"âš ï¸  æœªæ‰¾åˆ°åŒ¹é…å­—æ®µ '{item}'ï¼Œè·³è¿‡")
                
                if not self.dedup_fields:
                    print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè¯·é‡æ–°é€‰æ‹©")
                    return self.configure_deduplication()
                
                # å»é‡å¹¶ä¿æŒé¡ºåº
                seen = set()
                unique_fields = []
                for field in self.dedup_fields:
                    if field not in seen:
                        seen.add(field)
                        unique_fields.append(field)
                self.dedup_fields = unique_fields
                
                print(f"âœ… å·²é€‰æ‹© {len(self.dedup_fields)} ä¸ªå­—æ®µè¿›è¡Œå»é‡:")
                for field in self.dedup_fields:
                    print(f"  ğŸ” {field}")
                
            return True, self.dedup_fields
            
        except Exception as e:
            print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {str(e)}ï¼Œè¯·é‡æ–°é€‰æ‹©")
            return self.configure_deduplication()
    
    def process_data(self, files: List[str], selected_fields: List[str], 
                    deduplicate: bool, dedup_fields: List[str]) -> pd.DataFrame:
        """
        æ•°æ®å¤„ç†ä¸»å‡½æ•°
        
        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            selected_fields: é€‰ä¸­çš„å­—æ®µ
            deduplicate: æ˜¯å¦å»é‡
            dedup_fields: å»é‡å­—æ®µåˆ—è¡¨
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ¡†
        """
        print(f"\n=== æ­¥éª¤5: æ•°æ®å¤„ç† ===")
        all_data = []
        total_rows = 0
        
        print("ğŸ”„ å¼€å§‹å¤„ç†æ–‡ä»¶...")
        
        for i, file in enumerate(files, 1):
            try:
                print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(files)}: {os.path.basename(file)}")
                df = pd.read_excel(file)
                
                # ä½¿ç”¨æ™ºèƒ½åˆ—ååŒ¹é…éªŒè¯å¿…éœ€å­—æ®µ
                is_valid, missing_fields, column_mapping = self.validate_required_columns(df, selected_fields)
                
                if not is_valid:
                    print(f"âš ï¸  è­¦å‘Šï¼šæ–‡ä»¶ç¼ºå°‘å­—æ®µ {missing_fields}ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
                    continue
                
                # ä½¿ç”¨æ˜ å°„åçš„åˆ—å
                mapped_fields = [column_mapping.get(field, field) for field in selected_fields]
                print(f"ğŸ“‹ ä½¿ç”¨æ˜ å°„åçš„åˆ—å: {mapped_fields}")
                
                # ä½¿ç”¨æ˜ å°„åçš„åˆ—åæå–æ•°æ®
                selected_data = df[mapped_fields].copy()
                
                # å°†åˆ—åé‡å‘½åä¸ºæ ‡å‡†åç§°ï¼Œå¹¶æŒ‰ç…§ç”¨æˆ·é€‰æ‹©çš„é¡ºåºé‡æ–°æ’åˆ—
                rename_mapping = {}
                for i, field in enumerate(selected_fields):
                    if mapped_fields[i] != field:
                        rename_mapping[mapped_fields[i]] = field
                
                if rename_mapping:
                    selected_data = selected_data.rename(columns=rename_mapping)
                    print(f"ğŸ“ åˆ—åé‡å‘½å: {rename_mapping}")
                
                # æŒ‰ç…§ç”¨æˆ·é€‰æ‹©çš„å­—æ®µé¡ºåºé‡æ–°æ’åˆ—åˆ—
                selected_data = selected_data[selected_fields]
                print(f"ğŸ“‹ æŒ‰ç”¨æˆ·é€‰æ‹©é¡ºåºæ’åˆ—å­—æ®µ: {selected_fields}")
                
                all_data.append(selected_data)
                file_rows = len(selected_data)
                total_rows += file_rows
                print(f"âœ… æˆåŠŸè¯»å– {file_rows} è¡Œæ•°æ®")
                
            except Exception as e:
                print(f"âŒ é”™è¯¯ï¼šå¤„ç†æ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
                continue
        
        if not all_data:
            print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ•°æ®")
            return pd.DataFrame()
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        print(f"\nğŸ”„ æ­£åœ¨åˆå¹¶æ•°æ®...")
        combined_df = pd.concat(all_data, ignore_index=True)
        print(f"âœ… åˆå¹¶å®Œæˆï¼Œæ€»è¡Œæ•°: {len(combined_df)}")
        

        
        # å»é‡å¤„ç†
        if deduplicate and dedup_fields:
            print(f"\nğŸ”„ æ­£åœ¨æŒ‰å­—æ®µ {dedup_fields} å»é‡...")
            before_count = len(combined_df)
            
            # æŸ¥æ‰¾é‡å¤è®°å½•
            duplicated_mask = combined_df.duplicated(subset=dedup_fields, keep=False)
            duplicated_records = combined_df[duplicated_mask]
            
            # ä¿å­˜é‡å¤è®°å½•åˆ°å®ä¾‹å˜é‡
            self.duplicate_records = duplicated_records.copy()
            self.duplicate_count = len(duplicated_records)
            
            if len(duplicated_records) > 0:
                print(f"\n" + "ğŸ”" + "="*58)
                print(f"ğŸ“‹ å‘ç°é‡å¤è®°å½•è¯¦æƒ…")
                print(f"ğŸ”" + "="*58)
                print(f"ğŸ“Š é‡å¤è®°å½•æ€»æ•°: {len(duplicated_records)} æ¡")
                print(f"ğŸ“Š é‡å¤ç»„æ•°é‡: {duplicated_records.groupby(dedup_fields).ngroups} ç»„")
                print(f"ğŸ”‘ å»é‡ä¾æ®å­—æ®µ: {', '.join(dedup_fields)}")
                
                # æŒ‰å»é‡å­—æ®µåˆ†ç»„æ˜¾ç¤ºé‡å¤è®°å½•
                duplicate_groups = duplicated_records.groupby(dedup_fields)
                group_count = 0
                
                for group_key, group_df in duplicate_groups:
                    group_count += 1
                    if group_count <= 10:  # æœ€å¤šæ˜¾ç¤ºå‰10ç»„é‡å¤è®°å½•
                        print(f"\n  {'='*50}")
                        print(f"  ğŸ“ é‡å¤ç»„ {group_count} (å…± {len(group_df)} æ¡é‡å¤è®°å½•)")
                        print(f"  {'='*50}")
                        
                        # æ˜¾ç¤ºé‡å¤å­—æ®µçš„å€¼
                        if isinstance(group_key, tuple):
                            for i, field in enumerate(dedup_fields):
                                print(f"  ğŸ”‘ {field}: {group_key[i]}")
                        else:
                            print(f"  ğŸ”‘ {dedup_fields[0]}: {group_key}")
                        
                        print(f"  {'-'*40}")
                        
                        # æ˜¾ç¤ºé‡å¤è®°å½•çš„è¯¦ç»†ä¿¡æ¯ï¼ˆæœ€å¤šæ˜¾ç¤º3æ¡ï¼‰
                        display_count = min(3, len(group_df))
                        for idx, (_, row) in enumerate(group_df.head(display_count).iterrows()):
                            print(f"  ğŸ“„ ç¬¬ {idx + 1} æ¡è®°å½•:")
                            
                            # å°†å­—æ®µå€¼æ ¼å¼åŒ–ä¸ºè¡¨æ ¼å½¢å¼
                            field_values = []
                            for field in combined_df.columns:
                                value = row[field]
                                if pd.notna(value) and str(value).strip():
                                    # å¤„ç†è¿‡é•¿çš„å€¼
                                    str_value = str(value)
                                    if len(str_value) > 20:
                                        str_value = str_value[:17] + "..."
                                    field_values.append(f"{field}: {str_value}")
                                else:
                                    field_values.append(f"{field}: <ç©ºå€¼>")
                            
                            # æ¯è¡Œæ˜¾ç¤º2ä¸ªå­—æ®µï¼Œç¾åŒ–æ˜¾ç¤º
                            for i in range(0, len(field_values), 2):
                                line_fields = field_values[i:i+2]
                                if len(line_fields) == 2:
                                    print(f"     {line_fields[0]:<30} | {line_fields[1]}")
                                else:
                                    print(f"     {line_fields[0]}")
                            
                            if idx < display_count - 1:
                                print(f"     {'-'*35}")
                        
                        if len(group_df) > display_count:
                            print(f"  âš ï¸  è¿˜æœ‰ {len(group_df) - display_count} æ¡é‡å¤è®°å½•æœªæ˜¾ç¤º")
                    else:
                        break
                
                if group_count > 10:
                    print(f"\n  âš ï¸  è¿˜æœ‰ {len(duplicate_groups) - 10} ç»„é‡å¤è®°å½•æœªæ˜¾ç¤º")
                
                print(f"\n" + "ğŸ”§" + "-"*58)
                if self.enable_interactive_dedup:
                    print(f"ğŸ’¡ äº¤äº’å¼å»é‡ç­–ç•¥è¯´æ˜:")
                    print(f"   â€¢ å¯¹äºæœ‰å­—æ®µå€¼å†²çªçš„é‡å¤ç»„ï¼Œå°†è¯¢é—®æ‚¨çš„å¤„ç†æ–¹å¼")
                    print(f"   â€¢ æ‚¨å¯ä»¥é€‰æ‹©ä¿ç•™ç‰¹å®šå€¼æˆ–åˆ›å»ºå¤šæ¡è®°å½•")
                    print(f"   â€¢ æ‰€æœ‰åŸå§‹é‡å¤è®°å½•å°†ä¿å­˜åˆ°Excelçš„'é‡å¤è®°å½•'å·¥ä½œè¡¨ä¸­")
                else:
                    print(f"ğŸ’¡ è‡ªåŠ¨å»é‡ç­–ç•¥è¯´æ˜:")
                    print(f"   â€¢ ä¿ç•™æ¯ç»„çš„ç¬¬ä¸€æ¡è®°å½•")
                    print(f"   â€¢ åˆ é™¤åç»­æ‰€æœ‰é‡å¤è®°å½•") 
                    print(f"   â€¢ æ‰€æœ‰é‡å¤è®°å½•å°†ä¿å­˜åˆ°Excelçš„'é‡å¤è®°å½•'å·¥ä½œè¡¨ä¸­")
                print(f"ğŸ”§" + "-"*58)
            
            # æ‰§è¡Œå»é‡å¤„ç†
            if self.enable_interactive_dedup and len(duplicated_records) > 0:
                print(f"\nğŸ¯ å¼€å§‹äº¤äº’å¼å»é‡å¤„ç†...")
                processed_records = []
                duplicate_groups = duplicated_records.groupby(dedup_fields)
                
                for group_key, group_df in duplicate_groups:
                    resolved_records = self.resolve_field_conflicts(group_key, group_df, dedup_fields)
                    if not resolved_records.empty:
                        processed_records.append(resolved_records)
                
                if processed_records:
                    # é‡æ–°æ„å»ºæ•°æ®æ¡†ï¼šéé‡å¤è®°å½• + å¤„ç†åçš„é‡å¤è®°å½•
                    non_duplicated_records = combined_df[~duplicated_mask]
                    processed_duplicates = pd.concat(processed_records, ignore_index=True)
                    combined_df = pd.concat([non_duplicated_records, processed_duplicates], ignore_index=True)
                else:
                    # å¦‚æœæ‰€æœ‰é‡å¤ç»„éƒ½è¢«è·³è¿‡ï¼Œåªä¿ç•™éé‡å¤è®°å½•
                    combined_df = combined_df[~duplicated_mask]
                
                after_count = len(combined_df)
                removed_count = before_count - after_count
            else:
                # ä¼ ç»Ÿè‡ªåŠ¨å»é‡
                combined_df = combined_df.drop_duplicates(subset=dedup_fields, keep='first')
                after_count = len(combined_df)
                removed_count = before_count - after_count
            
            print(f"\nâœ… å»é‡å®Œæˆ:")
            print(f"  ğŸ“Š å»é‡å‰è¡Œæ•°: {before_count}")
            print(f"  ğŸ“Š å»é‡åè¡Œæ•°: {after_count}")
            print(f"  ğŸ—‘ï¸  åˆ é™¤é‡å¤è®°å½•: {removed_count}")
            
            if removed_count > 0:
                print(f"  ğŸ“ˆ å»é‡ç‡: {removed_count/before_count*100:.1f}%")
        
        return combined_df
    
    def export_to_excel(self, df: pd.DataFrame, output_filename: str = None):
        """
        å¯¼å‡ºåˆ°Excel
        
        Args:
            df: æ•°æ®æ¡†
            output_filename: è¾“å‡ºæ–‡ä»¶å
        """
        if output_filename is None:
            output_filename = self.output_filename
        
        print(f"\n=== æ­¥éª¤6: å¯¼å‡ºç»“æœ ===")
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        output_path = output_filename
        if not os.path.dirname(output_path):
            output_path = os.path.join(".", output_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(output_path):
            print(f"âš ï¸  æ–‡ä»¶ '{output_filename}' å·²å­˜åœ¨")
            overwrite = input("æ˜¯å¦è¦†ç›–ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            if overwrite not in ['y', 'yes', 'æ˜¯']:
                # ç”Ÿæˆæ–°æ–‡ä»¶å
                base_name = os.path.splitext(output_filename)[0]
                extension = os.path.splitext(output_filename)[1]
                counter = 1
                while True:
                    new_filename = f"{base_name}_{counter}{extension}"
                    new_output_path = os.path.join(".", new_filename)
                    if not os.path.exists(new_output_path):
                        output_path = new_output_path
                        output_filename = new_filename
                        print(f"ğŸ“ ä½¿ç”¨æ–°æ–‡ä»¶å: {new_filename}")
                        break
                    counter += 1
            else:
                # å°è¯•åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶
                try:
                    os.remove(output_path)
                    print(f"âœ… å·²åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶: {output_filename}")
                except PermissionError:
                    print(f"âŒ æ— æ³•åˆ é™¤æ–‡ä»¶ '{output_filename}'ï¼Œæ–‡ä»¶å¯èƒ½è¢«å…¶ä»–ç¨‹åºå ç”¨")
                    print("è¯·å…³é—­Excelæˆ–å…¶ä»–å¯èƒ½æ‰“å¼€è¯¥æ–‡ä»¶çš„ç¨‹åºï¼Œç„¶åé‡è¯•")
                    return None
                except Exception as e:
                    print(f"âŒ åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                    return None
        
        try:
            # åˆ›å»ºExcelå†™å…¥å™¨ï¼Œæ”¯æŒå¤šä¸ªå·¥ä½œè¡¨
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # ä¸»æ•°æ®è¡¨
                df.to_excel(writer, sheet_name='åˆå¹¶æ•°æ®', index=False)
                
                # ç»Ÿè®¡ä¿¡æ¯è¡¨
                stats_items = [
                    'æ€»è®°å½•æ•°',
                    'å¤„ç†æ–‡ä»¶æ•°',
                    'é€‰æ‹©å­—æ®µæ•°',
                    'æ˜¯å¦å»é‡',
                    'å»é‡å­—æ®µæ•°',
                    'åˆ é™¤é‡å¤è®°å½•æ•°'
                ]
                stats_values = [
                    len(df),
                    len(self.selected_files),
                    len(self.selected_fields),
                    'æ˜¯' if self.deduplicate else 'å¦',
                    len(self.dedup_fields) if self.deduplicate else 0,
                    self.duplicate_count - len(df) if self.deduplicate and self.duplicate_count > 0 else 0
                ]
                

                
                stats_items.append('å¤„ç†æ—¶é—´')
                stats_values.append(pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'))
                
                stats_data = {
                    'ç»Ÿè®¡é¡¹ç›®': stats_items,
                    'æ•°å€¼': stats_values
                }
                stats_df = pd.DataFrame(stats_data)
                stats_df.to_excel(writer, sheet_name='å¤„ç†ç»Ÿè®¡', index=False)
                
                # å­—æ®µä¿¡æ¯è¡¨
                field_info = {
                    'å­—æ®µåç§°': self.selected_fields,
                    'å­—æ®µç±»å‹': [str(df[field].dtype) for field in self.selected_fields],
                    'éç©ºå€¼æ•°é‡': [df[field].notna().sum() for field in self.selected_fields],
                    'ç©ºå€¼æ•°é‡': [df[field].isna().sum() for field in self.selected_fields]
                }
                field_df = pd.DataFrame(field_info)
                field_df.to_excel(writer, sheet_name='å­—æ®µä¿¡æ¯', index=False)
                
                # é‡å¤è®°å½•è¡¨ï¼ˆå¦‚æœæœ‰é‡å¤è®°å½•ï¼‰
                sheet_names = ['åˆå¹¶æ•°æ®', 'å¤„ç†ç»Ÿè®¡', 'å­—æ®µä¿¡æ¯']
                if not self.duplicate_records.empty:
                    # æ·»åŠ é‡å¤æ ‡è®°åˆ—
                    duplicate_export = self.duplicate_records.copy()
                    
                    # ä¸ºé‡å¤è®°å½•æ·»åŠ åˆ†ç»„ä¿¡æ¯
                    if self.dedup_fields:
                        duplicate_groups = duplicate_export.groupby(self.dedup_fields)
                        group_ids = []
                        group_sizes = []
                        
                        for group_id, (group_key, group_df) in enumerate(duplicate_groups, 1):
                            for _ in range(len(group_df)):
                                group_ids.append(group_id)
                                group_sizes.append(len(group_df))
                        
                        duplicate_export.insert(0, 'é‡å¤ç»„ID', group_ids)
                        duplicate_export.insert(1, 'ç»„å†…é‡å¤æ•°', group_sizes)
                    
                    duplicate_export.to_excel(writer, sheet_name='é‡å¤è®°å½•', index=False)
                    sheet_names.append('é‡å¤è®°å½•')
                    print(f"ğŸ“‹ é‡å¤è®°å½•å·²ä¿å­˜åˆ° 'é‡å¤è®°å½•' å·¥ä½œè¡¨ï¼Œå…± {len(self.duplicate_records)} æ¡è®°å½•")
            
            print(f"âœ… æ•°æ®å·²æˆåŠŸå¯¼å‡ºåˆ°: {output_path}")
            print(f"æ€»å…±å¯¼å‡º {len(df)} æ¡è®°å½•")
            print(f"ğŸ“‹ åŒ…å«å·¥ä½œè¡¨: {', '.join(sheet_names)}")
            
            return output_path
            
        except PermissionError:
            print(f"âŒ æƒé™é”™è¯¯ï¼šæ— æ³•ä¿å­˜åˆ° {output_path}")
            print("è¯·ç¡®ä¿æ–‡ä»¶æ²¡æœ‰è¢«å…¶ä»–ç¨‹åºï¼ˆå¦‚Excelï¼‰æ‰“å¼€")
            print("å»ºè®®ï¼š")
            print("1. å…³é—­å¯èƒ½æ‰“å¼€è¯¥æ–‡ä»¶çš„Excelç¨‹åº")
            print("2. ä½¿ç”¨ä¸åŒçš„æ–‡ä»¶å")
            print("3. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«è®¾ç½®ä¸ºåªè¯»")
            return None
        except Exception as e:
            print(f"âŒ å¯¼å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return None
    
    def set_output_filename(self):
        """è®¾ç½®è¾“å‡ºæ–‡ä»¶å"""
        print(f"\n=== æ­¥éª¤4.5: è¾“å‡ºè®¾ç½® ===")
        print(f"ğŸ“ å½“å‰è¾“å‡ºæ–‡ä»¶å: {self.output_filename}")
        filename = input("è¯·è¾“å…¥æ–°çš„è¾“å‡ºæ–‡ä»¶ååˆ—å¦‚G:\\wang\\excelï¼ˆé»˜è®¤æ ¼å¼ä¸ºxlsxï¼‰: ").strip()
        if filename:
            # ç¡®ä¿æ–‡ä»¶æ‰©å±•åæ­£ç¡®
            if not filename.endswith(('.xlsx', '.xls')):
                filename += '.xlsx'
            self.output_filename = filename
        print(f"âœ… è¾“å‡ºæ–‡ä»¶å: {self.output_filename}")
    

    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        print("=" * 60)
        print("ğŸ¯ Excelæ–‡ä»¶å¤„ç†å·¥å…· v2.4")
        print("=" * 60)
        
        # æ˜¾ç¤ºæ™ºèƒ½åŒ¹é…é…ç½®ï¼ˆé»˜è®¤å¯ç”¨ï¼Œä¸è¯¢é—®ç”¨æˆ·ï¼‰
        print(f"\n=== æ™ºèƒ½åŒ¹é…é…ç½® ===")
        print(f"ğŸ¤– æ™ºèƒ½åŒ¹é…è®¾ç½®ï¼ˆå·²å¯ç”¨ï¼‰:")
        print(f"  â€¢ æ™ºèƒ½åŒ¹é…: {'å¯ç”¨' if self.enable_smart_matching else 'ç¦ç”¨'}")
        print(f"  â€¢ è‡ªåŠ¨æ¸…ç†åˆ—å: {'å¯ç”¨' if self.auto_clean_columns else 'ç¦ç”¨'}")
        print(f"  â€¢ ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold}")
        print(f"âœ… ä½¿ç”¨é»˜è®¤æ™ºèƒ½åŒ¹é…è®¾ç½®ï¼Œæå‡å¤„ç†æ•ˆç‡")
        
        try:
            # 1. æ–‡ä»¶é€‰æ‹©
            folder_path = input("è¯·è¾“å…¥åŒ…å«Excelæ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆæˆ–æŒ‰å›è½¦ä½¿ç”¨å½“å‰ç›®å½•ï¼‰: ").strip()
            if not folder_path:
                folder_path = "."
            
            files = self.select_files(folder_path)
            if not files:
                print("âŒ æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶ï¼Œç¨‹åºé€€å‡º")
                return
            
            # 1.5. æ–‡ä»¶å¤‡ä»½
            if not self.backup_files(files):
                print("âŒ å¤‡ä»½å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
                return
            
            # 2. å­—æ®µåˆ†æ
            all_fields = self.get_field_list(files)
            if not all_fields:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•å­—æ®µï¼Œç¨‹åºé€€å‡º")
                return
            
            # 3. å­—æ®µé€‰æ‹©
            selected_fields = self.select_fields(all_fields)
            if not selected_fields:
                print("âŒ æœªé€‰æ‹©ä»»ä½•å­—æ®µï¼Œç¨‹åºé€€å‡º")
                return
            

            
            # 4. å»é‡é…ç½®
            deduplicate, dedup_fields = self.configure_deduplication()
            
            # 4.5. è¾“å‡ºè®¾ç½®
            self.set_output_filename()
            
            # 5. æ•°æ®å¤„ç†
            result_df = self.process_data(files, selected_fields, deduplicate, dedup_fields)
            if result_df.empty:
                print("âŒ æ²¡æœ‰æ•°æ®å¯å¤„ç†ï¼Œç¨‹åºé€€å‡º")
                return
            
            # 6. å¯¼å‡ºç»“æœ
            output_path = self.export_to_excel(result_df)
            
            if output_path:
                print(f"\n" + "=" * 60)
                print("ğŸ‰ å¤„ç†å®Œæˆï¼")
                print("=" * 60)
                print(f"ğŸ“„ ç»“æœæ–‡ä»¶: {output_path}")
                print(f"ğŸ“Š å¤„ç†è®°å½•æ•°: {len(result_df)}")
                print(f"ğŸ“ å¤„ç†æ–‡ä»¶æ•°: {len(files)}")
                print(f"ğŸ“‹ é€‰æ‹©å­—æ®µæ•°: {len(selected_fields)}")
                if deduplicate and dedup_fields:
                    print(f"ğŸ” å»é‡å­—æ®µ: {', '.join(dedup_fields)}")
                    if self.duplicate_count > 0:
                        removed_count = self.duplicate_count - len(result_df)
                        print(f"ğŸ“Š å‘ç°é‡å¤è®°å½•: {self.duplicate_count} æ¡")
                        print(f"ğŸ—‘ï¸  åˆ é™¤é‡å¤è®°å½•: {removed_count} æ¡")
                        print(f"ğŸ’¾ é‡å¤è®°å½•å·²ä¿å­˜åˆ° 'é‡å¤è®°å½•' å·¥ä½œè¡¨")
                    else:
                        print(f"âœ… æœªå‘ç°é‡å¤è®°å½•")

                

            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
    
    def resolve_field_conflicts(self, group_key, group_df: pd.DataFrame, dedup_fields: List[str]) -> pd.DataFrame:
        """
        è§£å†³å­—æ®µå€¼å†²çªï¼Œè®©ç”¨æˆ·é€‰æ‹©å¦‚ä½•å¤„ç†ä¸åŒçš„å­—æ®µå€¼
        
        Args:
            group_key: é‡å¤ç»„çš„é”®å€¼
            group_df: é‡å¤ç»„çš„æ•°æ®æ¡†
            dedup_fields: å»é‡å­—æ®µåˆ—è¡¨
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ¡†
        """
        if not self.enable_interactive_dedup or len(group_df) <= 1:
            return group_df.head(1)  # é»˜è®¤ä¿ç•™ç¬¬ä¸€æ¡
        
        # æ£€æŸ¥éå»é‡å­—æ®µæ˜¯å¦æœ‰å†²çª
        non_dedup_fields = [field for field in group_df.columns if field not in dedup_fields]
        conflicts = {}
        
        for field in non_dedup_fields:
            # è·å–å”¯ä¸€å€¼ï¼Œä¿æŒå‡ºç°é¡ºåº
            seen = set()
            unique_values = []
            for value in group_df[field].dropna():
                if value not in seen:
                    seen.add(value)
                    unique_values.append(value)
            
            if len(unique_values) > 1:
                conflicts[field] = unique_values
        
        if not conflicts:
            return group_df.head(1)  # æ²¡æœ‰å†²çªï¼Œä¿ç•™ç¬¬ä¸€æ¡
        
        print(f"\n{'ğŸ”§' + '='*60}")
        print(f"âš ï¸  å‘ç°å­—æ®µå€¼å†²çªï¼")
        print(f"{'ğŸ”§' + '='*60}")
        
        # æ˜¾ç¤ºé‡å¤ç»„ä¿¡æ¯
        if isinstance(group_key, tuple):
            for i, field in enumerate(dedup_fields):
                print(f"ğŸ”‘ {field}: {group_key[i]}")
        else:
            print(f"ğŸ”‘ {dedup_fields[0]}: {group_key}")
        
        print(f"\nğŸ“Š è¯¥ç»„æœ‰ {len(group_df)} æ¡è®°å½•ï¼Œä»¥ä¸‹å­—æ®µå­˜åœ¨ä¸åŒå€¼:")
        
        # æ˜¾ç¤ºå†²çªçš„å­—æ®µå’Œå€¼
        for field, values in conflicts.items():
            print(f"\nğŸ“ å­—æ®µ '{field}' çš„ä¸åŒå€¼:")
            for i, value in enumerate(values, 1):
                if pd.isna(value):
                    print(f"  {i}. <ç©ºå€¼>")
                else:
                    print(f"  {i}. {value}")
        
        print(f"\nğŸ¤” è¯·é€‰æ‹©å¤„ç†æ–¹å¼:")
        print(f"  1. ä¿ç•™ç¬¬ä¸€æ¡è®°å½• (é»˜è®¤)")
        print(f"  2. æ‰‹åŠ¨é€‰æ‹©æ¯ä¸ªå†²çªå­—æ®µçš„å€¼")
        print(f"  3. ä¸ºæ¯ä¸ªä¸åŒå€¼åˆ›å»ºå•ç‹¬è®°å½•")
        print(f"  4. è·³è¿‡æ­¤ç»„ï¼Œä¸åšå¤„ç†")
        
        while True:
            try:
                choice = input("\nè¯·é€‰æ‹©å¤„ç†æ–¹å¼ (1-4ï¼Œé»˜è®¤1): ").strip()
                if not choice:
                    choice = "1"
                
                if choice == "1":
                    print("âœ… ä¿ç•™ç¬¬ä¸€æ¡è®°å½•")
                    return group_df.head(1)
                
                elif choice == "2":
                    return self._manual_resolve_conflicts(group_df, conflicts, dedup_fields)
                
                elif choice == "3":
                    print("âœ… ä¸ºæ¯ä¸ªä¸åŒå€¼åˆ›å»ºå•ç‹¬è®°å½•")
                    return self._create_separate_records(group_df, conflicts, dedup_fields)
                
                elif choice == "4":
                    print("âš ï¸  è·³è¿‡æ­¤ç»„")
                    return pd.DataFrame()  # è¿”å›ç©ºæ•°æ®æ¡†
                
                else:
                    print("âŒ è¯·è¾“å…¥ 1-4 ä¹‹é—´çš„æ•°å­—")
                    
            except KeyboardInterrupt:
                print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œä¿ç•™ç¬¬ä¸€æ¡è®°å½•")
                return group_df.head(1)
    
    def _manual_resolve_conflicts(self, group_df: pd.DataFrame, conflicts: Dict, dedup_fields: List[str]) -> pd.DataFrame:
        """æ‰‹åŠ¨è§£å†³å†²çª"""
        result_record = group_df.iloc[0].copy()  # åŸºäºç¬¬ä¸€æ¡è®°å½•
        
        print(f"\nğŸ”§ å¼€å§‹æ‰‹åŠ¨è§£å†³å†²çª...")
        print(f"ğŸ“„ åŸºç¡€è®°å½•ï¼ˆç¬¬ä¸€æ¡ï¼‰: {dict(result_record)}")
        
        for field, values in conflicts.items():
            print(f"\nğŸ“ è¯·é€‰æ‹©å­—æ®µ '{field}' çš„å€¼:")
            print(f"ğŸ” å½“å‰å€¼: {result_record[field]}")
            print(f"ğŸ“‹ å¯é€‰å€¼:")
            
            for i, value in enumerate(values, 1):
                if pd.isna(value):
                    print(f"  {i}. <ç©ºå€¼>")
                else:
                    print(f"  {i}. {value}")
            
            while True:
                try:
                    choice = input(f"è¯·é€‰æ‹© (1-{len(values)}): ").strip()
                    choice_idx = int(choice) - 1
                    if 0 <= choice_idx < len(values):
                        selected_value = values[choice_idx]
                        old_value = result_record[field]
                        result_record[field] = selected_value
                        
                        if pd.isna(selected_value):
                            print(f"âœ… å·²é€‰æ‹©: <ç©ºå€¼>")
                        else:
                            print(f"âœ… å·²é€‰æ‹©: {selected_value}")
                        
                        print(f"ğŸ”„ å­—æ®µ '{field}' æ›´æ–°: {old_value} â†’ {selected_value}")
                        break
                    else:
                        print("âŒ ç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°é€‰æ‹©")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        print(f"\nâœ… å†²çªè§£å†³å®Œæˆï¼")
        print(f"ğŸ“„ æœ€ç»ˆè®°å½•: {dict(result_record)}")
        return pd.DataFrame([result_record])
    
    def _create_separate_records(self, group_df: pd.DataFrame, conflicts: Dict, dedup_fields: List[str]) -> pd.DataFrame:
        """ä¸ºä¸åŒå€¼åˆ›å»ºå•ç‹¬è®°å½•"""
        # æ‰¾åˆ°æœ€å¤šå€¼çš„å­—æ®µä½œä¸ºä¸»å­—æ®µ
        main_field = max(conflicts.keys(), key=lambda f: len(conflicts[f]))
        main_values = conflicts[main_field]
        
        print(f"ğŸ“ ä»¥å­—æ®µ '{main_field}' ä¸ºä¸»å­—æ®µåˆ›å»º {len(main_values)} æ¡è®°å½•")
        
        result_records = []
        base_record = group_df.iloc[0].copy()
        
        for i, main_value in enumerate(main_values):
            new_record = base_record.copy()
            new_record[main_field] = main_value
            
            # ä¸ºå…¶ä»–å†²çªå­—æ®µé€‰æ‹©å¯¹åº”çš„å€¼
            for field in conflicts:
                if field != main_field:
                    # æ‰¾åˆ°ä¸main_valueå¯¹åº”çš„è®°å½•ä¸­è¯¥å­—æ®µçš„å€¼
                    matching_records = group_df[group_df[main_field] == main_value]
                    if not matching_records.empty:
                        new_record[field] = matching_records.iloc[0][field]
                    # å¦‚æœæ²¡æœ‰å®Œå…¨åŒ¹é…çš„è®°å½•ï¼Œä¿æŒåŸå€¼
            
            result_records.append(new_record)
            print(f"  ğŸ“„ è®°å½• {i+1}: {main_field}={main_value}")
        
        return pd.DataFrame(result_records)

    def backup_files(self, files: List[str]) -> bool:
        """
        å¤‡ä»½é€‰ä¸­çš„Excelæ–‡ä»¶
        
        Args:
            files: è¦å¤‡ä»½çš„æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            å¤‡ä»½æ˜¯å¦æˆåŠŸ
        """
        print(f"\n=== æ–‡ä»¶å¤‡ä»½ ===")
        
        # è¯¢é—®æ˜¯å¦è¦å¤‡ä»½
        backup_choice = input("ğŸ¤” æ˜¯å¦è¦å¤‡ä»½é€‰ä¸­çš„Excelæ–‡ä»¶ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        if backup_choice in ['n', 'no', 'å¦']:
            print("âœ… è·³è¿‡å¤‡ä»½ï¼Œç›´æ¥å¤„ç†æ–‡ä»¶")
            return True
        
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = f"backup_{timestamp}"
        
        try:
            if not os.path.exists(backup_dir):
                os.makedirs(backup_dir)
            
            print(f"ğŸ“ åˆ›å»ºå¤‡ä»½ç›®å½•: {backup_dir}")
            
            # å¤‡ä»½æ¯ä¸ªæ–‡ä»¶
            backup_success = 0
            backup_failed = 0
            
            for file_path in files:
                try:
                    filename = os.path.basename(file_path)
                    backup_path = os.path.join(backup_dir, filename)
                    
                    # å¦‚æœå¤‡ä»½ç›®å½•ä¸­å·²æœ‰åŒåæ–‡ä»¶ï¼Œæ·»åŠ åºå·
                    counter = 1
                    original_backup_path = backup_path
                    while os.path.exists(backup_path):
                        name, ext = os.path.splitext(original_backup_path)
                        backup_path = f"{name}_{counter}{ext}"
                        counter += 1
                    
                    # å¤åˆ¶æ–‡ä»¶
                    import shutil
                    shutil.copy2(file_path, backup_path)
                    print(f"âœ… å·²å¤‡ä»½: {filename} -> {os.path.basename(backup_path)}")
                    backup_success += 1
                    
                except Exception as e:
                    print(f"âŒ å¤‡ä»½å¤±è´¥: {os.path.basename(file_path)} - {str(e)}")
                    backup_failed += 1
            
            print(f"\nğŸ“Š å¤‡ä»½ç»“æœ:")
            print(f"  âœ… æˆåŠŸå¤‡ä»½: {backup_success} ä¸ªæ–‡ä»¶")
            if backup_failed > 0:
                print(f"  âŒ å¤‡ä»½å¤±è´¥: {backup_failed} ä¸ªæ–‡ä»¶")
            print(f"  ğŸ“ å¤‡ä»½ä½ç½®: {os.path.abspath(backup_dir)}")
            
            if backup_failed > 0:
                continue_choice = input("\nâš ï¸  éƒ¨åˆ†æ–‡ä»¶å¤‡ä»½å¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­å¤„ç†ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
                if continue_choice in ['n', 'no', 'å¦']:
                    print("âŒ ç”¨æˆ·é€‰æ‹©é€€å‡º")
                    return False
            
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºå¤‡ä»½ç›®å½•å¤±è´¥: {str(e)}")
            continue_choice = input("âš ï¸  å¤‡ä»½å¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­å¤„ç†ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            return continue_choice in ['y', 'yes', 'æ˜¯']

    def _manual_select_column(self, required_field: str, available_columns: List[str]) -> str:
        """æ‰‹åŠ¨é€‰æ‹©åˆ—å"""
        if not available_columns:
            print(f"  âš ï¸  æ²¡æœ‰å¯ç”¨çš„åˆ—åå¯é€‰æ‹©")
            return None
        
        print(f"\n  ğŸ“‹ å¯ç”¨çš„åˆ—å:")
        for i, column in enumerate(available_columns, 1):
            print(f"    {i:2d}. {column}")
        
        print(f"\n  ğŸ“ è¯·é€‰æ‹©è¦æ˜ å°„åˆ°å­—æ®µ '{required_field}' çš„åˆ—å:")
        while True:
            try:
                choice = input("  è¯·è¾“å…¥åˆ—åç¼–å·: ").strip()
                choice_idx = int(choice) - 1
                if 0 <= choice_idx < len(available_columns):
                    selected_column = available_columns[choice_idx]
                    print(f"  âœ… é€‰æ‹©äº†åˆ—å: {selected_column}")
                    return selected_column
                else:
                    print("  âŒ ç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°é€‰æ‹©")
            except ValueError:
                print("  âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")

def main():
    """ä¸»å‡½æ•°"""
    processor = ExcelProcessor()
    processor.run()

if __name__ == "__main__":
    main()