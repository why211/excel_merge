import pandas as pd
import os
import glob
import re
from typing import List, Tuple, Dict, Optional

class ExcelProcessor:
    """Excelæ–‡ä»¶å¤„ç†å·¥å…·"""
    
    def __init__(self):
        self.selected_files = []
        self.all_fields = []
        self.selected_fields = []
        self.deduplicate = False
        self.dedup_fields = []
        self.output_filename = "result.xlsx"
        
        # å­¦ç”Ÿå§“åè¡¥å……åŠŸèƒ½ç›¸å…³å±æ€§ï¼ˆæ—§ç‰ˆæœ¬ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
        self.enable_name_supplement = False
        self.student_name_mapping = {}  # å­¦å·åˆ°å­¦ç”Ÿå§“åçš„æ˜ å°„
        self.default_student_name = "æœªçŸ¥å­¦ç”Ÿ"
        self.supplement_stats = {
            'total_supplemented': 0,
            'successful_matches': 0,
            'default_value_used': 0
        }
        
        # å­—æ®µè¡¥å……åŠŸèƒ½ç›¸å…³å±æ€§ï¼ˆæ–°ç‰ˆæœ¬ï¼‰
        self.enable_field_supplement = False
        self.field_mappings = {}  # å­—æ®µæ˜ å°„å­—å…¸ {field_name: {link_value: target_value}}
        self.field_default_values = {}  # å­—æ®µé»˜è®¤å€¼å­—å…¸ {field_name: default_value}
        self.link_field = 'å­¦å·'  # å…³è”å­—æ®µï¼Œé»˜è®¤ä¸ºå­¦å·

        # åŒæ­¥æ¨¡å¼ç›¸å…³å±æ€§
        self.operation_mode = "merge"  # "merge" or "sync"
        self.source_file = ""  # æºæ–‡ä»¶è·¯å¾„å˜é‡
        self.target_file = ""  # ç›®æ ‡æ–‡ä»¶è·¯å¾„å˜é‡
        self.link_field = ""  # å…³è”å­—æ®µå˜é‡
        self.update_fields = []  # æ›´æ–°å­—æ®µåˆ—è¡¨å˜é‡
        self.output_directory = ""  # è¾“å‡ºç›®å½•å˜é‡
        self.unmatched_handling = "empty"  # æœªåŒ¹é…è®°å½•å¤„ç†æ–¹å¼: "empty" æˆ– "default"
        self.default_values = {}  # é»˜è®¤å€¼å­—å…¸
        self.sync_stats = {
            'source_records': 0,
            'target_records': 0,
            'updated_records': 0,
            'failed_records': 0,
            'sync_success_rate': 0.0
        }
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦
        
        Args:
            str1: å­—ç¬¦ä¸²1
            str2: å­—ç¬¦ä¸²2
            
        Returns:
            ç›¸ä¼¼åº¦ (0-1)
        """
        from difflib import SequenceMatcher
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def select_files(self, folder_path: str = ".") -> List[str]:
        """
        æ–‡ä»¶é€‰æ‹©åŠŸèƒ½
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•
            
        Returns:
            é€‰ä¸­çš„æ–‡ä»¶åˆ—è¡¨
        """
        print(f"\n=== æ­¥éª¤1: æ–‡ä»¶é€‰æ‹© ===")
        print(f"æ­£åœ¨æ‰«ææ–‡ä»¶å¤¹: {folder_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰Excelæ–‡ä»¶
        excel_patterns = ['*.xlsx', '*.xls']
        excel_files = []
        
        for pattern in excel_patterns:
            excel_files.extend(glob.glob(os.path.join(folder_path, pattern)))
        
        if not excel_files:
            print(f"âŒ åœ¨æ–‡ä»¶å¤¹ '{folder_path}' ä¸­æ²¡æœ‰æ‰¾åˆ°Excelæ–‡ä»¶")
            return []
        
        # æ˜¾ç¤ºæ‰¾åˆ°çš„æ–‡ä»¶
        print(f"\nâœ… æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶:")
        for i, file in enumerate(excel_files, 1):
            filename = os.path.basename(file)
            file_size = os.path.getsize(file) / 1024  # KB
            print(f"{i:2d}. {filename:<30} ({file_size:.1f} KB)")
        
        # ç”¨æˆ·é€‰æ‹©æ–‡ä»¶
        print(f"\nè¯·é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶:")
        print("ï¿½ï¿½ è¾“å…¥æ–‡ä»¶ç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2,3ï¼‰")
        print("ï¿½ï¿½ è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰æ–‡ä»¶")
        print("ğŸ“ è¾“å…¥ 'q' é€€å‡ºç¨‹åº")
        
        try:
            choice = input("\nè¯·é€‰æ‹©: ").strip().lower()
            
            if choice == 'q':
                print("ç¨‹åºé€€å‡º")
                return []
            elif choice == 'all':
                self.selected_files = excel_files
                print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(excel_files)} ä¸ªæ–‡ä»¶")
            else:
                # è§£æç”¨æˆ·é€‰æ‹©çš„æ–‡ä»¶ç¼–å·
                indices = [int(x.strip()) - 1 for x in choice.split(',')]
                self.selected_files = [excel_files[i] for i in indices if 0 <= i < len(excel_files)]
                
                if not self.selected_files:
                    print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆæ–‡ä»¶ï¼Œè¯·é‡æ–°é€‰æ‹©")
                    return self.select_files(folder_path)
                
                print(f"âœ… å·²é€‰æ‹© {len(self.selected_files)} ä¸ªæ–‡ä»¶:")
                for file in self.selected_files:
                    print(f"  ğŸ“„ {os.path.basename(file)}")
                
            return self.selected_files
            
        except (ValueError, IndexError) as e:
            print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {str(e)}ï¼Œè¯·é‡æ–°é€‰æ‹©")
            return self.select_files(folder_path)
    
    def get_field_list(self, files: List[str]) -> List[str]:
        """
        è·å–æ‰€æœ‰æ–‡ä»¶çš„å­—æ®µåˆ—è¡¨
        
        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            æ‰€æœ‰å­—æ®µçš„åˆ—è¡¨
        """
        print(f"\n=== æ­¥éª¤2: å­—æ®µåˆ†æ ===")
        all_fields = set()
        file_field_info = {}
        
        for file in files:
            try:
                df = pd.read_excel(file)
                file_fields = list(df.columns)
                all_fields.update(file_fields)
                file_field_info[os.path.basename(file)] = {
                    'field_count': len(file_fields),
                    'fields': file_fields
                }
                print(f"ğŸ“Š æ–‡ä»¶ '{os.path.basename(file)}' åŒ…å« {len(file_fields)} ä¸ªå­—æ®µ")
                
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
        
        # è®¡ç®—æ¯ä¸ªå­—æ®µçš„å‡ºç°æ¬¡æ•°å¹¶æ’åº
        field_occurrence = {}
        for field in all_fields:
            files_with_field = [f for f, info in file_field_info.items() if field in info['fields']]
            field_occurrence[field] = len(files_with_field)
        
        # æŒ‰å‡ºç°æ¬¡æ•°ä»é«˜åˆ°ä½æ’åº
        sorted_fields = sorted(field_occurrence.items(), key=lambda x: x[1], reverse=True)
        self.all_fields = [field for field, count in sorted_fields]
        
        print(f"\nâœ… æ€»å…±å‘ç° {len(self.all_fields)} ä¸ªä¸åŒå­—æ®µ")
        
        return self.all_fields
    
    def analyze_student_name_situation(self, files: List[str]) -> Dict:
        """
        åˆ†æå­¦ç”Ÿå§“åè¡¥å……æƒ…å†µ
        
        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        analysis_result = {
            'files_with_both': [],  # åŒæ—¶åŒ…å«å­¦å·å’Œå§“åçš„æ–‡ä»¶
            'files_missing_name': [],  # åŒ…å«å­¦å·ä½†ç¼ºå°‘å§“åçš„æ–‡ä»¶
            'files_without_student_id': [],  # ä¸åŒ…å«å­¦å·çš„æ–‡ä»¶
            'total_files': len(files)
        }
        
        print(f"\nğŸ” åˆ†æå­¦ç”Ÿå§“åè¡¥å……æƒ…å†µ...")
        
        for file in files:
            try:
                df = pd.read_excel(file)
                file_fields = list(df.columns)
                filename = os.path.basename(file)
                
                # æ”¯æŒå¤šç§å­¦å·å­—æ®µåç§°
                has_student_id = any(id_field in file_fields for id_field in ['å­¦å·', '*å­¦å·'])
                # æ”¯æŒå¤šç§å­¦ç”Ÿå§“åå­—æ®µåç§°
                has_student_name = any(name in file_fields for name in ['å­¦ç”Ÿå§“å', '*å­¦ç”Ÿå§“å'])
                
                if has_student_id and has_student_name:
                    analysis_result['files_with_both'].append(file)
                    print(f"âœ… {filename}: åŒ…å«å­¦å·å’Œå§“å")
                elif has_student_id and not has_student_name:
                    analysis_result['files_missing_name'].append(file)
                    print(f"âš ï¸  {filename}: åŒ…å«å­¦å·ä½†ç¼ºå°‘å§“å")
                else:
                    analysis_result['files_without_student_id'].append(file)
                    print(f"â„¹ï¸  {filename}: ä¸åŒ…å«å­¦å·")
                    
            except Exception as e:
                print(f"âŒ åˆ†ææ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
                analysis_result['files_without_student_id'].append(file)
        
        return analysis_result
    
    def build_student_name_mapping(self, files_with_both: List[str]) -> Dict[str, str]:
        """
        æ„å»ºå­¦å·åˆ°å­¦ç”Ÿå§“åçš„æ˜ å°„
        
        Args:
            files_with_both: åŒæ—¶åŒ…å«å­¦å·å’Œå§“åçš„æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            å­¦å·åˆ°å­¦ç”Ÿå§“åçš„æ˜ å°„å­—å…¸
        """
        if not files_with_both:
            return {}
        
        print(f"\nğŸ”„ æ„å»ºå­¦å·åˆ°å­¦ç”Ÿå§“åçš„æ˜ å°„...")
        mapping = {}
        total_mappings = 0
        
        for file in files_with_both:
            try:
                df = pd.read_excel(file)
                filename = os.path.basename(file)
                
                # ç¡®å®šå­¦å·å­—æ®µåç§°
                student_id_field = None
                for id_field in ['å­¦å·', '*å­¦å·']:
                    if id_field in df.columns:
                        student_id_field = id_field
                        break
                
                if not student_id_field:
                    print(f"âš ï¸  æ–‡ä»¶ '{filename}' ç¼ºå°‘å­¦å·å­—æ®µï¼Œè·³è¿‡")
                    continue
                
                # ç¡®å®šå­¦ç”Ÿå§“åå­—æ®µåç§°
                student_name_field = None
                for name_field in ['å­¦ç”Ÿå§“å', '*å­¦ç”Ÿå§“å']:
                    if name_field in df.columns:
                        student_name_field = name_field
                        break
                
                if not student_name_field:
                    print(f"âš ï¸  æ–‡ä»¶ '{filename}' ç¼ºå°‘å­¦ç”Ÿå§“åå­—æ®µï¼Œè·³è¿‡")
                    continue
                
                # æ„å»ºæ˜ å°„å…³ç³»
                file_mappings = 0
                for _, row in df.iterrows():
                    student_id = str(row[student_id_field]).strip()
                    student_name = str(row[student_name_field]).strip()
                    
                    # è·³è¿‡ç©ºå€¼
                    if pd.isna(student_id) or pd.isna(student_name) or student_id == '' or student_name == '':
                        continue
                    
                    # å¦‚æœå­¦å·å·²å­˜åœ¨ï¼Œä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…çš„å§“å
                    if student_id not in mapping:
                        mapping[student_id] = student_name
                        file_mappings += 1
                
                total_mappings += file_mappings
                print(f"ğŸ“Š {filename}: æ·»åŠ äº† {file_mappings} ä¸ªæ˜ å°„å…³ç³»")
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
                continue
        
        print(f"âœ… æ€»å…±æ„å»ºäº† {total_mappings} ä¸ªå­¦å·-å§“åæ˜ å°„å…³ç³»")
        return mapping
    
    def configure_name_supplement(self, analysis_result: Dict) -> Tuple[bool, str]:
        """
        é…ç½®å­¦ç”Ÿå§“åè¡¥å……åŠŸèƒ½
        
        Args:
            analysis_result: åˆ†æç»“æœ
            
        Returns:
            (æ˜¯å¦å¯ç”¨è¡¥å……åŠŸèƒ½, é»˜è®¤å­¦ç”Ÿå§“å)
        """
        files_missing_name = analysis_result['files_missing_name']
        files_with_both = analysis_result['files_with_both']
        
        if not files_missing_name:
            print(f"\nâœ… æ‰€æœ‰æ–‡ä»¶éƒ½åŒ…å«å­¦ç”Ÿå§“åå­—æ®µï¼Œæ— éœ€è¡¥å……")
            return False, ""
        
        if not files_with_both:
            print(f"\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°åŒ…å«å­¦å·å’Œå§“åçš„æ–‡ä»¶ï¼Œæ— æ³•æ„å»ºæ˜ å°„å…³ç³»")
            print(f"ğŸ“ å»ºè®®ï¼šè‡³å°‘éœ€è¦ä¸€ä¸ªåŒ…å«å­¦å·å’Œå§“åçš„æ–‡ä»¶æ¥æ„å»ºæ˜ å°„å…³ç³»")
            return False, ""
        
        print(f"\n=== å­¦ç”Ÿå§“åè¡¥å……é…ç½® ===")
        print(f"ğŸ“Š åˆ†æç»“æœ:")
        print(f"  â€¢ åŒ…å«å­¦å·å’Œå§“åçš„æ–‡ä»¶: {len(files_with_both)} ä¸ª")
        print(f"  â€¢ ç¼ºå°‘å­¦ç”Ÿå§“åçš„æ–‡ä»¶: {len(files_missing_name)} ä¸ª")
        print(f"  â€¢ ä¸åŒ…å«å­¦å·çš„æ–‡ä»¶: {len(analysis_result['files_without_student_id'])} ä¸ª")
        
        print(f"\nğŸ¤” æ£€æµ‹åˆ°éƒ¨åˆ†æ–‡ä»¶ç¼ºå°‘å­¦ç”Ÿå§“åå­—æ®µï¼Œæ˜¯å¦å¯ç”¨å­¦ç”Ÿå§“åè¡¥å……åŠŸèƒ½ï¼Ÿ")
        print(f"ğŸ“ è¡¥å……åŠŸèƒ½å°†ä»å…¶ä»–æ–‡ä»¶ä¸­æ ¹æ®å­¦å·åŒ¹é…è·å–å­¦ç”Ÿå§“å")
        
        choice = input("è¯·é€‰æ‹© (y/nï¼Œé»˜è®¤y): ").strip().lower()
        enable_supplement = choice not in ['n', 'no', 'å¦']
        
        if not enable_supplement:
            print(f"âœ… å·²é€‰æ‹©ä¸å¯ç”¨å­¦ç”Ÿå§“åè¡¥å……åŠŸèƒ½")
            return False, ""
        
        # è®¾ç½®é»˜è®¤å­¦ç”Ÿå§“å
        print(f"\nğŸ“ è¯·è¾“å…¥æœªæ‰¾åˆ°åŒ¹é…å­¦ç”Ÿå§“åæ—¶ä½¿ç”¨çš„é»˜è®¤å€¼")
        default_name = input(f"é»˜è®¤å€¼ï¼ˆé»˜è®¤ï¼š{self.default_student_name}ï¼‰: ").strip()
        if not default_name:
            default_name = self.default_student_name
        
        print(f"âœ… å·²è®¾ç½®é»˜è®¤å­¦ç”Ÿå§“å: {default_name}")
        return True, default_name
    
    def supplement_student_names(self, df: pd.DataFrame, mapping: Dict[str, str], 
                               default_name: str) -> pd.DataFrame:
        """
        ä¸ºæ•°æ®æ¡†è¡¥å……å­¦ç”Ÿå§“å
        
        Args:
            df: æ•°æ®æ¡†
            mapping: å­¦å·åˆ°å­¦ç”Ÿå§“åçš„æ˜ å°„
            default_name: é»˜è®¤å­¦ç”Ÿå§“å
            
        Returns:
            è¡¥å……åçš„æ•°æ®æ¡†
        """
        # ç¡®å®šå­¦å·å­—æ®µåç§°
        student_id_field = None
        for id_field in ['å­¦å·', '*å­¦å·']:
            if id_field in df.columns:
                student_id_field = id_field
                break
        
        if not student_id_field:
            print(f"âš ï¸  æ•°æ®æ¡†ä¸åŒ…å«å­¦å·å­—æ®µï¼Œæ— æ³•è¡¥å……å­¦ç”Ÿå§“å")
            return df
        
        # ç¡®å®šå­¦ç”Ÿå§“åå­—æ®µåç§°
        student_name_field = None
        for name_field in ['å­¦ç”Ÿå§“å', '*å­¦ç”Ÿå§“å']:
            if name_field in df.columns:
                student_name_field = name_field
                break
        
        # å¦‚æœå·²ç»æœ‰å­¦ç”Ÿå§“åå­—æ®µï¼Œå…ˆæ£€æŸ¥æ˜¯å¦éœ€è¦è¡¥å……
        if student_name_field:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºçš„å­¦ç”Ÿå§“å
            missing_names = df[student_name_field].isna() | (df[student_name_field].astype(str).str.strip() == '')
            if not missing_names.any():
                print(f"âœ… å­¦ç”Ÿå§“åå­—æ®µå·²å®Œæ•´ï¼Œæ— éœ€è¡¥å……")
                return df
        
        # åˆ›å»ºå­¦ç”Ÿå§“åå­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if not student_name_field:
            student_name_field = 'å­¦ç”Ÿå§“å'  # é»˜è®¤ä½¿ç”¨æ ‡å‡†åç§°
            df[student_name_field] = default_name
            print(f"ğŸ“ åˆ›å»ºå­¦ç”Ÿå§“åå­—æ®µ")
        
        # è¡¥å……å­¦ç”Ÿå§“å
        supplemented_count = 0
        successful_matches = 0
        default_used = 0
        
        # è¿‡æ»¤æ‰å­¦å·ä¸ºç©ºçš„è®°å½•
        before_filter = len(df)
        df = df.dropna(subset=[student_id_field])
        after_filter = len(df)
        if before_filter > after_filter:
            print(f"âš ï¸  è¿‡æ»¤æ‰ {before_filter - after_filter} æ¡å­¦å·ä¸ºç©ºçš„è®°å½•")
        
        for idx, row in df.iterrows():
            student_id = str(row[student_id_field]).strip()
            
            # è·³è¿‡ç©ºå­¦å·ï¼ˆåŒé‡æ£€æŸ¥ï¼‰
            if pd.isna(student_id) or student_id == '':
                continue
            
            # æ£€æŸ¥å½“å‰å­¦ç”Ÿå§“åæ˜¯å¦ä¸ºç©º
            current_name = str(row[student_name_field]).strip()
            if pd.isna(current_name) or current_name == '' or current_name == default_name:
                # å°è¯•ä»æ˜ å°„ä¸­è·å–å­¦ç”Ÿå§“åï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
                if student_id in mapping:
                    df.at[idx, student_name_field] = mapping[student_id]
                    successful_matches += 1
                else:
                    # å°è¯•æ­£åˆ™åŒ¹é…ï¼ˆæ”¯æŒä¸€ä½å­—ç¬¦çš„æ¨¡ç³ŠåŒ¹é…ï¼‰
                    matched_name = None
                    for map_id, map_name in mapping.items():
                        # å¦‚æœå­¦å·é•¿åº¦ç›¸åŒï¼Œå°è¯•ä¸€ä½å­—ç¬¦çš„æ¨¡ç³ŠåŒ¹é…
                        if len(student_id) == len(map_id):
                            # è®¡ç®—ä¸åŒå­—ç¬¦çš„æ•°é‡
                            diff_count = sum(1 for a, b in zip(student_id, map_id) if a != b)
                            if diff_count <= 1:  # å…è®¸ä¸€ä½å­—ç¬¦çš„å·®å¼‚
                                matched_name = map_name
                                break
                    
                    if matched_name:
                        df.at[idx, student_name_field] = matched_name
                        successful_matches += 1
                    else:
                        df.at[idx, student_name_field] = default_name
                        default_used += 1
                    supplemented_count += 1
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.supplement_stats['total_supplemented'] += supplemented_count
        self.supplement_stats['successful_matches'] += successful_matches
        self.supplement_stats['default_value_used'] += default_used
        
        if supplemented_count > 0:
            print(f"ğŸ“Š è¡¥å……ç»Ÿè®¡: æˆåŠŸåŒ¹é… {successful_matches} ä¸ªï¼Œä½¿ç”¨é»˜è®¤å€¼ {default_used} ä¸ª")
        
        return df
    
    def get_file_fields(self, file_path: str) -> List[str]:
        """
        è·å–å•ä¸ªæ–‡ä»¶çš„å­—æ®µåˆ—è¡¨
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            å­—æ®µåˆ—è¡¨
        """
        try:
            df = pd.read_excel(file_path)
            return list(df.columns)
        except Exception as e:
            return []
    
    def select_fields(self, all_fields: List[str]) -> List[str]:
        """
        å­—æ®µé€‰æ‹©åŠŸèƒ½
        
        Args:
            all_fields: æ‰€æœ‰å¯ç”¨å­—æ®µåˆ—è¡¨
            
        Returns:
            é€‰ä¸­çš„å­—æ®µåˆ—è¡¨
        """
        print(f"\n=== æ­¥éª¤3: å­—æ®µé€‰æ‹© ===")
        print("ğŸ“‹ å¯ç”¨å­—æ®µåˆ—è¡¨ï¼ˆæŒ‰å‡ºç°æ¬¡æ•°æ’åºï¼‰:")
        
        # åˆ†é¡µæ˜¾ç¤ºå­—æ®µ
        page_size = 10
        total_pages = (len(all_fields) + page_size - 1) // page_size
        
        for page in range(total_pages):
            start_idx = page * page_size
            end_idx = min(start_idx + page_size, len(all_fields))
            
            print(f"\n--- ç¬¬ {page + 1}/{total_pages} é¡µ ---")
            for i in range(start_idx, end_idx):
                field = all_fields[i]
                # è®¡ç®—è¯¥å­—æ®µçš„å‡ºç°æ¬¡æ•°
                occurrence_count = sum(1 for f in self.selected_files if field in self.get_file_fields(f))
                print(f"{i + 1:2d}. {field:<25} (å‡ºç°åœ¨ {occurrence_count} ä¸ªæ–‡ä»¶ä¸­)")
        
        print(f"\nè¯·é€‰æ‹©è¦å¯¼å…¥çš„å­—æ®µ:")
        print("ï¿½ï¿½ è¾“å…¥å­—æ®µç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2,3ï¼‰")
        print("ï¿½ï¿½ è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰å­—æ®µ")
        print("ï¿½ï¿½ è¾“å…¥ 'page 1' æŸ¥çœ‹ç¬¬1é¡µï¼ˆå¯æ›¿æ¢é¡µç ï¼‰")
        
        try:
            choice = input("\nè¯·é€‰æ‹©: ").strip().lower()
            
            if choice.startswith('page '):
                try:
                    page_num = int(choice.split()[1]) - 1
                    if 0 <= page_num < total_pages:
                        print(f"\n--- ç¬¬ {page_num + 1}/{total_pages} é¡µ ---")
                        start_idx = page_num * page_size
                        end_idx = min(start_idx + page_size, len(all_fields))
                        for i in range(start_idx, end_idx):
                            field = all_fields[i]
                            print(f"{i + 1:2d}. {field}")
                        return self.select_fields(all_fields)
                    else:
                        print("âŒ é¡µç è¶…å‡ºèŒƒå›´")
                        return self.select_fields(all_fields)
                except:
                    print("âŒ é¡µç æ ¼å¼é”™è¯¯")
                    return self.select_fields(all_fields)
            
            elif choice == 'all':
                self.selected_fields = all_fields
                print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(all_fields)} ä¸ªå­—æ®µ")
            else:
                # è§£æç”¨æˆ·é€‰æ‹©çš„å­—æ®µç¼–å·
                indices = [int(x.strip()) - 1 for x in choice.split(',')]
                self.selected_fields = [all_fields[i] for i in indices if 0 <= i < len(all_fields)]
                
                if not self.selected_fields:
                    print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè¯·é‡æ–°é€‰æ‹©")
                    return self.select_fields(all_fields)
                
                print(f"âœ… å·²é€‰æ‹© {len(self.selected_fields)} ä¸ªå­—æ®µ:")
                for field in self.selected_fields:
                    print(f"  ğŸ“‹ {field}")
                
            return self.selected_fields
            
        except (ValueError, IndexError) as e:
            print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {str(e)}ï¼Œè¯·é‡æ–°é€‰æ‹©")
            return self.select_fields(all_fields)
    
    def configure_deduplication(self) -> Tuple[bool, List[str]]:
        """
        å»é‡é…ç½®ï¼šè¿”å›(æ˜¯å¦å»é‡, å»é‡å­—æ®µåˆ—è¡¨)
        
        Returns:
            (æ˜¯å¦å»é‡, å»é‡å­—æ®µåˆ—è¡¨)
        """
        print(f"\n=== æ­¥éª¤4: å»é‡é…ç½® ===")
        
        # è¯¢é—®æ˜¯å¦éœ€è¦å»é‡
        print("ğŸ¤” æ˜¯å¦éœ€è¦å»é‡ï¼Ÿ")
        print("ğŸ“ å»é‡å°†åˆ é™¤é‡å¤çš„è®°å½•ï¼Œä¿ç•™ç¬¬ä¸€æ¡")
        dedup_choice = input("è¯·é€‰æ‹© (y/nï¼Œé»˜è®¤n): ").strip().lower()
        self.deduplicate = dedup_choice in ['y', 'yes', 'æ˜¯']
        
        if not self.deduplicate:
            print("âœ… å·²é€‰æ‹©ä¸å»é‡ï¼Œå°†ä¿ç•™æ‰€æœ‰è®°å½•")
            return False, []
        
        # å¦‚æœå»é‡ï¼Œé€‰æ‹©å»é‡å­—æ®µ
        print(f"\nğŸ“‹ è¯·é€‰æ‹©å»é‡å­—æ®µï¼ˆåŸºäºè¿™äº›å­—æ®µçš„ç»„åˆæ¥åˆ¤æ–­é‡å¤ï¼‰:")
        print("å¯ç”¨å­—æ®µåˆ—è¡¨:")
        for i, field in enumerate(self.selected_fields, 1):
            # è®¡ç®—è¯¥å­—æ®µçš„å‡ºç°æ¬¡æ•°
            occurrence_count = sum(1 for f in self.selected_files if field in self.get_file_fields(f))
            print(f"{i:2d}. {field:<25} (å‡ºç°åœ¨ {occurrence_count} ä¸ªæ–‡ä»¶ä¸­)")
        
        print(f"\nï¿½ï¿½ è¾“å…¥å­—æ®µç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2ï¼‰")
        print(f"ğŸ“ è¾“å…¥ 'all' ä½¿ç”¨æ‰€æœ‰é€‰ä¸­å­—æ®µè¿›è¡Œå»é‡")
        print(f"ï¿½ï¿½ è¾“å…¥ 'single 1' åªä½¿ç”¨ç¬¬1ä¸ªå­—æ®µå»é‡")
        
        try:
            choice = input("\nè¯·é€‰æ‹©å»é‡å­—æ®µ: ").strip().lower()
            
            if choice == 'all':
                self.dedup_fields = self.selected_fields.copy()
                print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(self.dedup_fields)} ä¸ªå­—æ®µè¿›è¡Œå»é‡")
            elif choice.startswith('single '):
                try:
                    field_idx = int(choice.split()[1]) - 1
                    if 0 <= field_idx < len(self.selected_fields):
                        self.dedup_fields = [self.selected_fields[field_idx]]
                        print(f"âœ… å·²é€‰æ‹©å•ä¸ªå­—æ®µè¿›è¡Œå»é‡: {self.dedup_fields[0]}")
                    else:
                        print("âŒ å­—æ®µç¼–å·è¶…å‡ºèŒƒå›´")
                        return self.configure_deduplication()
                except:
                    print("âŒ å­—æ®µç¼–å·æ ¼å¼é”™è¯¯")
                    return self.configure_deduplication()
            else:
                # è§£æç”¨æˆ·é€‰æ‹©çš„å­—æ®µç¼–å·
                indices = [int(x.strip()) - 1 for x in choice.split(',')]
                self.dedup_fields = [self.selected_fields[i] for i in indices if 0 <= i < len(self.selected_fields)]
                
                if not self.dedup_fields:
                    print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè¯·é‡æ–°é€‰æ‹©")
                    return self.configure_deduplication()
                
                print(f"âœ… å·²é€‰æ‹© {len(self.dedup_fields)} ä¸ªå­—æ®µè¿›è¡Œå»é‡:")
                for field in self.dedup_fields:
                    print(f"  ğŸ” {field}")
                
            return True, self.dedup_fields
            
        except (ValueError, IndexError) as e:
            print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {str(e)}ï¼Œè¯·é‡æ–°é€‰æ‹©")
            return self.configure_deduplication()
    
    def process_data(self, files: List[str], selected_fields: List[str], 
                    deduplicate: bool, dedup_fields: List[str]) -> pd.DataFrame:
        """
        æ•°æ®å¤„ç†ä¸»å‡½æ•°
        
        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            selected_fields: é€‰ä¸­çš„å­—æ®µ
            deduplicate: æ˜¯å¦å»é‡
            dedup_fields: å»é‡å­—æ®µåˆ—è¡¨
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ¡†
        """
        print(f"\n=== æ­¥éª¤5: æ•°æ®å¤„ç† ===")
        all_data = []
        total_rows = 0
        
        print("ğŸ”„ å¼€å§‹å¤„ç†æ–‡ä»¶...")
        
        for i, file in enumerate(files, 1):
            try:
                print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(files)}: {os.path.basename(file)}")
                df = pd.read_excel(file)
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åŒ…å«æ‰€æœ‰é€‰ä¸­å­—æ®µï¼Œæ”¯æŒå­¦å·å’Œå­¦ç”Ÿå§“åå­—æ®µçš„å˜ä½“
                missing_fields = []
                for field in selected_fields:
                    if field not in df.columns:
                        # å¦‚æœæ˜¯å­¦å·å­—æ®µï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å˜ä½“
                        if field == 'å­¦å·' and '*å­¦å·' in df.columns:
                            continue  # æœ‰*å­¦å·å˜ä½“ï¼Œä¸ç®—ç¼ºå¤±
                        elif field == '*å­¦å·' and 'å­¦å·' in df.columns:
                            continue  # æœ‰å­¦å·å˜ä½“ï¼Œä¸ç®—ç¼ºå¤±
                        # å¦‚æœæ˜¯å­¦ç”Ÿå§“åå­—æ®µï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å˜ä½“
                        elif field == 'å­¦ç”Ÿå§“å' and '*å­¦ç”Ÿå§“å' in df.columns:
                            continue  # æœ‰*å­¦ç”Ÿå§“åå˜ä½“ï¼Œä¸ç®—ç¼ºå¤±
                        elif field == '*å­¦ç”Ÿå§“å' and 'å­¦ç”Ÿå§“å' in df.columns:
                            continue  # æœ‰å­¦ç”Ÿå§“åå˜ä½“ï¼Œä¸ç®—ç¼ºå¤±
                        missing_fields.append(field)
                
                if missing_fields:
                    print(f"âš ï¸  è­¦å‘Šï¼šæ–‡ä»¶ç¼ºå°‘å­—æ®µ {missing_fields}ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
                    continue
                
                # æå–é€‰ä¸­çš„å­—æ®µï¼Œå¤„ç†å­¦å·å’Œå­¦ç”Ÿå§“åå­—æ®µçš„å˜ä½“
                df_temp = df.copy()
                actual_fields = []
                
                for field in selected_fields:
                    if field in df.columns:
                        actual_fields.append(field)
                    elif field == 'å­¦å·' and '*å­¦å·' in df.columns:
                        # å°†*å­¦å·é‡å‘½åä¸ºå­¦å·
                        df_temp['å­¦å·'] = df_temp['*å­¦å·']
                        actual_fields.append('å­¦å·')
                    elif field == '*å­¦å·' and 'å­¦å·' in df.columns:
                        # å°†å­¦å·é‡å‘½åä¸º*å­¦å·
                        df_temp['*å­¦å·'] = df_temp['å­¦å·']
                        actual_fields.append('*å­¦å·')
                    elif field == 'å­¦ç”Ÿå§“å' and '*å­¦ç”Ÿå§“å' in df.columns:
                        # å°†*å­¦ç”Ÿå§“åé‡å‘½åä¸ºå­¦ç”Ÿå§“å
                        df_temp['å­¦ç”Ÿå§“å'] = df_temp['*å­¦ç”Ÿå§“å']
                        actual_fields.append('å­¦ç”Ÿå§“å')
                    elif field == '*å­¦ç”Ÿå§“å' and 'å­¦ç”Ÿå§“å' in df.columns:
                        # å°†å­¦ç”Ÿå§“åé‡å‘½åä¸º*å­¦ç”Ÿå§“å
                        df_temp['*å­¦ç”Ÿå§“å'] = df_temp['å­¦ç”Ÿå§“å']
                        actual_fields.append('*å­¦ç”Ÿå§“å')
                    else:
                        actual_fields.append(field)
                
                selected_data = df_temp[actual_fields].copy()
                
                all_data.append(selected_data)
                file_rows = len(selected_data)
                total_rows += file_rows
                print(f"âœ… æˆåŠŸè¯»å– {file_rows} è¡Œæ•°æ®")
                
            except Exception as e:
                print(f"âŒ é”™è¯¯ï¼šå¤„ç†æ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
                continue
        
        if not all_data:
            print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ•°æ®")
            return pd.DataFrame()
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        print(f"\nğŸ”„ æ­£åœ¨åˆå¹¶æ•°æ®...")
        combined_df = pd.concat(all_data, ignore_index=True)
        print(f"âœ… åˆå¹¶å®Œæˆï¼Œæ€»è¡Œæ•°: {len(combined_df)}")
        
        # è¿‡æ»¤æ‰å­¦å·ä¸ºç©ºçš„è®°å½•
        student_id_fields = [col for col in combined_df.columns if 'å­¦å·' in col]
        if student_id_fields:
            before_filter = len(combined_df)
            combined_df = combined_df.dropna(subset=student_id_fields)
            after_filter = len(combined_df)
            if before_filter > after_filter:
                print(f"âš ï¸  è¿‡æ»¤æ‰ {before_filter - after_filter} æ¡å­¦å·ä¸ºç©ºçš„è®°å½•")
                print(f"âœ… è¿‡æ»¤åæ€»è¡Œæ•°: {len(combined_df)}")
        
        # å­—æ®µè¡¥å……å¤„ç†
        if self.enable_field_supplement and self.field_mappings:
            print(f"\nğŸ”„ æ­£åœ¨è¡¥å……ç¼ºå¤±å­—æ®µ...")
            combined_df = self.supplement_fields(
                combined_df, 
                self.field_mappings, 
                self.field_default_values, 
                self.link_field
            )
            
            # æ˜¾ç¤ºè¡¥å……ç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“Š å­—æ®µè¡¥å……å®Œæˆ")
            for field, mapping in self.field_mappings.items():
                if mapping:
                    print(f"  â€¢ å­—æ®µ '{field}': æ„å»ºäº† {len(mapping)} ä¸ªæ˜ å°„å…³ç³»")
        
        # å»é‡å¤„ç†
        if deduplicate and dedup_fields:
            print(f"\nğŸ”„ æ­£åœ¨æŒ‰å­—æ®µ {dedup_fields} å»é‡...")
            before_count = len(combined_df)
            combined_df = combined_df.drop_duplicates(subset=dedup_fields, keep='first')
            after_count = len(combined_df)
            removed_count = before_count - after_count
            
            print(f"âœ… å»é‡å®Œæˆ:")
            print(f"  ğŸ“Š å»é‡å‰è¡Œæ•°: {before_count}")
            print(f"  ğŸ“Š å»é‡åè¡Œæ•°: {after_count}")
            print(f"  ï¿½ï¿½ï¸  åˆ é™¤é‡å¤è®°å½•: {removed_count}")
            
            if removed_count > 0:
                print(f"  ğŸ“ˆ å»é‡ç‡: {removed_count/before_count*100:.1f}%")
        
        return combined_df
    
    def export_to_excel(self, df: pd.DataFrame, output_filename: str = None):
        """
        å¯¼å‡ºåˆ°Excel
        
        Args:
            df: æ•°æ®æ¡†
            output_filename: è¾“å‡ºæ–‡ä»¶å
        """
        if output_filename is None:
            output_filename = self.output_filename
        
        print(f"\n=== æ­¥éª¤6: å¯¼å‡ºç»“æœ ===")
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        output_path = output_filename
        if not os.path.dirname(output_path):
            output_path = os.path.join(".", output_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(output_path):
            print(f"âš ï¸  æ–‡ä»¶ '{output_filename}' å·²å­˜åœ¨")
            overwrite = input("æ˜¯å¦è¦†ç›–ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            if overwrite not in ['y', 'yes', 'æ˜¯']:
                # ç”Ÿæˆæ–°æ–‡ä»¶å
                base_name = os.path.splitext(output_filename)[0]
                extension = os.path.splitext(output_filename)[1]
                counter = 1
                while True:
                    new_filename = f"{base_name}_{counter}{extension}"
                    new_output_path = os.path.join(".", new_filename)
                    if not os.path.exists(new_output_path):
                        output_path = new_output_path
                        output_filename = new_filename
                        print(f"ğŸ“ ä½¿ç”¨æ–°æ–‡ä»¶å: {new_filename}")
                        break
                    counter += 1
            else:
                # å°è¯•åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶
                try:
                    os.remove(output_path)
                    print(f"âœ… å·²åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶: {output_filename}")
                except PermissionError:
                    print(f"âŒ æ— æ³•åˆ é™¤æ–‡ä»¶ '{output_filename}'ï¼Œæ–‡ä»¶å¯èƒ½è¢«å…¶ä»–ç¨‹åºå ç”¨")
                    print("è¯·å…³é—­Excelæˆ–å…¶ä»–å¯èƒ½æ‰“å¼€è¯¥æ–‡ä»¶çš„ç¨‹åºï¼Œç„¶åé‡è¯•")
                    return None
                except Exception as e:
                    print(f"âŒ åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                    return None
        
        try:
            # åˆ›å»ºExcelå†™å…¥å™¨ï¼Œæ”¯æŒå¤šä¸ªå·¥ä½œè¡¨
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # ä¸»æ•°æ®è¡¨
                df.to_excel(writer, sheet_name='åˆå¹¶æ•°æ®', index=False)
                
                # ç»Ÿè®¡ä¿¡æ¯è¡¨
                stats_items = [
                    'æ€»è®°å½•æ•°',
                    'å¤„ç†æ–‡ä»¶æ•°',
                    'é€‰æ‹©å­—æ®µæ•°',
                    'æ˜¯å¦å»é‡',
                    'å»é‡å­—æ®µæ•°',
                    'åˆ é™¤é‡å¤è®°å½•æ•°'
                ]
                stats_values = [
                    len(df),
                    len(self.selected_files),
                    len(self.selected_fields),
                    'æ˜¯' if self.deduplicate else 'å¦',
                    len(self.dedup_fields) if self.deduplicate else 0,
                    len(df) - len(df.drop_duplicates(subset=self.dedup_fields)) if self.deduplicate and self.dedup_fields else 0
                ]
                
                # æ·»åŠ å­—æ®µè¡¥å……ç»Ÿè®¡
                if self.enable_field_supplement:
                    stats_items.extend([
                        'æ˜¯å¦å¯ç”¨å­—æ®µè¡¥å……',
                        'å…³è”å­—æ®µ',
                        'è¡¥å……å­—æ®µæ•°',
                        'å­—æ®µè¡¥å……æˆåŠŸç‡'
                    ])
                    # è®¡ç®—è¡¥å……æˆåŠŸç‡ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ç»Ÿè®¡å…·ä½“çš„è¡¥å……æƒ…å†µï¼‰
                    stats_values.extend([
                        'æ˜¯',
                        self.link_field,
                        len(self.field_mappings),
                        '100.0%'  # ç®€åŒ–æ˜¾ç¤º
                    ])
                else:
                    stats_items.append('æ˜¯å¦å¯ç”¨å­—æ®µè¡¥å……')
                    stats_values.append('å¦')
                
                stats_items.append('å¤„ç†æ—¶é—´')
                stats_values.append(pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'))
                
                stats_data = {
                    'ç»Ÿè®¡é¡¹ç›®': stats_items,
                    'æ•°å€¼': stats_values
                }
                stats_df = pd.DataFrame(stats_data)
                stats_df.to_excel(writer, sheet_name='å¤„ç†ç»Ÿè®¡', index=False)
                
                # å­—æ®µä¿¡æ¯è¡¨
                field_info = {
                    'å­—æ®µåç§°': self.selected_fields,
                    'å­—æ®µç±»å‹': [str(df[field].dtype) for field in self.selected_fields],
                    'éç©ºå€¼æ•°é‡': [df[field].notna().sum() for field in self.selected_fields],
                    'ç©ºå€¼æ•°é‡': [df[field].isna().sum() for field in self.selected_fields]
                }
                field_df = pd.DataFrame(field_info)
                field_df.to_excel(writer, sheet_name='å­—æ®µä¿¡æ¯', index=False)
            
            print(f"âœ… æ•°æ®å·²æˆåŠŸå¯¼å‡ºåˆ°: {output_path}")
            print(f"ï¿½ï¿½ æ€»å…±å¯¼å‡º {len(df)} æ¡è®°å½•")
            print(f"ğŸ“‹ åŒ…å«å·¥ä½œè¡¨: åˆå¹¶æ•°æ®ã€å¤„ç†ç»Ÿè®¡ã€å­—æ®µä¿¡æ¯")
            
            return output_path
            
        except PermissionError:
            print(f"âŒ æƒé™é”™è¯¯ï¼šæ— æ³•ä¿å­˜åˆ° {output_path}")
            print("è¯·ç¡®ä¿æ–‡ä»¶æ²¡æœ‰è¢«å…¶ä»–ç¨‹åºï¼ˆå¦‚Excelï¼‰æ‰“å¼€")
            print("å»ºè®®ï¼š")
            print("1. å…³é—­å¯èƒ½æ‰“å¼€è¯¥æ–‡ä»¶çš„Excelç¨‹åº")
            print("2. ä½¿ç”¨ä¸åŒçš„æ–‡ä»¶å")
            print("3. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«è®¾ç½®ä¸ºåªè¯»")
            return None
        except Exception as e:
            print(f"âŒ å¯¼å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return None
    
    def set_output_filename(self):
        """è®¾ç½®è¾“å‡ºæ–‡ä»¶å"""
        print(f"\n=== æ­¥éª¤4.5: è¾“å‡ºè®¾ç½® ===")
        print(f"ğŸ“ å½“å‰è¾“å‡ºæ–‡ä»¶å: {self.output_filename}")
        filename = input("è¯·è¾“å…¥æ–°çš„è¾“å‡ºæ–‡ä»¶ååˆ—å¦‚G:\\wang\\excelï¼ˆé»˜è®¤æ ¼å¼ä¸ºxlsxï¼‰: ").strip()
        if filename:
            # ç¡®ä¿æ–‡ä»¶æ‰©å±•åæ­£ç¡®
            if not filename.endswith(('.xlsx', '.xls')):
                filename += '.xlsx'
            self.output_filename = filename
        print(f"âœ… è¾“å‡ºæ–‡ä»¶å: {self.output_filename}")
    

    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        print("=" * 60)
        print("ğŸ¯ Excelæ–‡ä»¶å¤„ç†å·¥å…· v2.4")
        print("ğŸ“‹ åŠŸèƒ½ï¼šå¤šæ–‡ä»¶æ•°æ®åˆå¹¶ã€å­—æ®µé€‰æ‹©ã€å»é‡å¤„ç†ã€å­¦ç”Ÿå§“åè¡¥å……ã€å•æºåŒæ­¥ã€å¤šæºåŒæ­¥")
        print("=" * 60)
        
        # é€‰æ‹©æ“ä½œæ¨¡å¼
        mode = self.select_operation_mode()
        
        if mode == "merge":
            self.run_merge_mode()
        elif mode == "sync":
            self.run_sync_mode()
        elif mode == "multi_sync":
            self.run_multi_sync_mode()
        else:
            print("ğŸ‘‹ ç¨‹åºé€€å‡º")
    
    def run_sync_only(self):
        """è¿è¡ŒåŒæ­¥åŠŸèƒ½ï¼ˆä¸“é—¨ç”¨äºexcel_tool.pyè°ƒç”¨ï¼‰"""
        print("=" * 60)
        print("ğŸ¯ Excelæ•°æ®åŒæ­¥å·¥å…·")
        print("ğŸ“‹ åŠŸèƒ½ï¼šå°†ä¸€ä¸ªæˆ–è€…å¤šä¸ªExcelæ–‡ä»¶çš„æ•°æ®åŒæ­¥åˆ°å¦ä¸€ä¸ªæ–‡ä»¶")
        print("=" * 60)
        
        # é€‰æ‹©åŒæ­¥æ¨¡å¼
        mode = self.select_sync_mode()
        
        if mode == "sync":
            self.run_sync_mode()
        elif mode == "multi_sync":
            self.run_multi_sync_mode()
        else:
            print("ğŸ‘‹ ç¨‹åºé€€å‡º")
    
    def select_operation_mode(self) -> str:
        """
        é€‰æ‹©æ“ä½œæ¨¡å¼
        
        Returns:
            str: æ“ä½œæ¨¡å¼ ("merge", "sync", æˆ– "multi_sync")
        """
        print("\nè¯·é€‰æ‹©æ“ä½œæ¨¡å¼ï¼š")
        print("1. åˆå¹¶åˆ°ç©ºExcelï¼ˆåˆ›å»ºæ–°çš„åˆå¹¶æ–‡ä»¶ï¼‰")
        print("2. åŒæ­¥åˆ°æœ‰æ•°æ®çš„Excelï¼ˆæ›´æ–°ç°æœ‰æ–‡ä»¶ï¼‰")
        print("   - 2.1 æºæ–‡ä»¶åˆ°ç›®æ ‡æ–‡ä»¶ï¼ˆå•ä¸ªæºæ–‡ä»¶åŒæ­¥ï¼‰")
        print("   - 2.2 å¤šä¸ªæºæ–‡ä»¶åˆ°ç›®æ ‡æ–‡ä»¶ï¼ˆå¤šä¸ªæºæ–‡ä»¶åŒæ­¥ï¼‰")
        
        while True:
            choice = input("\nè¯·é€‰æ‹© (1/2): ").strip()
            if choice == "1":
                print("âœ… å·²é€‰æ‹©ï¼šåˆå¹¶æ¨¡å¼")
                return "merge"
            elif choice == "2":
                # è¿›ä¸€æ­¥é€‰æ‹©åŒæ­¥æ¨¡å¼
                print("\nè¯·é€‰æ‹©åŒæ­¥æ¨¡å¼ï¼š")
                print("1. æºæ–‡ä»¶åˆ°ç›®æ ‡æ–‡ä»¶ï¼ˆå•ä¸ªæºæ–‡ä»¶åŒæ­¥ï¼‰")
                print("2. å¤šä¸ªæºæ–‡ä»¶åˆ°ç›®æ ‡æ–‡ä»¶ï¼ˆå¤šä¸ªæºæ–‡ä»¶åŒæ­¥ï¼‰")
                
                sync_choice = input("\nè¯·é€‰æ‹© (1/2): ").strip()
                if sync_choice == "1":
                    print("âœ… å·²é€‰æ‹©ï¼šå•æºåŒæ­¥æ¨¡å¼")
                    return "sync"
                elif sync_choice == "2":
                    print("âœ… å·²é€‰æ‹©ï¼šå¤šæºåŒæ­¥æ¨¡å¼")
                    return "multi_sync"
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")
                    continue
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")
    
    def select_sync_mode(self) -> str:
        """
        é€‰æ‹©åŒæ­¥æ¨¡å¼ï¼ˆä¸“é—¨ç”¨äºåŒæ­¥åŠŸèƒ½ï¼‰
        
        Returns:
            str: åŒæ­¥æ¨¡å¼ ("sync" æˆ– "multi_sync")
        """
        print("\nè¯·é€‰æ‹©åŒæ­¥æ¨¡å¼ï¼š")
        print("1. æºæ–‡ä»¶åˆ°ç›®æ ‡æ–‡ä»¶ï¼ˆå•ä¸ªæºæ–‡ä»¶åŒæ­¥ï¼‰")
        print("2. å¤šä¸ªæºæ–‡ä»¶åˆ°ç›®æ ‡æ–‡ä»¶ï¼ˆå¤šä¸ªæºæ–‡ä»¶åŒæ­¥ï¼‰")
        
        while True:
            choice = input("\nè¯·é€‰æ‹© (1/2): ").strip()
            if choice == "1":
                print("âœ… å·²é€‰æ‹©ï¼šå•æºåŒæ­¥æ¨¡å¼")
                return "sync"
            elif choice == "2":
                print("âœ… å·²é€‰æ‹©ï¼šå¤šæºåŒæ­¥æ¨¡å¼")
                return "multi_sync"
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")
    
    def run_merge_mode(self):
        """è¿è¡Œåˆå¹¶æ¨¡å¼"""
        print("\nğŸ”„ å¯åŠ¨åˆå¹¶æ¨¡å¼...")
        
        try:
            # 1. æ–‡ä»¶é€‰æ‹©
            folder_path = input("è¯·è¾“å…¥åŒ…å«Excelæ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆæˆ–æŒ‰å›è½¦ä½¿ç”¨å½“å‰ç›®å½•ï¼‰: ").strip()
            if not folder_path:
                folder_path = "."
            
            files = self.select_files(folder_path)
            if not files:
                print("âŒ æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶ï¼Œç¨‹åºé€€å‡º")
                return
            
            # 2. å­—æ®µåˆ†æ
            all_fields = self.get_field_list(files)
            if not all_fields:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•å­—æ®µï¼Œç¨‹åºé€€å‡º")
                return
            
            # 3. å­—æ®µé€‰æ‹©
            selected_fields = self.select_fields(all_fields)
            if not selected_fields:
                print("âŒ æœªé€‰æ‹©ä»»ä½•å­—æ®µï¼Œç¨‹åºé€€å‡º")
                return
            
            # 3.5. å­—æ®µè¡¥å……é…ç½®
            field_analysis_result = self.analyze_field_supplement_situation(files, selected_fields)
            self.enable_field_supplement, self.field_mappings, self.field_default_values, self.link_field = self.configure_field_supplement(field_analysis_result, selected_fields)
            
            if self.enable_field_supplement:
                # ä¸ºæ¯ä¸ªéœ€è¦è¡¥å……çš„å­—æ®µæ„å»ºæ˜ å°„
                field_analysis = field_analysis_result['field_analysis']
                self.field_mappings = {}  # åˆå§‹åŒ–å­—æ®µæ˜ å°„å­—å…¸
                
                for field in selected_fields:
                    if field_analysis[field]['total_files_missing_field'] > 0:
                        # æ„å»ºè¯¥å­—æ®µçš„æ˜ å°„
                        files_with_field = field_analysis[field]['files_with_field']
                        if files_with_field:
                            self.field_mappings[field] = self.build_field_mapping(files_with_field, field, self.link_field)
                
                # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„å­—æ®µéƒ½è¢«é€‰ä¸­
                for field in selected_fields:
                    if field_analysis[field]['total_files_missing_field'] > 0:
                        # æ£€æŸ¥å­—æ®µæ˜¯å¦å·²åœ¨é€‰æ‹©åˆ—è¡¨ä¸­
                        field_variants = self.get_field_variants(field)
                        field_exists = field in selected_fields or any(variant in selected_fields for variant in field_variants)
                        
                        if not field_exists:
                            # é€‰æ‹©æœ€å¸¸ç”¨çš„å˜ä½“
                            standard_count = sum(1 for f in files if field in self.get_file_fields(f))
                            star_count = sum(1 for f in files if f'*{field}' in self.get_file_fields(f))
                            
                            if star_count >= standard_count:
                                selected_fields.append(f'*{field}')
                                print(f"ğŸ“ è‡ªåŠ¨æ·»åŠ *{field}å­—æ®µåˆ°é€‰æ‹©åˆ—è¡¨")
                            else:
                                selected_fields.append(field)
                                print(f"ğŸ“ è‡ªåŠ¨æ·»åŠ {field}å­—æ®µåˆ°é€‰æ‹©åˆ—è¡¨")
            
            # 4. å»é‡é…ç½®
            deduplicate, dedup_fields = self.configure_deduplication()
            
            # 4.5. è¾“å‡ºè®¾ç½®
            self.set_output_filename()
            
            # 5. æ•°æ®å¤„ç†
            result_df = self.process_data(files, selected_fields, deduplicate, dedup_fields)
            if result_df.empty:
                print("âŒ æ²¡æœ‰æ•°æ®å¯å¤„ç†ï¼Œç¨‹åºé€€å‡º")
                return
            
            # 6. å¯¼å‡ºç»“æœ
            output_path = self.export_to_excel(result_df)
            
            if output_path:
                print(f"\n" + "=" * 60)
                print("ğŸ‰ å¤„ç†å®Œæˆï¼")
                print("=" * 60)
                print(f"ğŸ“„ ç»“æœæ–‡ä»¶: {output_path}")
                print(f"ğŸ“Š å¤„ç†è®°å½•æ•°: {len(result_df)}")
                print(f"ğŸ“ å¤„ç†æ–‡ä»¶æ•°: {len(files)}")
                print(f"ğŸ“‹ é€‰æ‹©å­—æ®µæ•°: {len(selected_fields)}")
                if deduplicate and dedup_fields:
                    print(f"ğŸ” å»é‡å­—æ®µ: {', '.join(dedup_fields)}")
                if self.enable_field_supplement:
                    print(f"ğŸ”§ å­—æ®µè¡¥å……: å·²å¯ç”¨ï¼Œå…³è”å­—æ®µ '{self.link_field}'ï¼Œè¡¥å……å­—æ®µæ•° {len(self.field_mappings)} ä¸ª")
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
    
    def run_sync_mode(self):
        """è¿è¡ŒåŒæ­¥æ¨¡å¼"""
        print("\nğŸ”„ å¯åŠ¨åŒæ­¥æ¨¡å¼...")
        
        try:
            # 1. æ–‡ä»¶è§’è‰²é€‰æ‹©
            self.select_file_roles()
            
            # 2. å…³è”å­—æ®µé€‰æ‹©
            self.select_link_field()
            
            # 3. æ›´æ–°å­—æ®µé€‰æ‹©
            self.select_update_fields()
            
            # 3.5. è¾“å‡ºç›®å½•è®¾ç½®
            self.set_output_directory()
            
            # 3.6. æœªåŒ¹é…è®°å½•å¤„ç†é…ç½®
            self.configure_unmatched_handling()
            
            # 4. æ‰§è¡ŒåŒæ­¥
            self.execute_sync()
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
    
    def select_file_roles(self):
        """æ–‡ä»¶è§’è‰²é€‰æ‹©"""
        print(f"\n=== æ­¥éª¤1: æ–‡ä»¶è§’è‰²é€‰æ‹© ===")
        
        # é€‰æ‹©æ–‡ä»¶å¤¹
        folder_path = input("è¯·è¾“å…¥åŒ…å«Excelæ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆæˆ–æŒ‰å›è½¦ä½¿ç”¨é»˜è®¤ç›®å½•G:\\wang\\excelï¼‰: ").strip()
        if not folder_path:
            folder_path = "G:\\wang\\excel"
        
        # æ‰«æExcelæ–‡ä»¶
        excel_patterns = ['*.xlsx', '*.xls']
        excel_files = []
        
        for pattern in excel_patterns:
            excel_files.extend(glob.glob(os.path.join(folder_path, pattern)))
        
        if not excel_files:
            print(f"âŒ åœ¨æ–‡ä»¶å¤¹ '{folder_path}' ä¸­æ²¡æœ‰æ‰¾åˆ°Excelæ–‡ä»¶")
            return
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
        print(f"\nâœ… æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶:")
        for i, file in enumerate(excel_files, 1):
            filename = os.path.basename(file)
            file_size = os.path.getsize(file) / 1024  # KB
            print(f"{i:2d}. {filename:<30} ({file_size:.1f} KB)")
        
        # é€‰æ‹©æºæ–‡ä»¶
        print(f"\nğŸ“‹ è¯·é€‰æ‹©æºæ–‡ä»¶ï¼ˆæä¾›æ•°æ®çš„æ–‡ä»¶ï¼‰:")
        while True:
            try:
                source_choice = input("è¯·è¾“å…¥æºæ–‡ä»¶ç¼–å·: ").strip()
                source_index = int(source_choice) - 1
                if 0 <= source_index < len(excel_files):
                    self.source_file = excel_files[source_index]
                    print(f"âœ… æºæ–‡ä»¶: {os.path.basename(self.source_file)}")
                    break
                else:
                    print("âŒ æ–‡ä»¶ç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°é€‰æ‹©")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        # é€‰æ‹©ç›®æ ‡æ–‡ä»¶
        print(f"\nğŸ“‹ è¯·é€‰æ‹©ç›®æ ‡æ–‡ä»¶ï¼ˆéœ€è¦æ›´æ–°çš„æ–‡ä»¶ï¼‰:")
        while True:
            try:
                target_choice = input("è¯·è¾“å…¥ç›®æ ‡æ–‡ä»¶ç¼–å·: ").strip()
                target_index = int(target_choice) - 1
                if 0 <= target_index < len(excel_files):
                    if target_index == source_index:
                        print("âŒ ç›®æ ‡æ–‡ä»¶ä¸èƒ½ä¸æºæ–‡ä»¶ç›¸åŒï¼Œè¯·é‡æ–°é€‰æ‹©")
                        continue
                    self.target_file = excel_files[target_index]
                    print(f"âœ… ç›®æ ‡æ–‡ä»¶: {os.path.basename(self.target_file)}")
                    break
                else:
                    print("âŒ æ–‡ä»¶ç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°é€‰æ‹©")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    def select_link_field(self):
        """å…³è”å­—æ®µé€‰æ‹©"""
        print(f"\n=== æ­¥éª¤2: å…³è”å­—æ®µé€‰æ‹© ===")
        
        try:
            # è¯»å–æºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶
            source_df = pd.read_excel(self.source_file)
            target_df = pd.read_excel(self.target_file)
            
            # è·å–ä¸¤ä¸ªæ–‡ä»¶çš„åˆ—å
            source_columns = list(source_df.columns)
            target_columns = list(target_df.columns)
            
            # æ‰¾å‡ºå…±æœ‰çš„å­—æ®µ
            common_fields = list(set(source_columns) & set(target_columns))
            
            if not common_fields:
                print("âŒ æºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶æ²¡æœ‰å…±åŒçš„å­—æ®µï¼Œæ— æ³•è¿›è¡ŒåŒæ­¥")
                return
            
            print(f"ğŸ“‹ æºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶å…±æœ‰çš„å­—æ®µ:")
            for i, field in enumerate(common_fields, 1):
                print(f"{i:2d}. {field}")
            
            # é€‰æ‹©å…³è”å­—æ®µ
            print(f"\nğŸ”— è¯·é€‰æ‹©ç”¨äºå…³è”è®°å½•çš„å­—æ®µï¼ˆå¦‚IDã€å§“åç­‰å”¯ä¸€æ ‡è¯†å­—æ®µï¼‰:")
            while True:
                try:
                    link_choice = input("è¯·è¾“å…¥å…³è”å­—æ®µç¼–å·: ").strip()
                    link_index = int(link_choice) - 1
                    if 0 <= link_index < len(common_fields):
                        self.link_field = common_fields[link_index]
                        print(f"âœ… å…³è”å­—æ®µ: {self.link_field}")
                        break
                    else:
                        print("âŒ å­—æ®µç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°é€‰æ‹©")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                    
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    def set_output_directory(self):
        """è®¾ç½®è¾“å‡ºç›®å½•"""
        print(f"\n=== æ­¥éª¤3.5: è¾“å‡ºç›®å½•è®¾ç½® ===")
        
        # è·å–ç›®æ ‡æ–‡ä»¶æ‰€åœ¨ç›®å½•ä½œä¸ºé»˜è®¤ç›®å½•
        default_dir = os.path.dirname(self.target_file)
        print(f"ğŸ“ å½“å‰ç›®æ ‡æ–‡ä»¶ç›®å½•: {default_dir}")
        
        output_dir = input("è¯·è¾“å…¥è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆæˆ–æŒ‰å›è½¦ä½¿ç”¨ç›®æ ‡æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼‰: ").strip()
        if not output_dir:
            output_dir = default_dir
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        if not os.path.exists(output_dir):
            try:
                os.makedirs(output_dir)
                print(f"âœ… å·²åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
            except Exception as e:
                print(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥: {str(e)}")
                print(f"ğŸ“ ä½¿ç”¨é»˜è®¤ç›®å½•: {default_dir}")
                output_dir = default_dir
        else:
            print(f"âœ… è¾“å‡ºç›®å½•: {output_dir}")
        
        self.output_directory = output_dir
    
    def configure_unmatched_handling(self):
        """é…ç½®æœªåŒ¹é…è®°å½•çš„å¤„ç†æ–¹å¼"""
        print(f"\n=== æ­¥éª¤3.6: æœªåŒ¹é…è®°å½•å¤„ç†é…ç½® ===")
        
        print("ğŸ¤” å¯¹äºåŒ¹é…ä¸ä¸Šçš„è®°å½•ï¼Œæ‚¨å¸Œæœ›å¦‚ä½•å¤„ç†ï¼Ÿ")
        print("1. è®¾ç½®ä¸ºç©ºå€¼ï¼ˆä¿æŒåŸæœ‰æ•°æ®ä¸å˜ï¼‰")
        print("2. ä½¿ç”¨é»˜è®¤å€¼ï¼ˆä¸ºæ¯ä¸ªå­—æ®µè®¾ç½®é»˜è®¤å€¼ï¼‰")
        
        while True:
            choice = input("è¯·é€‰æ‹©å¤„ç†æ–¹å¼ (1/2): ").strip()
            if choice == "1":
                self.unmatched_handling = "empty"
                print("âœ… å·²é€‰æ‹©ï¼šæœªåŒ¹é…è®°å½•è®¾ç½®ä¸ºç©ºå€¼")
                break
            elif choice == "2":
                self.unmatched_handling = "default"
                print("âœ… å·²é€‰æ‹©ï¼šæœªåŒ¹é…è®°å½•ä½¿ç”¨é»˜è®¤å€¼")
                self.set_default_values()
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")
    
    def set_default_values(self):
        """ä¸ºæ¯ä¸ªæ›´æ–°å­—æ®µè®¾ç½®é»˜è®¤å€¼"""
        print(f"\nğŸ“ è¯·ä¸ºæ¯ä¸ªæ›´æ–°å­—æ®µè®¾ç½®é»˜è®¤å€¼:")
        
        for field in self.update_fields:
            while True:
                default_value = input(f"è¯·è¾“å…¥å­—æ®µ '{field}' çš„é»˜è®¤å€¼: ").strip()
                if default_value:
                    self.default_values[field] = default_value
                    print(f"âœ… å­—æ®µ '{field}' é»˜è®¤å€¼è®¾ç½®ä¸º: {default_value}")
                    break
                else:
                    print("âŒ é»˜è®¤å€¼ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def select_update_fields(self):
        """æ›´æ–°å­—æ®µé€‰æ‹©"""
        print(f"\n=== æ­¥éª¤3: æ›´æ–°å­—æ®µé€‰æ‹© ===")
        
        try:
            # è¯»å–æºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶
            source_df = pd.read_excel(self.source_file)
            target_df = pd.read_excel(self.target_file)
            
            # è·å–ä¸¤ä¸ªæ–‡ä»¶çš„åˆ—å
            source_columns = list(source_df.columns)
            target_columns = list(target_df.columns)
            
            # æ˜¾ç¤ºæºæ–‡ä»¶çš„æ‰€æœ‰å­—æ®µä¾›ç”¨æˆ·é€‰æ‹©
            print(f"ğŸ“‹ æºæ–‡ä»¶ä¸­çš„æ‰€æœ‰å­—æ®µ:")
            for i, field in enumerate(source_columns, 1):
                # æ ‡è®°å“ªäº›å­—æ®µåœ¨ç›®æ ‡æ–‡ä»¶ä¸­å·²å­˜åœ¨
                status = "ï¼ˆç›®æ ‡æ–‡ä»¶ä¸­å·²å­˜åœ¨ï¼‰" if field in target_columns else "ï¼ˆç›®æ ‡æ–‡ä»¶ä¸­ä¸å­˜åœ¨ï¼‰"
                print(f"{i:2d}. {field} {status}")
            
            # é€‰æ‹©æ›´æ–°å­—æ®µ
            print(f"\nğŸ“ è¯·é€‰æ‹©éœ€è¦ä»æºæ–‡ä»¶åŒæ­¥åˆ°ç›®æ ‡æ–‡ä»¶çš„å­—æ®µ:")
            print("ğŸ’¡ è¾“å…¥å­—æ®µç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,2,3ï¼‰")
            print("ğŸ’¡ è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰å­—æ®µ")
            print("ğŸ’¡ æ³¨æ„ï¼šå¦‚æœå­—æ®µåœ¨ç›®æ ‡æ–‡ä»¶ä¸­å·²å­˜åœ¨ï¼Œå°†ä¼šè¦†ç›–åŸæœ‰æ•°æ®")
            
            while True:
                choice = input("è¯·é€‰æ‹©: ").strip().lower()
                
                if choice == 'all':
                    self.update_fields = source_columns
                    print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(source_columns)} ä¸ªå­—æ®µ")
                    break
                else:
                    try:
                        indices = [int(x.strip()) - 1 for x in choice.split(',')]
                        selected_fields = [source_columns[i] for i in indices if 0 <= i < len(source_columns)]
                        
                        if not selected_fields:
                            print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè¯·é‡æ–°é€‰æ‹©")
                            continue
                        
                        self.update_fields = selected_fields
                        print(f"âœ… å·²é€‰æ‹© {len(selected_fields)} ä¸ªå­—æ®µ:")
                        for field in selected_fields:
                            status = "ï¼ˆå°†è¦†ç›–ç›®æ ‡æ–‡ä»¶ä¸­çš„ç°æœ‰æ•°æ®ï¼‰" if field in target_columns else "ï¼ˆå°†æ·»åŠ åˆ°ç›®æ ‡æ–‡ä»¶ä¸­ï¼‰"
                            print(f"  ğŸ“‹ {field} {status}")
                        break
                        
                    except (ValueError, IndexError):
                        print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·é‡æ–°é€‰æ‹©")
                        
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    def execute_sync(self):
        """æ‰§è¡ŒåŒæ­¥æ“ä½œ"""
        print(f"\n=== æ­¥éª¤4: æ‰§è¡ŒåŒæ­¥ ===")
        
        try:
            # è¯»å–æºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶
            source_df = pd.read_excel(self.source_file)
            target_df = pd.read_excel(self.target_file)
            
            # ç»Ÿè®¡è®°å½•æ•°
            self.sync_stats['source_records'] = len(source_df)
            self.sync_stats['target_records'] = len(target_df)
            
            print(f"ğŸ“Š æºæ–‡ä»¶è®°å½•æ•°: {self.sync_stats['source_records']}")
            print(f"ğŸ“Š ç›®æ ‡æ–‡ä»¶è®°å½•æ•°: {self.sync_stats['target_records']}")
            print(f"ğŸ”— å…³è”å­—æ®µ: {self.link_field}")
            print(f"ğŸ“ æ›´æ–°å­—æ®µ: {', '.join(self.update_fields)}")
            
            # ç¡®è®¤æ‰§è¡Œ
            confirm = input(f"\næ˜¯å¦ç¡®è®¤æ‰§è¡ŒåŒæ­¥æ“ä½œï¼Ÿ(y/n): ").strip().lower()
            if confirm not in ['y', 'yes', 'æ˜¯']:
                print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                return
            
            # å¤‡ä»½ç›®æ ‡æ–‡ä»¶
            self.backup_target_file()
            
            # æ‰§è¡ŒåŒæ­¥
            updated_df = self.perform_sync(source_df, target_df)
            
            # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
            self.save_updated_file(updated_df)
            
            # æ˜¾ç¤ºåŒæ­¥ç»“æœ
            self.show_sync_results()
            
        except Exception as e:
            print(f"âŒ åŒæ­¥æ‰§è¡Œå‡ºé”™: {str(e)}")
    
    def backup_target_file(self):
        """å¤‡ä»½ç›®æ ‡æ–‡ä»¶"""
        try:
            # åˆ›å»ºå¤‡ä»½ç›®å½•
            backup_dir = "backup"
            if not os.path.exists(backup_dir):
                os.makedirs(backup_dir)
            
            # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
            filename = os.path.basename(self.target_file)
            name, ext = os.path.splitext(filename)
            timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
            backup_filename = f"{name}_backup_{timestamp}{ext}"
            backup_path = os.path.join(backup_dir, backup_filename)
            
            # å¤åˆ¶æ–‡ä»¶
            import shutil
            shutil.copy2(self.target_file, backup_path)
            
            print(f"âœ… å·²å¤‡ä»½ç›®æ ‡æ–‡ä»¶: {backup_filename}")
            
        except Exception as e:
            print(f"âš ï¸  å¤‡ä»½æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    def perform_sync(self, source_df: pd.DataFrame, target_df: pd.DataFrame) -> pd.DataFrame:
        """æ‰§è¡ŒåŒæ­¥æ“ä½œ"""
        print(f"\nğŸ”„ æ­£åœ¨æ‰§è¡ŒåŒæ­¥...")
        
        # åˆ›å»ºç›®æ ‡æ–‡ä»¶çš„å‰¯æœ¬
        updated_df = target_df.copy()
        
        # ä¸ºæ¯ä¸ªæ›´æ–°å­—æ®µæ·»åŠ æ–°åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        added_fields = []
        existing_fields = []
        for field in self.update_fields:
            if field not in updated_df.columns:
                updated_df[field] = None
                added_fields.append(field)
            else:
                existing_fields.append(field)
        
        if added_fields:
            print(f"ğŸ“ å°†æ·»åŠ æ–°å­—æ®µåˆ°ç›®æ ‡æ–‡ä»¶: {', '.join(added_fields)}")
        if existing_fields:
            print(f"ğŸ“ å°†è¦†ç›–ç›®æ ‡æ–‡ä»¶ä¸­çš„ç°æœ‰å­—æ®µ: {', '.join(existing_fields)}")
        
        # æ„å»ºæºæ–‡ä»¶çš„æ˜ å°„å…³ç³»
        source_mapping = {}
        for _, row in source_df.iterrows():
            link_value = str(row[self.link_field]).strip()
            if link_value and link_value != 'nan':
                source_mapping[link_value] = row
        
        print(f"ğŸ“Š æºæ–‡ä»¶æ˜ å°„å…³ç³»æ•°é‡: {len(source_mapping)}")
        
        # æ›´æ–°ç›®æ ‡æ–‡ä»¶
        updated_count = 0
        failed_count = 0
        unmatched_count = 0
        
        for idx, row in updated_df.iterrows():
            link_value = str(row[self.link_field]).strip()
            
            if link_value and link_value != 'nan' and link_value in source_mapping:
                # æ‰¾åˆ°åŒ¹é…çš„è®°å½•ï¼Œæ›´æ–°å­—æ®µ
                source_row = source_mapping[link_value]
                for field in self.update_fields:
                    try:
                        # å¤„ç†æ•°æ®ç±»å‹è½¬æ¢ï¼Œé¿å…ç±»å‹ä¸åŒ¹é…è­¦å‘Š
                        value = source_row[field]
                        if pd.isna(value) or str(value).strip() == '':
                            continue
                        
                        # ç¡®ä¿ç›®æ ‡åˆ—æ˜¯å¯¹è±¡ç±»å‹ï¼Œä»¥ä¿æŒå­—ç¬¦ä¸²æ ¼å¼
                        if updated_df[field].dtype in ['int64', 'float64']:
                            updated_df[field] = updated_df[field].astype('object')
                        
                        # ç›´æ¥èµ‹å€¼ï¼Œä¿æŒåŸå§‹å­—ç¬¦ä¸²æ ¼å¼
                        updated_df.at[idx, field] = str(value)
                    except Exception as e:
                        print(f"âš ï¸  æ›´æ–°å­—æ®µ {field} æ—¶å‡ºé”™: {str(e)}")
                        continue
                updated_count += 1
            else:
                # å¤„ç†æœªåŒ¹é…çš„è®°å½•
                if self.unmatched_handling == "default":
                    # ä½¿ç”¨é»˜è®¤å€¼
                    for field in self.update_fields:
                        try:
                            # ç¡®ä¿ç›®æ ‡åˆ—æ˜¯å¯¹è±¡ç±»å‹
                            if updated_df[field].dtype in ['int64', 'float64']:
                                updated_df[field] = updated_df[field].astype('object')
                            
                            # è®¾ç½®é»˜è®¤å€¼
                            default_value = self.default_values.get(field, "")
                            updated_df.at[idx, field] = default_value
                        except Exception as e:
                            print(f"âš ï¸  è®¾ç½®å­—æ®µ {field} é»˜è®¤å€¼æ—¶å‡ºé”™: {str(e)}")
                            continue
                    unmatched_count += 1
                else:
                    # è®¾ç½®ä¸ºç©ºå€¼ï¼ˆä¿æŒåŸæœ‰æ•°æ®ä¸å˜ï¼‰
                    failed_count += 1
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.sync_stats['updated_records'] = updated_count
        self.sync_stats['failed_records'] = failed_count
        self.sync_stats['unmatched_records'] = unmatched_count
        
        if self.sync_stats['target_records'] > 0:
            self.sync_stats['sync_success_rate'] = (updated_count / self.sync_stats['target_records']) * 100
        
        print(f"âœ… åŒæ­¥å®Œæˆ:")
        print(f"  æ›´æ–°è®°å½•: {updated_count} ä¸ª")
        print(f"  æœªåŒ¹é…è®°å½•: {unmatched_count} ä¸ª")
        print(f"  å¤±è´¥è®°å½•: {failed_count} ä¸ª")
        print(f"  æˆåŠŸç‡: {self.sync_stats['sync_success_rate']:.1f}%")
        
        return updated_df
    
    def save_updated_file(self, updated_df: pd.DataFrame):
        """ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«å ç”¨
            if os.path.exists(self.target_file):
                try:
                    # å°è¯•ä»¥å†™å…¥æ¨¡å¼æ‰“å¼€æ–‡ä»¶ï¼Œæ£€æŸ¥æ˜¯å¦è¢«å ç”¨
                    with open(self.target_file, 'r+b') as f:
                        pass
                except PermissionError:
                    print(f"âŒ ç›®æ ‡æ–‡ä»¶è¢«å…¶ä»–ç¨‹åºå ç”¨ï¼Œæ— æ³•ä¿å­˜")
                    print("è¯·å…³é—­Excelæˆ–å…¶ä»–å¯èƒ½æ‰“å¼€è¯¥æ–‡ä»¶çš„ç¨‹åºï¼Œç„¶åé‡è¯•")
                    
                    # è¯¢é—®æ˜¯å¦ä¿å­˜åˆ°æ–°æ–‡ä»¶
                    save_as_new = input("æ˜¯å¦ä¿å­˜åˆ°æ–°æ–‡ä»¶ï¼Ÿ(y/n): ").strip().lower()
                    if save_as_new in ['y', 'yes', 'æ˜¯']:
                        # ç”Ÿæˆæ–°æ–‡ä»¶å
                        filename = os.path.basename(self.target_file)
                        name, ext = os.path.splitext(filename)
                        timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
                        new_filename = f"{name}_updated_{timestamp}{ext}"
                        new_path = os.path.join(self.output_directory, new_filename)
                        
                        with pd.ExcelWriter(new_path, engine='openpyxl') as writer:
                            updated_df.to_excel(writer, index=False)
                        
                        print(f"âœ… å·²ä¿å­˜åˆ°æ–°æ–‡ä»¶: {new_filename}")
                        return
                    else:
                        print("âŒ ç”¨æˆ·å–æ¶ˆä¿å­˜")
                        return
            
            # ä¿å­˜åˆ°åŸæ–‡ä»¶
            with pd.ExcelWriter(self.target_file, engine='openpyxl') as writer:
                updated_df.to_excel(writer, index=False)
            
            print(f"âœ… ç›®æ ‡æ–‡ä»¶å·²æ›´æ–°: {os.path.basename(self.target_file)}")
            
        except PermissionError:
            print(f"âŒ æ— æ³•ä¿å­˜æ–‡ä»¶ï¼Œæ–‡ä»¶å¯èƒ½è¢«å…¶ä»–ç¨‹åºå ç”¨")
            print("è‡ªåŠ¨ä¿å­˜åˆ°æ–°æ–‡ä»¶...")
            
            # ç”Ÿæˆæ–°æ–‡ä»¶å
            filename = os.path.basename(self.target_file)
            name, ext = os.path.splitext(filename)
            timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
            new_filename = f"{name}_updated_{timestamp}{ext}"
            new_path = os.path.join(self.output_directory, new_filename)
            
            try:
                with pd.ExcelWriter(new_path, engine='openpyxl') as writer:
                    updated_df.to_excel(writer, index=False)
                
                print(f"âœ… å·²ä¿å­˜åˆ°æ–°æ–‡ä»¶: {new_filename}")
                # æ›´æ–°ç›®æ ‡æ–‡ä»¶è·¯å¾„ä¸ºæ–°çš„æ–‡ä»¶è·¯å¾„
                self.target_file = new_path
            except Exception as e2:
                print(f"âŒ ä¿å­˜åˆ°æ–°æ–‡ä»¶ä¹Ÿå¤±è´¥: {str(e2)}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            print("å°è¯•ä¿å­˜åˆ°æ–°æ–‡ä»¶...")
            
            try:
                # ç”Ÿæˆæ–°æ–‡ä»¶å
                filename = os.path.basename(self.target_file)
                name, ext = os.path.splitext(filename)
                timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
                new_filename = f"{name}_updated_{timestamp}{ext}"
                new_path = os.path.join(self.output_directory, new_filename)
                
                with pd.ExcelWriter(new_path, engine='openpyxl') as writer:
                    updated_df.to_excel(writer, index=False)
                
                print(f"âœ… å·²ä¿å­˜åˆ°æ–°æ–‡ä»¶: {new_filename}")
            except Exception as e2:
                print(f"âŒ ä¿å­˜åˆ°æ–°æ–‡ä»¶ä¹Ÿå¤±è´¥: {str(e2)}")
    
    def show_sync_results(self):
        """æ˜¾ç¤ºåŒæ­¥ç»“æœ"""
        print(f"\n" + "=" * 60)
        print("ğŸ‰ åŒæ­¥å¤„ç†å®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ“Š åŒæ­¥ç»Ÿè®¡ä¿¡æ¯ï¼š")
        print(f"æºæ–‡ä»¶: {os.path.basename(self.source_file)}")
        print(f"ç›®æ ‡æ–‡ä»¶: {os.path.basename(self.target_file)}")
        print(f"æºæ–‡ä»¶è®°å½•æ•°: {self.sync_stats['source_records']} ä¸ª")
        print(f"ç›®æ ‡æ–‡ä»¶è®°å½•æ•°: {self.sync_stats['target_records']} ä¸ª")
        print(f"æˆåŠŸæ›´æ–°è®°å½•: {self.sync_stats['updated_records']} ä¸ª")
        print(f"æœªåŒ¹é…è®°å½•: {self.sync_stats.get('unmatched_records', 0)} ä¸ª")
        print(f"å¤±è´¥è®°å½•: {self.sync_stats['failed_records']} ä¸ª")
        print(f"åŒæ­¥æˆåŠŸç‡: {self.sync_stats['sync_success_rate']:.1f}%")
        print(f"å…³è”å­—æ®µ: {self.link_field}")
        print(f"æ›´æ–°å­—æ®µ: {', '.join(self.update_fields)}")
        print(f"å¤„ç†æ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ç§»é™¤åŒæ­¥æŠ¥å‘Šä¿å­˜
        # self.save_sync_report()
    
    def save_sync_report(self):
        """ä¿å­˜åŒæ­¥æŠ¥å‘Š"""
        try:
            # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
            timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
            report_filename = f"åŒæ­¥å¤„ç†æŠ¥å‘Š_{timestamp}.xlsx"
            
            # åˆ›å»ºæŠ¥å‘Šæ•°æ®
            report_data = {
                'ç»Ÿè®¡é¡¹ç›®': [
                    'æºæ–‡ä»¶',
                    'ç›®æ ‡æ–‡ä»¶',
                    'æºæ–‡ä»¶è®°å½•æ•°',
                    'ç›®æ ‡æ–‡ä»¶è®°å½•æ•°',
                    'æˆåŠŸæ›´æ–°è®°å½•',
                    'å¤±è´¥è®°å½•',
                    'åŒæ­¥æˆåŠŸç‡',
                    'å…³è”å­—æ®µ',
                    'æ›´æ–°å­—æ®µ',
                    'å¤„ç†æ—¶é—´'
                ],
                'æ•°å€¼': [
                    os.path.basename(self.source_file),
                    os.path.basename(self.target_file),
                    f"{self.sync_stats['source_records']} ä¸ª",
                    f"{self.sync_stats['target_records']} ä¸ª",
                    f"{self.sync_stats['updated_records']} ä¸ª",
                    f"{self.sync_stats['failed_records']} ä¸ª",
                    f"{self.sync_stats['sync_success_rate']:.1f}%",
                    self.link_field,
                    ', '.join(self.update_fields),
                    pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
                ]
            }
            
            # ä¿å­˜åˆ°Excelæ–‡ä»¶
            report_df = pd.DataFrame(report_data)
            report_df.to_excel(report_filename, index=False)
            
            # ç§»é™¤åŒæ­¥æŠ¥å‘Šè¾“å‡ºä¿¡æ¯
            # print(f"ğŸ“„ åŒæ­¥æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filename}")
            
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜åŒæ­¥æŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}")

    def analyze_field_supplement_situation(self, files: List[str], selected_fields: List[str]) -> Dict:
        """
        åˆ†æå­—æ®µè¡¥å……æƒ…å†µ
        
        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            selected_fields: é€‰ä¸­çš„å­—æ®µåˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        print(f"\nğŸ” åˆ†æå­—æ®µè¡¥å……æƒ…å†µ...")
        
        field_analysis = {}
        files_with_all_fields = []
        files_missing_fields = {}
        
        for field in selected_fields:
            field_analysis[field] = {
                'files_with_field': [],
                'files_missing_field': [],
                'total_files_with_field': 0,
                'total_files_missing_field': 0
            }
        
        for file in files:
            try:
                df = pd.read_excel(file)
                file_fields = list(df.columns)
                
                # æ£€æŸ¥æ¯ä¸ªå­—æ®µ
                file_has_all_fields = True
                missing_fields_in_file = []
                
                for field in selected_fields:
                    # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨ï¼ˆåŒ…æ‹¬å˜ä½“ï¼‰
                    field_exists = False
                    if field in file_fields:
                        field_exists = True
                    else:
                        # æ£€æŸ¥å˜ä½“
                        field_variants = self.get_field_variants(field)
                        for variant in field_variants:
                            if variant in file_fields:
                                field_exists = True
                                break
                    
                    if field_exists:
                        field_analysis[field]['files_with_field'].append(file)
                        field_analysis[field]['total_files_with_field'] += 1
                    else:
                        field_analysis[field]['files_missing_field'].append(file)
                        field_analysis[field]['total_files_missing_field'] += 1
                        missing_fields_in_file.append(field)
                        file_has_all_fields = False
                
                if file_has_all_fields:
                    files_with_all_fields.append(file)
                else:
                    files_missing_fields[file] = missing_fields_in_file
                    
            except Exception as e:
                print(f"âš ï¸  åˆ†ææ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
                continue
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        for file in files:
            try:
                df = pd.read_excel(file)
                file_fields = list(df.columns)
                
                missing_fields = []
                for field in selected_fields:
                    field_exists = False
                    if field in file_fields:
                        field_exists = True
                    else:
                        field_variants = self.get_field_variants(field)
                        for variant in field_variants:
                            if variant in file_fields:
                                field_exists = True
                                break
                    
                    if not field_exists:
                        missing_fields.append(field)
                
                if not missing_fields:
                    print(f"âœ… {os.path.basename(file)}: åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ")
                else:
                    print(f"âš ï¸  {os.path.basename(file)}: ç¼ºå°‘å­—æ®µ {', '.join(missing_fields)}")
                    
            except Exception as e:
                print(f"âš ï¸  åˆ†ææ–‡ä»¶ '{os.path.basename(file)}' æ—¶å‡ºé”™: {str(e)}")
                continue
        
        return {
            'field_analysis': field_analysis,
            'files_with_all_fields': files_with_all_fields,
            'files_missing_fields': files_missing_fields,
            'total_files': len(files)
        }
    
    def get_field_variants(self, field: str) -> List[str]:
        """
        è·å–å­—æ®µçš„å˜ä½“åç§°
        
        Args:
            field: åŸå§‹å­—æ®µå
            
        Returns:
            å­—æ®µå˜ä½“åˆ—è¡¨
        """
        variants = []
        
        # å­¦å·å­—æ®µå˜ä½“
        if field == 'å­¦å·':
            variants = ['*å­¦å·']
        elif field == '*å­¦å·':
            variants = ['å­¦å·']
        
        # å­¦ç”Ÿå§“åå­—æ®µå˜ä½“
        elif field == 'å­¦ç”Ÿå§“å':
            variants = ['*å­¦ç”Ÿå§“å']
        elif field == '*å­¦ç”Ÿå§“å':
            variants = ['å­¦ç”Ÿå§“å']
        
        # å…¶ä»–å­—æ®µçš„é€šç”¨å˜ä½“ï¼ˆå¸¦*å‰ç¼€ï¼‰
        elif not field.startswith('*'):
            variants = [f'*{field}']
        else:
            variants = [field[1:]]  # å»æ‰*å‰ç¼€
        
        return variants
    
    def configure_field_supplement(self, analysis_result: Dict, selected_fields: List[str]) -> Tuple[bool, Dict[str, str], Dict[str, str], str]:
        """
        é…ç½®å­—æ®µè¡¥å……åŠŸèƒ½
        
        Args:
            analysis_result: åˆ†æç»“æœ
            selected_fields: é€‰ä¸­çš„å­—æ®µåˆ—è¡¨
            
        Returns:
            (æ˜¯å¦å¯ç”¨è¡¥å……åŠŸèƒ½, å­—æ®µæ˜ å°„å­—å…¸, é»˜è®¤å€¼å­—å…¸, å…³è”å­—æ®µ)
        """
        field_analysis = analysis_result['field_analysis']
        files_missing_fields = analysis_result['files_missing_fields']
        
        # æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦è¡¥å……çš„å­—æ®µ
        fields_need_supplement = []
        for field in selected_fields:
            if field_analysis[field]['total_files_missing_field'] > 0:
                fields_need_supplement.append(field)
        
        if not fields_need_supplement:
            print(f"\nâœ… æ‰€æœ‰æ–‡ä»¶éƒ½åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µï¼Œæ— éœ€è¡¥å……")
            return False, {}, {}, 'å­¦å·'
        
        print(f"\n=== å­—æ®µè¡¥å……é…ç½® ===")
        print(f"ğŸ“Š åˆ†æç»“æœ:")
        print(f"  â€¢ åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µçš„æ–‡ä»¶: {len(analysis_result['files_with_all_fields'])} ä¸ª")
        print(f"  â€¢ éœ€è¦è¡¥å……å­—æ®µçš„æ–‡ä»¶: {len(files_missing_fields)} ä¸ª")
        
        for field in fields_need_supplement:
            missing_count = field_analysis[field]['total_files_missing_field']
            total_count = analysis_result['total_files']
            print(f"  â€¢ ç¼ºå°‘å­—æ®µ '{field}' çš„æ–‡ä»¶: {missing_count}/{total_count} ä¸ª")
        
        print(f"\nğŸ¤” æ£€æµ‹åˆ°éƒ¨åˆ†æ–‡ä»¶ç¼ºå°‘å­—æ®µï¼Œæ˜¯å¦å¯ç”¨å­—æ®µè¡¥å……åŠŸèƒ½ï¼Ÿ")
        print(f"ğŸ“ è¡¥å……åŠŸèƒ½å°†ä»å…¶ä»–æ–‡ä»¶ä¸­æ ¹æ®å…³è”å­—æ®µåŒ¹é…è·å–ç¼ºå¤±å­—æ®µ")
        
        choice = input("è¯·é€‰æ‹© (y/nï¼Œé»˜è®¤y): ").strip().lower()
        enable_supplement = choice not in ['n', 'no', 'å¦']
        
        if not enable_supplement:
            print(f"âœ… å·²é€‰æ‹©ä¸å¯ç”¨å­—æ®µè¡¥å……åŠŸèƒ½")
            return False, {}, {}, 'å­¦å·'
        
        # é€‰æ‹©å…³è”å­—æ®µ
        print(f"\nğŸ”— è¯·é€‰æ‹©ç”¨äºåŒ¹é…çš„å…³è”å­—æ®µ:")
        print(f"ğŸ“‹ å¯ç”¨å­—æ®µ: {', '.join(selected_fields)}")
        print(f"ğŸ“ è¾“å…¥å­—æ®µåç§°ï¼ˆå¦‚ï¼šå­¦å·ã€å­¦ç”Ÿå§“åç­‰ï¼‰")
        print(f"ğŸ“ å»ºè®®é€‰æ‹©åœ¨æ‰€æœ‰æ–‡ä»¶ä¸­éƒ½å­˜åœ¨ä¸”å”¯ä¸€æ€§è¾ƒå¥½çš„å­—æ®µä½œä¸ºå…³è”å­—æ®µ")
        
        link_field = input("å…³è”å­—æ®µï¼ˆé»˜è®¤ï¼šå­¦å·ï¼‰: ").strip()
        if not link_field:
            link_field = 'å­¦å·'
        
        # éªŒè¯å…³è”å­—æ®µæ˜¯å¦åœ¨é€‰ä¸­å­—æ®µä¸­
        if link_field not in selected_fields:
            print(f"âš ï¸  å…³è”å­—æ®µ '{link_field}' ä¸åœ¨é€‰ä¸­å­—æ®µä¸­ï¼Œå°†ä½¿ç”¨é»˜è®¤å­—æ®µ 'å­¦å·'")
            link_field = 'å­¦å·'
        
        print(f"âœ… å·²è®¾ç½®å…³è”å­—æ®µ: {link_field}")
        
        # ä¸ºæ¯ä¸ªéœ€è¦è¡¥å……çš„å­—æ®µè®¾ç½®é»˜è®¤å€¼
        default_values = {}
        
        for field in fields_need_supplement:
            print(f"\nğŸ“ è¯·è¾“å…¥å­—æ®µ '{field}' æœªæ‰¾åˆ°åŒ¹é…æ—¶ä½¿ç”¨çš„é»˜è®¤å€¼")
            default_value = input(f"é»˜è®¤å€¼ï¼ˆé»˜è®¤ï¼šæœªçŸ¥{field}ï¼‰: ").strip()
            if not default_value:
                default_value = f"æœªçŸ¥{field}"
            default_values[field] = default_value
            print(f"âœ… å·²è®¾ç½®å­—æ®µ '{field}' é»˜è®¤å€¼: {default_value}")
        
        return True, {}, default_values, link_field
    
    def build_field_mapping(self, files_with_field: List[str], target_field: str, link_field: str = 'å­¦å·') -> Dict[str, str]:
        """
        æ„å»ºå­—æ®µæ˜ å°„å…³ç³»
        
        Args:
            files_with_field: åŒ…å«ç›®æ ‡å­—æ®µçš„æ–‡ä»¶åˆ—è¡¨
            target_field: ç›®æ ‡å­—æ®µå
            link_field: å…³è”å­—æ®µåï¼ˆé»˜è®¤å­¦å·ï¼‰
            
        Returns:
            æ˜ å°„å­—å…¸ {link_value: target_value}
        """
        mapping = {}
        
        print(f"\nğŸ”„ æ„å»º{link_field}åˆ°{target_field}çš„æ˜ å°„...")
        
        for file in files_with_field:
            try:
                df = pd.read_excel(file)
                
                # ç¡®å®šå…³è”å­—æ®µå’Œç›®æ ‡å­—æ®µçš„å®é™…åç§°
                actual_link_field = self.find_actual_field_name(df, link_field)
                actual_target_field = self.find_actual_field_name(df, target_field)
                
                if not actual_link_field or not actual_target_field:
                    continue
                
                # æ„å»ºæ˜ å°„
                for _, row in df.iterrows():
                    link_value = str(row[actual_link_field]).strip()
                    target_value = str(row[actual_target_field]).strip()
                    
                    if pd.notna(link_value) and link_value != '' and pd.notna(target_value) and target_value != '':
                        # å¦‚æœå…³è”å€¼å·²å­˜åœ¨ï¼Œæ£€æŸ¥å€¼æ˜¯å¦ä¸€è‡´
                        if link_value in mapping:
                            if mapping[link_value] != target_value:
                                print(f"âš ï¸  {link_field} {link_value} åœ¨ä¸åŒæ–‡ä»¶ä¸­æœ‰ä¸åŒçš„{target_field}å€¼: {mapping[link_value]} vs {target_value}")
                                # ä¿ç•™ç¬¬ä¸€ä¸ªå€¼ï¼Œè·³è¿‡åç»­çš„
                                continue
                        else:
                            mapping[link_value] = target_value
                
                print(f"ğŸ“Š {os.path.basename(file)}: æ·»åŠ äº† {len(df)} ä¸ªæ˜ å°„å…³ç³»")
                
            except Exception as e:
                print(f"âš ï¸  æ„å»ºæ˜ å°„æ—¶å‡ºé”™ '{os.path.basename(file)}': {str(e)}")
                continue
        
        print(f"âœ… æ€»å…±æ„å»ºäº† {len(mapping)} ä¸ª{link_field}-{target_field}æ˜ å°„å…³ç³»")
        return mapping
    
    def find_actual_field_name(self, df: pd.DataFrame, field: str) -> str:
        """
        åœ¨æ•°æ®æ¡†ä¸­æŸ¥æ‰¾å­—æ®µçš„å®é™…åç§°ï¼ˆåŒ…æ‹¬å˜ä½“ï¼‰
        
        Args:
            df: æ•°æ®æ¡†
            field: ç›®æ ‡å­—æ®µå
            
        Returns:
            å®é™…å­—æ®µåæˆ–None
        """
        if field in df.columns:
            return field
        
        # æ£€æŸ¥å˜ä½“
        variants = self.get_field_variants(field)
        for variant in variants:
            if variant in df.columns:
                return variant
        
        return None
    
    def supplement_fields(self, df: pd.DataFrame, field_mappings: Dict[str, Dict[str, str]], 
                         default_values: Dict[str, str], link_field: str = 'å­¦å·') -> pd.DataFrame:
        """
        ä¸ºæ•°æ®æ¡†è¡¥å……ç¼ºå¤±å­—æ®µ
        
        Args:
            df: æ•°æ®æ¡†
            field_mappings: å­—æ®µæ˜ å°„å­—å…¸ {field_name: {link_value: target_value}}
            default_values: é»˜è®¤å€¼å­—å…¸ {field_name: default_value}
            link_field: å…³è”å­—æ®µå
            
        Returns:
            è¡¥å……åçš„æ•°æ®æ¡†
        """
        # ç¡®å®šå…³è”å­—æ®µçš„å®é™…åç§°
        actual_link_field = self.find_actual_field_name(df, link_field)
        if not actual_link_field:
            print(f"âš ï¸  æ•°æ®æ¡†ä¸åŒ…å«å…³è”å­—æ®µ '{link_field}'ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼å¡«å……ç¼ºå¤±å­—æ®µ")
            # å³ä½¿æ²¡æœ‰å…³è”å­—æ®µï¼Œä¹Ÿè¦åˆ›å»ºç¼ºå¤±çš„å­—æ®µå¹¶å¡«å……é»˜è®¤å€¼
            for target_field in field_mappings.keys():
                if target_field not in df.columns:
                    df[target_field] = default_values.get(target_field, f"æœªçŸ¥{target_field}")
                    print(f"ğŸ“ åˆ›å»ºå­—æ®µ: {target_field} (ä½¿ç”¨é»˜è®¤å€¼)")
            return df
        
        # ä¸ºæ¯ä¸ªéœ€è¦è¡¥å……çš„å­—æ®µè¿›è¡Œå¤„ç†
        for target_field, mapping in field_mappings.items():
            # ç¡®å®šç›®æ ‡å­—æ®µçš„å®é™…åç§°
            actual_target_field = self.find_actual_field_name(df, target_field)
            
            # å¦‚æœç›®æ ‡å­—æ®µä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒå¹¶å¡«å……é»˜è®¤å€¼
            if not actual_target_field:
                actual_target_field = target_field
                df[actual_target_field] = default_values.get(target_field, f"æœªçŸ¥{target_field}")
                print(f"ğŸ“ åˆ›å»ºå­—æ®µ: {actual_target_field}")
            else:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è¡¥å……
                missing_values = df[actual_target_field].isna() | (df[actual_target_field].astype(str).str.strip() == '')
                if not missing_values.any():
                    print(f"âœ… å­—æ®µ '{target_field}' å·²å®Œæ•´ï¼Œæ— éœ€è¡¥å……")
                    continue
            
            # è¡¥å……å­—æ®µå€¼
            supplemented_count = 0
            successful_matches = 0
            default_used = 0
            
            for idx, row in df.iterrows():
                link_value = str(row[actual_link_field]).strip()
                current_value = str(row[actual_target_field]).strip()
                
                # è·³è¿‡ç©ºå…³è”å€¼
                if pd.isna(link_value) or link_value == '':
                    continue
                
                # æ£€æŸ¥å½“å‰å€¼æ˜¯å¦ä¸ºç©ºæˆ–é»˜è®¤å€¼
                if pd.isna(current_value) or current_value == '' or current_value == default_values.get(target_field, ''):
                    # å°è¯•ä»æ˜ å°„ä¸­è·å–å€¼
                    if link_value in mapping:
                        df.at[idx, actual_target_field] = mapping[link_value]
                        successful_matches += 1
                    else:
                        # å°è¯•æ¨¡ç³ŠåŒ¹é…
                        matched_value = self.fuzzy_match_field_value(link_value, mapping)
                        if matched_value:
                            df.at[idx, actual_target_field] = matched_value
                            successful_matches += 1
                        else:
                            df.at[idx, actual_target_field] = default_values.get(target_field, f"æœªçŸ¥{target_field}")
                            default_used += 1
                    supplemented_count += 1
            
            if supplemented_count > 0:
                print(f"ğŸ“Š å­—æ®µ '{target_field}' è¡¥å……ç»Ÿè®¡: æˆåŠŸåŒ¹é… {successful_matches} ä¸ªï¼Œä½¿ç”¨é»˜è®¤å€¼ {default_used} ä¸ª")
        
        return df
    
    def fuzzy_match_field_value(self, link_value: str, mapping: Dict[str, str]) -> str:
        """
        æ¨¡ç³ŠåŒ¹é…å­—æ®µå€¼
        
        Args:
            link_value: å…³è”å€¼
            mapping: æ˜ å°„å­—å…¸
            
        Returns:
            åŒ¹é…çš„å€¼æˆ–None
        """
        # ç²¾ç¡®åŒ¹é…
        if link_value in mapping:
            return mapping[link_value]
        
        # å¯¹äºæ•°å­—å­—æ®µï¼Œä½¿ç”¨æ›´ä¸¥æ ¼çš„åŒ¹é…è§„åˆ™
        if link_value.isdigit():
            # åªå…è®¸æœ€åä¸€ä½æ•°å­—çš„å·®å¼‚ï¼Œä¸”å·®å¼‚ä¸èƒ½è¶…è¿‡2
            for map_key, map_value in mapping.items():
                if map_key.isdigit() and len(link_value) == len(map_key):
                    # æ£€æŸ¥é™¤äº†æœ€åä¸€ä½å¤–çš„å…¶ä»–ä½æ˜¯å¦ç›¸åŒ
                    if link_value[:-1] == map_key[:-1]:
                        # æ£€æŸ¥æœ€åä¸€ä½çš„å·®å¼‚
                        last_diff = abs(int(link_value[-1]) - int(map_key[-1]))
                        if last_diff <= 2:  # å…è®¸æœ€åä¸€ä½å·®å¼‚ä¸è¶…è¿‡2
                            return map_value
        else:
            # å¯¹äºéæ•°å­—å­—æ®µï¼Œä½¿ç”¨åŸæ¥çš„æ¨¡ç³ŠåŒ¹é…
            for map_key, map_value in mapping.items():
                if len(link_value) == len(map_key):
                    diff_count = sum(1 for a, b in zip(link_value, map_key) if a != b)
                    if diff_count <= 1:  # å…è®¸ä¸€ä½å­—ç¬¦çš„å·®å¼‚
                        return map_value
        
        return None

    def run_multi_sync_mode(self):
        """è¿è¡Œå¤šæºåŒæ­¥æ¨¡å¼"""
        print("\nğŸ”„ å¯åŠ¨å¤šæºåŒæ­¥æ¨¡å¼...")
        
        try:
            # 1. æ–‡ä»¶é€‰æ‹©
            self.select_multi_sync_files()
            
            # 2. å…³è”å­—æ®µé€‰æ‹©
            self.select_multi_sync_link_field()
            
            # 3. æ›´æ–°å­—æ®µé€‰æ‹©
            self.select_multi_sync_update_fields()
            
            # 4. å†²çªå¤„ç†é…ç½®
            self.configure_conflict_handling()
            
            # 5. è¾“å‡ºè®¾ç½®
            self.set_multi_sync_output()
            
            # 6. æ‰§è¡Œå¤šæºåŒæ­¥
            self.execute_multi_sync()
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
    
    def select_multi_sync_files(self):
        """å¤šæºåŒæ­¥æ–‡ä»¶é€‰æ‹©"""
        print(f"\n=== æ­¥éª¤1: å¤šæºåŒæ­¥æ–‡ä»¶é€‰æ‹© ===")
        
        # é€‰æ‹©æ–‡ä»¶å¤¹
        folder_path = input("è¯·è¾“å…¥åŒ…å«Excelæ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆæˆ–æŒ‰å›è½¦ä½¿ç”¨é»˜è®¤ç›®å½•G:\\wang\\excelï¼‰: ").strip()
        if not folder_path:
            folder_path = "G:\\wang\\excel"
        
        # æ‰«æExcelæ–‡ä»¶
        excel_patterns = ['*.xlsx', '*.xls']
        excel_files = []
        
        for pattern in excel_patterns:
            excel_files.extend(glob.glob(os.path.join(folder_path, pattern)))
        
        if not excel_files:
            print(f"âŒ åœ¨æ–‡ä»¶å¤¹ '{folder_path}' ä¸­æ²¡æœ‰æ‰¾åˆ°Excelæ–‡ä»¶")
            return
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
        print(f"\nâœ… æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶:")
        for i, file in enumerate(excel_files, 1):
            filename = os.path.basename(file)
            file_size = os.path.getsize(file) / 1024  # KB
            print(f"{i:2d}. {filename:<30} ({file_size:.1f} KB)")
        
        # é€‰æ‹©æºæ–‡ä»¶ï¼ˆå¤šä¸ªï¼‰
        print(f"\nğŸ“‹ è¯·é€‰æ‹©æºæ–‡ä»¶ï¼ˆæä¾›æ•°æ®çš„æ–‡ä»¶ï¼Œå¯å¤šé€‰ï¼‰:")
        print("ğŸ“ è¾“å…¥æ–‡ä»¶ç¼–å·ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆå¦‚ï¼š1,2,3ï¼‰")
        print("ğŸ“ è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰æ–‡ä»¶ä½œä¸ºæºæ–‡ä»¶")
        
        while True:
            try:
                source_choice = input("è¯·è¾“å…¥æºæ–‡ä»¶ç¼–å·: ").strip()
                if source_choice.lower() == 'all':
                    self.source_files = excel_files
                    print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(excel_files)} ä¸ªæ–‡ä»¶ä½œä¸ºæºæ–‡ä»¶")
                    break
                else:
                    source_indices = [int(x.strip()) - 1 for x in source_choice.split(',')]
                    self.source_files = [excel_files[i] for i in source_indices if 0 <= i < len(excel_files)]
                    
                    if not self.source_files:
                        print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆæ–‡ä»¶ï¼Œè¯·é‡æ–°é€‰æ‹©")
                        continue
                    
                    print(f"âœ… å·²é€‰æ‹© {len(self.source_files)} ä¸ªæºæ–‡ä»¶:")
                    for file in self.source_files:
                        print(f"  ğŸ“„ {os.path.basename(file)}")
                    break
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        # é€‰æ‹©ç›®æ ‡æ–‡ä»¶
        print(f"\nğŸ“‹ è¯·é€‰æ‹©ç›®æ ‡æ–‡ä»¶ï¼ˆéœ€è¦æ›´æ–°çš„æ–‡ä»¶ï¼‰:")
        while True:
            try:
                target_choice = input("è¯·è¾“å…¥ç›®æ ‡æ–‡ä»¶ç¼–å·: ").strip()
                target_index = int(target_choice) - 1
                if 0 <= target_index < len(excel_files):
                    self.target_file = excel_files[target_index]
                    print(f"âœ… ç›®æ ‡æ–‡ä»¶: {os.path.basename(self.target_file)}")
                    break
                else:
                    print("âŒ æ–‡ä»¶ç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°é€‰æ‹©")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    def select_multi_sync_link_field(self):
        """å¤šæºåŒæ­¥å…³è”å­—æ®µé€‰æ‹©"""
        print(f"\n=== æ­¥éª¤2: å…³è”å­—æ®µé€‰æ‹© ===")
        
        try:
            # è¯»å–ç›®æ ‡æ–‡ä»¶
            target_df = pd.read_excel(self.target_file)
            target_columns = list(target_df.columns)
            
            # è¯»å–æ‰€æœ‰æºæ–‡ä»¶ï¼Œæ‰¾å‡ºå…±åŒçš„å­—æ®µ
            all_source_columns = set()
            for source_file in self.source_files:
                source_df = pd.read_excel(source_file)
                all_source_columns.update(source_df.columns)
            
            # æ‰¾å‡ºç›®æ ‡æ–‡ä»¶å’Œæ‰€æœ‰æºæ–‡ä»¶å…±æœ‰çš„å­—æ®µ
            common_fields = list(set(target_columns) & all_source_columns)
            
            if not common_fields:
                print("âŒ ç›®æ ‡æ–‡ä»¶å’Œæºæ–‡ä»¶æ²¡æœ‰å…±åŒçš„å­—æ®µï¼Œæ— æ³•è¿›è¡ŒåŒæ­¥")
                return
            
            # æ™ºèƒ½æ£€æµ‹å…³è”å­—æ®µ
            print(f"ğŸ” æ™ºèƒ½æ£€æµ‹å…³è”å­—æ®µ...")
            
            # ä¼˜å…ˆé€‰æ‹©å¸¸è§çš„å…³é”®å­—æ®µ
            priority_fields = ['å­¦å·', 'æ•™å·¥å·', 'å·¥å·', 'ç¼–å·', 'ID', 'id', 'student_id', 'teacher_id']
            detected_field = None
            
            for priority_field in priority_fields:
                for field in common_fields:
                    if priority_field in field or field in priority_field:
                        detected_field = field
                        break
                if detected_field:
                    break
            
            # æ£€æµ‹æºæ–‡ä»¶ä¹‹é—´çš„å­—æ®µæ¨¡ç³ŠåŒ¹é…
            print(f"ğŸ” æ£€æµ‹æºæ–‡ä»¶å­—æ®µåŒ¹é…æƒ…å†µ...")
            source_files_data = {}
            for source_file in self.source_files:
                source_df = pd.read_excel(source_file)
                source_files_data[os.path.basename(source_file)] = list(source_df.columns)
            
            # æ£€æŸ¥å­—æ®µæ¨¡ç³ŠåŒ¹é…
            fuzzy_matches = []
            for i, file1 in enumerate(self.source_files):
                for j, file2 in enumerate(self.source_files):
                    if i < j:  # é¿å…é‡å¤æ£€æŸ¥
                        file1_name = os.path.basename(file1)
                        file2_name = os.path.basename(file2)
                        file1_fields = source_files_data[file1_name]
                        file2_fields = source_files_data[file2_name]
                        
                        # æ£€æŸ¥å­—æ®µæ¨¡ç³ŠåŒ¹é…
                        for field1 in file1_fields:
                            for field2 in file2_fields:
                                if field1 != field2 and self.calculate_similarity(field1, field2) >= 0.8:
                                    fuzzy_matches.append({
                                        'file1': file1_name,
                                        'file2': file2_name,
                                        'field1': field1,
                                        'field2': field2,
                                        'similarity': self.calculate_similarity(field1, field2)
                                    })
            
            # æ˜¾ç¤ºæ¨¡ç³ŠåŒ¹é…ç»“æœ
            if fuzzy_matches:
                print(f"ğŸ’¡ å‘ç° {len(fuzzy_matches)} ä¸ªå­—æ®µæ¨¡ç³ŠåŒ¹é…:")
                for match in fuzzy_matches:
                    print(f"  ğŸ“‹ {match['file1']} çš„ '{match['field1']}' ä¸ {match['file2']} çš„ '{match['field2']}' ç›¸ä¼¼åº¦: {match['similarity']:.2f}")
                print(f"ğŸ’¡ è¿™äº›å­—æ®µå¯èƒ½è¡¨ç¤ºç›¸åŒçš„æ•°æ®ï¼Œå»ºè®®æ£€æŸ¥å­—æ®µæ˜ å°„")
            else:
                print(f"âœ… æœªå‘ç°æ˜æ˜¾çš„å­—æ®µæ¨¡ç³ŠåŒ¹é…")
            
            # æ˜¾ç¤ºæ£€æµ‹å»ºè®®
            if detected_field:
                print(f"ğŸ’¡ å»ºè®®é€‰æ‹©å…³è”å­—æ®µ: {detected_field}")
            else:
                print(f"ğŸ’¡ æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„å…³è”å­—æ®µï¼Œè¯·æ‰‹åŠ¨é€‰æ‹©")
            
            # æ˜¾ç¤ºæ‰€æœ‰å¯é€‰å­—æ®µ
            print(f"ğŸ“‹ ç›®æ ‡æ–‡ä»¶å’Œæºæ–‡ä»¶å…±æœ‰çš„å­—æ®µ:")
            for i, field in enumerate(common_fields, 1):
                if detected_field and field == detected_field:
                    print(f"{i:2d}. {field} (æ¨è)")
                else:
                    print(f"{i:2d}. {field}")
            
            # è®©ç”¨æˆ·é€‰æ‹©
            print(f"\nğŸ“ è¯·é€‰æ‹©ç”¨äºåŒ¹é…çš„å…³è”å­—æ®µ:")
            while True:
                try:
                    link_choice = input("è¯·è¾“å…¥å…³è”å­—æ®µç¼–å·: ").strip()
                    link_index = int(link_choice) - 1
                    if 0 <= link_index < len(common_fields):
                        self.link_field = common_fields[link_index]
                        print(f"âœ… å…³è”å­—æ®µ: {self.link_field}")
                        break
                    else:
                        print("âŒ å­—æ®µç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°é€‰æ‹©")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                    
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    def select_multi_sync_update_fields(self):
        """å¤šæºåŒæ­¥æ›´æ–°å­—æ®µé€‰æ‹©"""
        print(f"\n=== æ­¥éª¤3: æ›´æ–°å­—æ®µé€‰æ‹© ===")
        
        try:
            # è¯»å–ç›®æ ‡æ–‡ä»¶
            target_df = pd.read_excel(self.target_file)
            target_columns = list(target_df.columns)
            
            # è¯»å–æ‰€æœ‰æºæ–‡ä»¶ï¼Œæ‰¾å‡ºå¯æ›´æ–°çš„å­—æ®µ
            all_source_columns = set()
            for source_file in self.source_files:
                source_df = pd.read_excel(source_file)
                all_source_columns.update(source_df.columns)
            
            # æ‰¾å‡ºç›®æ ‡æ–‡ä»¶ä¸­å­˜åœ¨ä¸”æºæ–‡ä»¶ä¸­ä¹Ÿå­˜åœ¨çš„å­—æ®µï¼ˆæ’é™¤å…³è”å­—æ®µï¼‰
            updateable_fields = [field for field in target_columns 
                               if field in all_source_columns and field != self.link_field]
            
            if not updateable_fields:
                print("âŒ æ²¡æœ‰å¯æ›´æ–°çš„å­—æ®µ")
                return
            
            # æ™ºèƒ½æ£€æµ‹æ›´æ–°å­—æ®µ
            print(f"ğŸ” æ™ºèƒ½æ£€æµ‹å¯æ›´æ–°å­—æ®µ...")
            
            # æ£€æµ‹æºæ–‡ä»¶ä¹‹é—´çš„å­—æ®µæ¨¡ç³ŠåŒ¹é…
            print(f"ğŸ” æ£€æµ‹æºæ–‡ä»¶å­—æ®µåŒ¹é…æƒ…å†µ...")
            source_files_data = {}
            for source_file in self.source_files:
                source_df = pd.read_excel(source_file)
                source_files_data[os.path.basename(source_file)] = list(source_df.columns)
            
            # æ£€æŸ¥å­—æ®µæ¨¡ç³ŠåŒ¹é…
            fuzzy_matches = []
            for i, file1 in enumerate(self.source_files):
                for j, file2 in enumerate(self.source_files):
                    if i < j:  # é¿å…é‡å¤æ£€æŸ¥
                        file1_name = os.path.basename(file1)
                        file2_name = os.path.basename(file2)
                        file1_fields = source_files_data[file1_name]
                        file2_fields = source_files_data[file2_name]
                        
                        # æ£€æŸ¥å­—æ®µæ¨¡ç³ŠåŒ¹é…
                        for field1 in file1_fields:
                            for field2 in file2_fields:
                                if field1 != field2 and self.calculate_similarity(field1, field2) >= 0.8:
                                    fuzzy_matches.append({
                                        'file1': file1_name,
                                        'file2': file2_name,
                                        'field1': field1,
                                        'field2': field2,
                                        'similarity': self.calculate_similarity(field1, field2)
                                    })
            
            # æ˜¾ç¤ºæ¨¡ç³ŠåŒ¹é…ç»“æœ
            if fuzzy_matches:
                print(f"ğŸ’¡ å‘ç° {len(fuzzy_matches)} ä¸ªå­—æ®µæ¨¡ç³ŠåŒ¹é…:")
                for match in fuzzy_matches:
                    print(f"  ğŸ“‹ {match['file1']} çš„ '{match['field1']}' ä¸ {match['file2']} çš„ '{match['field2']}' ç›¸ä¼¼åº¦: {match['similarity']:.2f}")
                print(f"ğŸ’¡ è¿™äº›å­—æ®µå¯èƒ½è¡¨ç¤ºç›¸åŒçš„æ•°æ®ï¼Œå»ºè®®æ£€æŸ¥å­—æ®µæ˜ å°„")
            else:
                print(f"âœ… æœªå‘ç°æ˜æ˜¾çš„å­—æ®µæ¨¡ç³ŠåŒ¹é…")
            
            # æ˜¾ç¤ºæ£€æµ‹å»ºè®®
            if updateable_fields:
                print(f"ğŸ’¡ æ£€æµ‹åˆ° {len(updateable_fields)} ä¸ªå¯æ›´æ–°å­—æ®µ")
                print(f"ğŸ“‹ å¯æ›´æ–°çš„å­—æ®µï¼ˆæ’é™¤å…³è”å­—æ®µ '{self.link_field}'ï¼‰:")
                for i, field in enumerate(updateable_fields, 1):
                    # æ˜¾ç¤ºæ¯ä¸ªå­—æ®µæ¥è‡ªå“ªäº›æºæ–‡ä»¶
                    source_files_with_field = []
                    for source_file in self.source_files:
                        source_df = pd.read_excel(source_file)
                        if field in source_df.columns:
                            source_files_with_field.append(os.path.basename(source_file))
                    
                    field_info = f"{i:2d}. {field}"
                    if source_files_with_field:
                        field_info += f" (æ¥è‡ª: {', '.join(source_files_with_field)})"
                    print(field_info)
                
                # è®©ç”¨æˆ·é€‰æ‹©
                print(f"\nğŸ“ è¯·é€‰æ‹©è¦æ›´æ–°çš„å­—æ®µ:")
                print("ğŸ“ è¾“å…¥å­—æ®µç¼–å·ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆå¦‚ï¼š1,2,3ï¼‰")
                print("ğŸ“ è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰å¯æ›´æ–°å­—æ®µ")
                
                while True:
                    try:
                        update_choice = input("è¯·è¾“å…¥è¦æ›´æ–°çš„å­—æ®µç¼–å·: ").strip()
                        if update_choice.lower() == 'all':
                            self.update_fields = updateable_fields
                            print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(updateable_fields)} ä¸ªå­—æ®µè¿›è¡Œæ›´æ–°")
                            break
                        else:
                            update_indices = [int(x.strip()) - 1 for x in update_choice.split(',')]
                            self.update_fields = [updateable_fields[i] for i in update_indices if 0 <= i < len(updateable_fields)]
                            
                            if not self.update_fields:
                                print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆå­—æ®µï¼Œè¯·é‡æ–°é€‰æ‹©")
                                continue
                            
                            print(f"âœ… å·²é€‰æ‹© {len(self.update_fields)} ä¸ªå­—æ®µè¿›è¡Œæ›´æ–°:")
                            for field in self.update_fields:
                                print(f"  ğŸ“‹ {field}")
                            break
                    except ValueError:
                        print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            else:
                print(f"âŒ æ²¡æœ‰å¯æ›´æ–°çš„å­—æ®µ")
                return
                    
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    def configure_conflict_handling(self):
        """é…ç½®å†²çªå¤„ç†æ–¹å¼"""
        print(f"\n=== æ­¥éª¤4: å†²çªå¤„ç†é…ç½® ===")
        
        print("ğŸ¤” å½“å¤šä¸ªæºæ–‡ä»¶å¯¹åŒä¸€è®°å½•æä¾›ä¸åŒæ•°æ®æ—¶ï¼Œå¦‚ä½•å¤„ç†å†²çªï¼Ÿ")
        print("1. è¯¢é—®ç”¨æˆ·é€‰æ‹©ï¼ˆæ¨èï¼‰")
        print("2. ä½¿ç”¨ç¬¬ä¸€ä¸ªæºæ–‡ä»¶çš„æ•°æ®")
        print("3. ä½¿ç”¨æœ€åä¸€ä¸ªæºæ–‡ä»¶çš„æ•°æ®")
        print("4. è·³è¿‡å†²çªçš„è®°å½•")
        
        while True:
            choice = input("\nè¯·é€‰æ‹©å†²çªå¤„ç†æ–¹å¼ (1/2/3/4): ").strip()
            if choice == "1":
                self.conflict_handling = "ask"
                print("âœ… å·²é€‰æ‹©ï¼šè¯¢é—®ç”¨æˆ·é€‰æ‹©")
                break
            elif choice == "2":
                self.conflict_handling = "first"
                print("âœ… å·²é€‰æ‹©ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªæºæ–‡ä»¶çš„æ•°æ®")
                break
            elif choice == "3":
                self.conflict_handling = "last"
                print("âœ… å·²é€‰æ‹©ï¼šä½¿ç”¨æœ€åä¸€ä¸ªæºæ–‡ä»¶çš„æ•°æ®")
                break
            elif choice == "4":
                self.conflict_handling = "skip"
                print("âœ… å·²é€‰æ‹©ï¼šè·³è¿‡å†²çªçš„è®°å½•")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2ã€3 æˆ– 4")
    
    def set_multi_sync_output(self):
        """è®¾ç½®å¤šæºåŒæ­¥è¾“å‡º"""
        print(f"\n=== æ­¥éª¤5: è¾“å‡ºè®¾ç½® ===")
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        self.output_directory = input("è¯·è¾“å…¥è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆæˆ–æŒ‰å›è½¦ä½¿ç”¨é»˜è®¤ç›®å½•G:\\wang\\excelï¼‰: ").strip()
        if not self.output_directory:
            self.output_directory = "G:\\wang\\excel"
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if not os.path.exists(self.output_directory):
            try:
                os.makedirs(self.output_directory)
                print(f"âœ… å·²åˆ›å»ºè¾“å‡ºç›®å½•: {self.output_directory}")
            except Exception as e:
                print(f"âŒ åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: {str(e)}")
                return
        
        print(f"âœ… è¾“å‡ºç›®å½•: {self.output_directory}")
    
    def execute_multi_sync(self):
        """æ‰§è¡Œå¤šæºåŒæ­¥"""
        print(f"\n=== æ­¥éª¤6: æ‰§è¡Œå¤šæºåŒæ­¥ ===")
        
        try:
            # å¤‡ä»½ç›®æ ‡æ–‡ä»¶
            self.backup_target_file()
            
            # è¯»å–ç›®æ ‡æ–‡ä»¶
            target_df = pd.read_excel(self.target_file)
            print(f"ğŸ“Š ç›®æ ‡æ–‡ä»¶åŒ…å« {len(target_df)} æ¡è®°å½•")
            
            # è¯»å–æ‰€æœ‰æºæ–‡ä»¶
            source_data = {}
            for source_file in self.source_files:
                source_df = pd.read_excel(source_file)
                source_data[os.path.basename(source_file)] = source_df
                print(f"ğŸ“Š æºæ–‡ä»¶ '{os.path.basename(source_file)}' åŒ…å« {len(source_df)} æ¡è®°å½•")
            
            # æ‰§è¡Œå¤šæºåŒæ­¥
            updated_df = self.perform_multi_sync(target_df, source_data)
            
            # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
            self.save_multi_sync_file(updated_df)
            
            # æ˜¾ç¤ºåŒæ­¥ç»“æœ
            self.show_multi_sync_results(target_df, updated_df)
            
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå¤šæºåŒæ­¥æ—¶å‡ºé”™: {str(e)}")
    
    def perform_multi_sync(self, target_df: pd.DataFrame, source_data: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """
        æ‰§è¡Œå¤šæºåŒæ­¥
        
        Args:
            target_df: ç›®æ ‡æ•°æ®æ¡†
            source_data: æºæ•°æ®å­—å…¸ {æ–‡ä»¶å: æ•°æ®æ¡†}
            
        Returns:
            æ›´æ–°åçš„æ•°æ®æ¡†
        """
        print(f"\nğŸ”„ å¼€å§‹æ‰§è¡Œå¤šæºåŒæ­¥...")
        
        # ç¡®å®šå…³è”å­—æ®µçš„å®é™…åç§°
        actual_link_field = self.find_actual_field_name(target_df, self.link_field)
        if not actual_link_field:
            print(f"âŒ ç›®æ ‡æ–‡ä»¶ä¸­æ‰¾ä¸åˆ°å…³è”å­—æ®µ '{self.link_field}'")
            return target_df
        
        # åˆ›å»ºæ›´æ–°åçš„æ•°æ®æ¡†å‰¯æœ¬
        updated_df = target_df.copy()
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_updates = 0
        conflicts_resolved = 0
        conflicts_skipped = 0
        
        # ä¸ºæ¯ä¸ªç›®æ ‡è®°å½•æŸ¥æ‰¾æºæ•°æ®
        for target_idx, target_row in updated_df.iterrows():
            link_value = str(target_row[actual_link_field]).strip()
            
            # è·³è¿‡ç©ºå…³è”å€¼
            if pd.isna(link_value) or link_value == '':
                continue
            
            # åœ¨æ‰€æœ‰æºæ–‡ä»¶ä¸­æŸ¥æ‰¾åŒ¹é…çš„è®°å½•
            matching_data = {}
            for source_name, source_df in source_data.items():
                # ç¡®å®šæºæ–‡ä»¶ä¸­çš„å…³è”å­—æ®µåç§°
                source_link_field = self.find_actual_field_name(source_df, self.link_field)
                if not source_link_field:
                    continue
                
                # æŸ¥æ‰¾åŒ¹é…çš„è®°å½•
                matching_rows = source_df[source_df[source_link_field].astype(str).str.strip() == link_value]
                if not matching_rows.empty:
                    matching_data[source_name] = matching_rows.iloc[0]  # å–ç¬¬ä¸€æ¡åŒ¹é…è®°å½•
            
            if not matching_data:
                continue
            
            # å¤„ç†æ¯ä¸ªæ›´æ–°å­—æ®µ
            for update_field in self.update_fields:
                # ç¡®å®šç›®æ ‡å­—æ®µçš„å®é™…åç§°
                actual_update_field = self.find_actual_field_name(updated_df, update_field)
                if not actual_update_field:
                    continue
                
                # æ”¶é›†æ‰€æœ‰æºæ–‡ä»¶ä¸­çš„å€¼
                field_values = {}
                for source_name, source_row in matching_data.items():
                    # ç¡®å®šæºæ–‡ä»¶ä¸­çš„å­—æ®µåç§°
                    source_field = self.find_actual_field_name(source_data[source_name], update_field)
                    if source_field and not pd.isna(source_row[source_field]):
                        field_values[source_name] = str(source_row[source_field]).strip()
                
                if not field_values:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å†²çªï¼ˆå¤šä¸ªä¸åŒçš„å€¼ï¼‰
                unique_values = set(field_values.values())
                if len(unique_values) == 1:
                    # æ²¡æœ‰å†²çªï¼Œç›´æ¥æ›´æ–°
                    value = list(unique_values)[0]
                    updated_df.at[target_idx, actual_update_field] = value
                    total_updates += 1
                else:
                    # æœ‰å†²çªï¼Œæ ¹æ®é…ç½®å¤„ç†
                    if self.conflict_handling == "ask":
                        # è¯¢é—®ç”¨æˆ·é€‰æ‹©
                        choice = self.ask_user_for_conflict_resolution(link_value, update_field, field_values)
                        if choice:
                            updated_df.at[target_idx, actual_update_field] = choice
                            total_updates += 1
                            conflicts_resolved += 1
                    elif self.conflict_handling == "first":
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæºæ–‡ä»¶çš„æ•°æ®
                        first_source = list(field_values.keys())[0]
                        updated_df.at[target_idx, actual_update_field] = field_values[first_source]
                        total_updates += 1
                        conflicts_resolved += 1
                    elif self.conflict_handling == "last":
                        # ä½¿ç”¨æœ€åä¸€ä¸ªæºæ–‡ä»¶çš„æ•°æ®
                        last_source = list(field_values.keys())[-1]
                        updated_df.at[target_idx, actual_update_field] = field_values[last_source]
                        total_updates += 1
                        conflicts_resolved += 1
                    elif self.conflict_handling == "skip":
                        # è·³è¿‡å†²çªçš„è®°å½•
                        conflicts_skipped += 1
                        continue
        
        print(f"âœ… å¤šæºåŒæ­¥å®Œæˆ:")
        print(f"  ğŸ“Š æ€»æ›´æ–°æ•°: {total_updates}")
        print(f"  ğŸ”„ å†²çªè§£å†³æ•°: {conflicts_resolved}")
        print(f"  â­ï¸  å†²çªè·³è¿‡æ•°: {conflicts_skipped}")
        
        return updated_df
    
    def ask_user_for_conflict_resolution(self, link_value: str, field_name: str, field_values: Dict[str, str]) -> str:
        """
        è¯¢é—®ç”¨æˆ·è§£å†³å†²çª
        
        Args:
            link_value: å…³è”å€¼
            field_name: å­—æ®µå
            field_values: å­—æ®µå€¼å­—å…¸ {æºæ–‡ä»¶å: å€¼}
            
        Returns:
            ç”¨æˆ·é€‰æ‹©çš„å€¼æˆ–None
        """
        print(f"\nâš ï¸  å‘ç°æ•°æ®å†²çª:")
        print(f"  ğŸ”— å…³è”å€¼: {link_value}")
        print(f"  ğŸ“‹ å­—æ®µ: {field_name}")
        print(f"  ğŸ“„ ä¸åŒæºæ–‡ä»¶æä¾›çš„å€¼:")
        
        for i, (source_name, value) in enumerate(field_values.items(), 1):
            print(f"    {i}. {source_name}: {value}")
        
        print(f"  ğŸ“ è¯·é€‰æ‹©è¦ä½¿ç”¨çš„å€¼ï¼ˆè¾“å…¥ç¼–å·ï¼‰:")
        print(f"  ğŸ“ è¾“å…¥ 'skip' è·³è¿‡æ­¤å­—æ®µçš„æ›´æ–°")
        
        while True:
            choice = input("è¯·é€‰æ‹©: ").strip()
            if choice.lower() == 'skip':
                return None
            try:
                choice_index = int(choice) - 1
                if 0 <= choice_index < len(field_values):
                    selected_source = list(field_values.keys())[choice_index]
                    selected_value = field_values[selected_source]
                    print(f"âœ… å·²é€‰æ‹©: {selected_source} çš„å€¼ '{selected_value}'")
                    return selected_value
                else:
                    print("âŒ é€‰æ‹©ç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°é€‰æ‹©")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—æˆ– 'skip'")
    
    def save_multi_sync_file(self, updated_df: pd.DataFrame):
        """ä¿å­˜å¤šæºåŒæ­¥æ–‡ä»¶"""
        try:
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            target_basename = os.path.splitext(os.path.basename(self.target_file))[0]
            timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
            output_filename = f"{target_basename}_å¤šæºåŒæ­¥_{timestamp}.xlsx"
            output_path = os.path.join(self.output_directory, output_filename)
            
            # ä¿å­˜æ–‡ä»¶
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # ä¸»æ•°æ®è¡¨
                updated_df.to_excel(writer, sheet_name='åŒæ­¥åæ•°æ®', index=False)
                
                # åŒæ­¥ç»Ÿè®¡è¡¨
                stats_data = {
                    'ç»Ÿè®¡é¡¹ç›®': [
                        'æºæ–‡ä»¶æ•°é‡',
                        'ç›®æ ‡æ–‡ä»¶',
                        'å…³è”å­—æ®µ',
                        'æ›´æ–°å­—æ®µæ•°',
                        'å†²çªå¤„ç†æ–¹å¼',
                        'åŒæ­¥æ—¶é—´'
                    ],
                    'æ•°å€¼': [
                        len(self.source_files),
                        os.path.basename(self.target_file),
                        self.link_field,
                        len(self.update_fields),
                        self.conflict_handling,
                        pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
                    ]
                }
                stats_df = pd.DataFrame(stats_data)
                stats_df.to_excel(writer, sheet_name='åŒæ­¥ç»Ÿè®¡', index=False)
            
            print(f"âœ… åŒæ­¥ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
            self.output_file = output_path
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    def show_multi_sync_results(self, original_df: pd.DataFrame, updated_df: pd.DataFrame):
        """æ˜¾ç¤ºå¤šæºåŒæ­¥ç»“æœ"""
        print(f"\n=== å¤šæºåŒæ­¥ç»“æœ ===")
        print(f"ğŸ“Š åŸå§‹è®°å½•æ•°: {len(original_df)}")
        print(f"ğŸ“Š æ›´æ–°åè®°å½•æ•°: {len(updated_df)}")
        print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {self.output_file}")
        print(f"ğŸ“‹ æ›´æ–°çš„å­—æ®µ: {', '.join(self.update_fields)}")
        print(f"ğŸ”— å…³è”å­—æ®µ: {self.link_field}")

def main():
    """ä¸»å‡½æ•°"""
    processor = ExcelProcessor()
    processor.run()

if __name__ == "__main__":
    main()